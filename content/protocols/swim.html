---
title: "SWIM"
date: 2021-12-27
draft: false
---

<p>
  <a href="https://www.cs.cornell.edu/projects/Quicksilver/public_pdfs/SWIM.pdf">Original Paper</a>
</p>

<ul>
  <li>
    SWIM is a <i>membership protocol</i> that provides each member of a group of processes with a locally-maintained list of other non-faulty members.
  </li>
  <li>
    The membership list is updated to reflect members joining the group or dropping out (either voluntarily or through failure).
  </li>
  <li>
   However, membership lists at different members need not be consistent across the group at the same point in time (weakly-consistent).
  </li>
  <li>
    The protocol consists of a <i>failure detector component</i> that detects failures of members and a <i>dissemination component</i> that propagates information about members that have either joined or left the group or failed.
  </li>
  <li>
    Processes are monitored for failure by means of a peer-to-peer periodic randomized probing protocol and information about membership changes is disseminated by piggybacking on the probing protocol messages.
  </li>
  <li>
    The rate of false failure detections is reduced by allowing members to <i>suspect</i> a process before declaring it as failed.
  </li>
</ul>


<h3>Failure Detection Component</h3>

<ul>
  <li>
    We consider an arbitrary member M_i.
  </li>
  <li>
    During each protocol period of length T' on its local clock, M_i chooses a random member M_j from its membership list and sends it a PING.
  </li>
  <li>
    M_i then waits for a replying ACK from M_j.
  </li>
  <li>
    If this reply is not received within a pre-specified timeout then M_i indirectly probes M_j.
  </li>
  <li>
    M_i selects k members at random and sends them a PING-REQ(M_j) to try to avoid the effect of any congestion on the network path between M_i and M_j which might have led to the dropping of the original PING or its ACK.
  </li>
  <li>
    On receiving this message, each of the k members sends a PING to M_j.
  </li>
  <li>
    If any of the k members receive an ACK from M_j then they forward that ACK back to M_i.
  </li>
  <li>
    At the end of this protocol period, M_i checks if it has (directly or indirectly) received any ACK from M_j.
  </li>
  <li>
    If no ACK has been received then M_i declares M_j as failed in its membership list and hands this update to the dissemination component.
  </li>
  <li>
    The data contained in each message of this protocol is tagged with the unique sequence number of the protocol period at the initiator M_i.
  </li>
</ul>


<h3>Failure Detection Parameters</h3>

<ul>
  <li>
    The failure detection algorithm uses two parameters: the protocol period T' (in units of time) and the size of failure detection subgroups k.
  </li>
  <li>
    The protocol does not require clocks to be synchronized across members and the properties of the protocol hold if T' is the average protocol period at the various group members.
  </li>
  <li>
    The pre-specified time-out used to initiate indirect probing is based on an estimate of the distribution of round-trip time (e.g. an average). The protocol period T' has to be at least three times the round-trip estimate. The original authors used the average measured round-trip time to set the timeout and used a T' significantly larger than this value.
  </li>
</ul>



<h3>Dissemination Component</h3>

<ul>
  <li>
    The basic SWIM protocol propagates membership updates using via network multicast.
  </li>
  <li>
    Upon detecting the failure of a group member, the process multicasts this information to the rest of the group as FAILED(M_j).
  </li>
  <li>
    A member receiving this message deletes M_j from its local membership list.
  </li>
  <li>
    Information about newly joined members or voluntarily leaving members are multicast in a similar manner.
  </li>
  <li>
    For a process to join the group, it would need to know at least one contact member in the group.
  </li>
</ul>


<h3>Dissemination using Piggybacking</h3>

<ul>
  <li>
    The use of a multicast primitive can be eliminated by instead piggybacking the information to be disseminated on the PING, PING-REQ and ACK messages generated by the failure detector component.
  </li>
  <li>
    Each group member M_i maintains a buffer of recent membership updates along with a local count for each buffer element.
  </li>
  <li>
    The local count specifies the number of times the element has been piggybacked so far by M_i and is used to choose which elements to piggyback next.
  </li>
  <li>
    If the size of this buffer is larger than the maximum number of elements that can be piggybacked on a single message then elements that have been gossiped fewer times are preferred. Preferring younger elements ensures that all membership changes infect at least a few members.
  </li>
  <li>
    This is needed as the protocol period is fixed and the rate of membership changes might temporarily overwhelm the speed of dissemination.
  </li>
  <li>
    Each element is piggybacked at most λlog(n) times where λ is a parameter.
  </li>
  <li>
    The implementation used by the original authors maintains one list of members that are not yet declared as failed in the group and a second list of members that have failed recently.
  </li>
  <li>
    An equal number of buffer elements was chosen from these two lists for piggybacking but the scheme could be generalized to adapt to relative variations in process join, leave and failure rates.
  </li>
  <li>
    This results in an infection-style of dissemination that is resilient to process failures and message loss. It also eliminates the generation of extra packets by the dissemination component thus giving a constant expected message overhead per group member.
  </li>
</ul>

<h3>Suspicion Mechanism</h3>

<ul>
  <li>
    If a non-faulty group member M_j is mistakenly detected as failed by another group member M_i (e.g. due to network packet losses or due to M_j being temporarily asleep) then M_j will be declared as failed in the group.
  </li>
  <li>
    That is, a healthy process M_j will be forced to drop out of the group at the very first instance that it is mistakenly detected as failed. This leads to a high rate of false positives in detecting failures.
  </li>
  <li>
    We reduce the rate of failure detection false positives by introducing the suspicion sub-protocol which is run whenever a failure is detected by the failure detector component.
  </li>
</ul>

<ul>
  <li>
    Consider a member M_i that chooses a member M_j as a PING target in the current protocol period and receives no ACK after running the failure detector protocol.
  </li>
  <li>
    Instead of declaring M_j as failed, M_i marks M_j as a suspected member in its local membership list and disseminates a {Suspect M_j : M_i suspects M_j} message by means of the dissemination component. Any group member M_l receiving such a message also marks M_j as suspected.
  </li>
  <li>
    Suspected members stay on in the membership list and are treated similar to non-faulty members with regards to the PING target selection operation of the failure detection protocol.
  </li>
  <li>
    If a member M_l successfully pings a suspected member M_j, it un-marks the previous suspicion of M_j in its membership list and spreads an {Alive M_j : M_l knows M_j is alive} message via the dissemination component. This message un-marks the suspected member M_j in membership lists of recipient members.
  </li>
  <li>
    If member M_j receives a message suspecting it the it can start propagating an Alive message clarifying it has not failed.
  </li>
  <li>
    Suspected entries in membership lists expire after a pre-specified timeout. If M_j is suspected at some member M_h and this entry times-out before receipt of an Alive message then M_h declares M_j as faulty, drops it from its local membership list and begins disseminating a {Confirm M_j : M_h declares M_j as faulty} message via the dissemination component.
  </li>
  <li>
    This Confirm message overrides any previous Suspect or Alive message and cascades in deletion of M_j from the membership lists of all recipients.
  </li>
</ul>


<h3>Suspicion Message Precedence</h3>

<ul>
  <li>
    Now, Alive messages override Suspect message and Confirm messages override both Suspect and Alive messages in their effect on the local membership list element corresponding to the suspected member.
  </li>
  <li>
    However, a member might be suspected and unsuspected multiple times during its lifetime. These multiple versions of Suspect and Alive messages (all pertaining to the same member M_j) need to be distinguished through unique identifiers.
  </li>
  <li>
    These identifiers are provided by using a virtual incarnation number field with each element in the membership lists. Incarnation numbers are global.
  </li>
  <li>
    A member M_i’s incarnation number is initialized to 0 when it joins the group, and it can be incremented only by M_i when it receives information (through the dissemination component) about itself being suspected in the current incarnation.
  </li>
  <li>
    M_i then generates an Alive message with its identifier and an incremented incarnation number and spreads this through the Dissemination Component to the group. 
  </li>
  <li>
    Thus, Suspect, Alive and Confirm messages contain the incarnation number of the member. The order of preference among these messages and their effect on the membership list is as follows:

    <ul>
      <li>
        {Alive M_l, inc = i} overrides {Alive M_l, inc = j}, i > j and {Suspect M_l, inc = j}, i > j 
      </li>
      <li>
        {Suspect M_l, inc = i} overrides {Alive M_l, inc = j}, i >= j and {Suspect M_l, inc = j}, i > j
      </li>
      <li>
        {Confirm M_l, inc = i} overrides {Alive M_l, inc = j}, any j and {Suspect M_l, inc = j}, any j
      </li>
    </ul>
  </li>
</ul>

<!--
These orders of preferences and overriding are required to maintain the desired correctness properties.

The preference rules and infection-style Dissemination Component also accommodate suspicions of a process by multiple other processes.

Preference rules do not depend on the source of suspicion, and the infection-style dissemination spreads a message (Suspect, Alive or Confirm) quicker if there are multiple sources, with exactly the same overhead per process as with one source of infection.

Failures of processes suspecting a failed pro-cess M_j may prolong detection time, but eventual detection is guaranteed.
-->


<!-- Suspicion mechanism, where a pro-cess that is unresponsive to ping messages, as generated by the SWIM failure detector protocol described in Sec-tion 3, is not immediately declared as “faulty”. Instead, the process is declared as “suspected”, and this information spread through the group using the Dissemination Compo-nent. After a prespecified time-out (we discuss values for this parameter in Section 5), the suspected process is de-clared as “faulty” and this information disseminated to the group. However, if the suspected process responds to a ping request before this time-out expires, information about this is disseminated to the group as an “alive” message. The process is then rejuvenated in membership lists at different members without ever having to leave or rejoin the group. This prespecified time-out thus effectively trades off an in-crease in failure detection time for a reduction in frequency of false failure detections.
  
The basic SWIM failure detection protocol guarantees eventual detection of the failure of an arbitrary process  , at each non-faulty group member  . However, it gives no deterministic guarantees on the time between failure of an arbitrary member  and its detection at another arbi-trary member  (in terms of the number of local proto-col rounds at  ). Section 4.3 describes a modification to the original SWIM failure detector protocol that guarantees such a Time Bounded Completeness property; the time in-terval between the occurrence of a failure and its detection at member  is no more than two times the group size (in number of protocol periods).  -->



<h3>Round-Robin Probe Target Selection</h3>

<ul>
  <li>
    The failure detector protocol detects failures in an average constant number of protocol periods.
  </li>
  <li>
    Although each process failure is guaranteed to be detected eventually at every other non-faulty process (eventual strong completeness), a pathological selection of PING targets across the group might lead to a large delay in the first detection of the process failure anywhere in the group.
  </li>
  <li>
    In the extreme case, this delay could be unbounded as the failed process might never be chosen as a PING target by any other non-faulty process.
  </li>
  <li>
    This can be solved modifying the failure detection component at member M_i to select PING targets from the current membership list in a round-robin fashion.
  </li>
  <li>
    A newly joining member is inserted in the membership list at a position that is chosen uniformly at random.
  </li>
  <li>
    On completing a traversal of the entire list, M_i rearranges the membership list to a random reordering.
  </li>
  <li>
    This way, once another member M_j is included in the local membership list at M_i, it will be chosen as a PING target exactly once during each traversal of the membership list.
  </li>
  <li>
    This bounds the worst case detection time of a process failure of any member by M_i while preserving the average failure detection time of the original protocol since the randomization of the membership lists at different members across the group leads to a similar distribution of PING target choices by each member.
  </li>
</ul>



<h3>Performance</h3>

<!-- 
PERFORMANCE

Membership changes have to be propagated within the group quickly after their occurrence.

The asynchrony and unreliability of the underlying network can cause messages to be lost, leading to false detection of process failures, since a process that is losing messages is indistinguishable from one that has failed. This rate of false positives has to be low.

Finally, the protocol needs to be peer-to-peer, and impose low message and computation loads on the network and processes.

... the SWIM project to implement a membership sub-system that provides stable failure detection time, stable rate of false positives and low message load per group member...


Mathematical analysis showed that as the group size is scaled up, the protocol’s properties of (expected) failure detection time, rate of false positives, and message load per member, are all independent of the group size.


---

Both the expected time to first detection of each process failure and the expected message load per member, do not vary with group size.

Our system, called SWIM, provides a membership substrate that:

(1) imposes a constant message load per group member;

(2) detects a process failure in an (expected) constant time at some non-faulty process in the group; (3) provides a deterministic bound (as a function of group size) on the local time that a non-faulty process takes to detect failure of another process;

(4) propagates membership updates, including information about failures, in infection-style (also gossip-style or epidemic-style); the dissemination latency in the group grows slowly (logarithmically) with the number of members;

(5) provides a mechanism to reduce the rate of false positives by “suspecting” a process before “declaring” it as failed within the group.


Finally, the protocol guarantees a deterministic time bound to detect failures. -->



<h3>Resources</h3>

<ul>
  <li>
    <a href=""></a>
  </li>
  <li>
    <a href="https://www.youtube.com/watch?v=bkmbWsDz8LM">Papers We Love: SWIM</a>
  </li>
</ul>

<!--
  https://www.brianstorti.com/swim/

  https://asafdav2.github.io/2017/swim-protocol/

  https://github.com/clockworksoul/smudge

  https://apple.github.io/swift-cluster-membership/docs/current/SWIM/Enums/SWIM.html

  https://blog.kevingomez.fr/2019/01/29/clusters-and-membership-discovering-the-swim-protocol/

  https://www.serf.io/docs/internals/simulator.html
-->


<!-- 
- Strong Completeness: crash-failure of any group member is detected by all non-faulty members ;
- Speed of failure detection: the time interval between a member failure and its detection by some non-faulty group member ;
- Accuracy: the rate of false positives of failure detection (note: 100% accuracy is impossible on asynchronous networks) ;
- Network Message Load, in bytes per second generated by the protocol.
-->

<!-- 
- Strong Completeness: as each node randomly selects at each protocol period a node to check, all nodes will eventually be checked and all faulty-nodes will be detected ;
- Speed of failure detection: the expected time between a failure of a node and its detection by some other node is at most T’ * (1 / (1 - e^Qf)), where Qf is the fraction of non-faulty nodes in the cluster and T’ is the protocol period (in time units, should be at least three times the round-trip estimate) ;
- False positives: the probability of direct or indirect probes being lost is (gross approximation here, the real equation is a bit larger) (1 - Delivery%²)*(1 - Delivery%⁴)^k — where Delivery_% is the probability of timely delivery of a packet and k is the number of members used to perform indirect probing). Notice how k is used as an exponent? It shows that increasing the number of nodes used for indirect probing will rapidly decrease the probability of having false positives ;
- Accuracy: as the accuracy is directly correlated to the false positives, we can calculate that with 95% of the packets successfully delivered and 3 nodes used for indirect probing, the protocol will have an accuracy of 99.9%. Again, this value increases as we increase k ;
- Network Message Load: as each node only pings one target each protocol period, we moved from an O(N²) to something in O(N). We roughly have two packets (PING and ACK) and an optional indirect probe (hence the 4 extra packets per relay node) (4*k + 2)*N.

Important: the speed of failure detection and the probability of false positives don’t depend on the number of nodes in the cluster (except asymptotically). Which means that the protocol will scale nicely, even on large clusters.
 -->


A more robust and efficient SWIM
The version of the SWIM protocol we described so far could be qualified as « basic SWIM ». It works and showcases the main ideas of the protocol, but it suffers from a few issues and limitations:

the dissemination component still relies on network multicasts. However, network multicast primitives such as IP multicast etc., are only best-effort and most of the time they aren’t even enabled on production systems ;
the failure detector doesn’t handle well nodes that are perturbed for small durations of time (overloaded host, unexpectedly long GC pause, …) ;
the basic SWIM failure detection protocol guarantees eventual detection of the failure of an arbitrary node. However, it gives no deterministic guarantees on the time between failure of an arbitrary node and its detection at another arbitrary member (in terms of the number of local protocol rounds).
Let’s dig in these limitations to better understand them and see what can be done to go around.

Infection-style dissemination
The basic protocol propagates membership updates (joins, leaves and failures) through the cluster using multicast primitives. Hardware multicast and IP multicast are available on most networks and operating systems, but are rarely enabled (for administrative or security reasons). The basic SWIM protocol would then have to use a costly broadcast, or an inefficient point-to-point messaging scheme, in order to disseminate the membership updates.

Furthermore, this type of multicast usually uses UDP and is a best-effort protocol. Reliably maintaining the memberlist would prove challenging.

Instead of multicast, the authors of the SWIM protocol suggested a different approach, eliminating the need for multicast altogether: piggybacking.

They took advantage of the fact that the protocol regularly sends messages to other nodes (PING, PING-REQ(), ACK) so they decided to include “gossip information” in these packets. This dissemination mechanism is called “infection-style”, as information spreads in a manner analogous to the spread of gossip in society, or epidemic in the general population.

Notice that this implementation of the dissemination component does not generate any extra packets (such as multicasts) - all “messages” handed to this component are propagated by piggybacking on the packets of the failure detection component. The network load remains the same as seen previously.

In the following example, we see how piggybacking can be used to disseminate information:

A knows that C is dead ;
D knows that E joined the cluster ;
A directly probes B and includes a gossip indicating that C should be considered as failed. B acknowledges and updates its own memberlist to remove C ;
A directly probes D and also indicates that C is dead. D acknowledges and piggybacks the ACK packet to indicate that a new node E has joined the cluster.

SWIM: infection-style dissemination
Infection-style dissemination implies that members of the cluster might have a different memberlist status as information takes more time to propagate. But it has been shown that such epidemic process spreads exponentially fast and all the nodes in the cluster will eventually (and rapidly) receive the gossips (it takes O(log(N)) time to reach every node).

To improve resiliency in case of nodes failures and packet losses, each node has its own prioritized list of “gossips” to disseminate. And each packet sent by the protocol can be used to piggyback a fixed amount of gossips.


Suspicion mechanism

It works as follows. Consider a node A that chooses another node B as ping target. If A receives no direct or indirect ACK from B, it does NOT declare it dead. Instead, it marks the unresponsive node as suspected in its local memberlist and it transfers this update to the dissemination component. Each node receiving the update also updates its local memberlist and keeps on disseminating the update.

That being said, suspected members do stay on the memberlists and are treated similarly to healthy members.

If any node receives an ACK from a suspected node, it un-suspects the node and disseminate the information. Similarly, if a node receive a gossip indicating that it is suspected, it can start propagating a “hey, I’m alive!” message to clarify the situation.

After a predefined timeout, suspected nodes are marked as dead and the information is propagated.

This mechanism reduces (but does not eliminate) the rate of failure detection false positives. Notice also that the Strong Completeness property of the original protocol continues to hold. Failures of processes suspecting a failed process may prolong detection time, but eventual detection is still guaranteed.

From the above discussion, Alive messages override Suspect messages, and Confirm messages override both Suspect and Alive messages, in their effect on the local membership list element corresponding to the suspected member.

However, a member might be suspected and unsuspected multiple times during its lifetime. And as no ordering of the event between the nodes is guaranteed, the following situation might happen:


Two nodes, receiving ambiguous updates
What’s the status of C? Which node is right? Without any additional information, A believes that C is alive whereas B believes it’s suspected.

To resolve this ambiguity, the updates need to be distinguished through unique identifiers: an incarnation number. Each node will maintain its own incarnation number. It’s number set to 0 when the node joins the cluster and can be incremented only by the node itself, when it receives information about itself being suspected in the current incarnation. The suspected node will then emit an Alive message with an incremented incarnation number and disseminate it.

The incarnation number must be included, along a node identifier, in every Alive, Suspect and Confirm messages. This number will be used to establish an “happens-before” relationship between events. For instance:


Two nodes, receiving unambiguous updates
receiving the message { Alive C, incarnation = 1 } would override the message { Suspect C, incarnation = 0 } as the incarnation number of the suspected C node is less than the alive C node.
on the other hand, the message { Alive C, incarnation = 1 } would not be overridden by { Suspect C, incarnation = 0 }
By comparing incarnation numbers, we can safely drop outdated messages and still end-up in a coherent state across the cluster.

Deterministic probe-target selection
In the first version of the protocol, the failure detector component chooses randomly the node to probe. Although each node failure is guaranteed to be detected eventually, a specially unlucky selection of nodes can lead to an important delay between the failure and its detection.

This can be fixed by using a round-robin selection instead of a random one. Joining nodes will be inserted in the member-list at random positions and when the list traversal is complete, it is randomly rearranged before being traversed again.

With this method, successive selections of the same target are at most (2n - 1) protocol periods apart. This bounds the worst case detection time of a node failure.




