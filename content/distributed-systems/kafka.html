---
title: "Apache Kafka"
date: 2022-03-06
draft: false
---

<!-- #region introduction -->
<ul>
  <li>
    Apache Kafka is an event streaming platform used to collect, store and process real-time data streams at scale.
  </li>
  <li>
    Applications called producers publish messages to categories called topics.
  </li>
  <li>
    Kafka durably persists these messages in append-only ordered logs called partitions. 
  </li>
  <li>
    Consumers subscribe to topics and read the messages. Producers and consumers are decoupled so components can be added and removed as business needs evolve.
  </li>
  <li>
    As messages are pushed to the broker from producers and pulled from the broker by consumers, a consumer can simply catch up when it is able to should it fall behind.
  </li>
  <li>
    Kafka replicates and distributes data among a cluster of brokers to provide redundancy and scalability.
  </li>
</ul>
<!-- #endregion -->

<h3>Concepts</h3>


A single Kafka server is called a broker. The broker receives messages from producers,
assigns offsets to them, and writes the messages to storage on disk. It also services
consumers, responding to fetch requests for partitions and responding with the
messages that have been published. Depending on the specific hardware and its per‐
formance characteristics, a single broker can easily handle thousands of partitions
and millions of messages per second.
Kafka brokers are designed to operate as part of a cluster. Within a cluster of brokers,
one broker will also function as the cluster controller (elected automatically from the
live members of the cluster). The controller is responsible for administrative opera‐
tions, including assigning partitions to brokers and monitoring for broker failures. A
partition is owned by a single broker in the cluster, and that broker is called the leader
of the partition. A replicated partition (as seen in Figure 1-7) is assigned to additional
brokers, called followers of the partition. Replication provides redundancy of mes‐
sages in the partition, such that one of the followers can take over leadership if there
is a broker failure. All producers must connect to the leader in order to publish mes‐
sages, but consumers may fetch from either the leader or one of the followers. Cluster
operations, including partition replication, are covered in detail in Chapter 7.





<h4>Brokers</h4>

<ul>
  <li>
    A single Kafka server is called a broker. Every broker has a unique identifier that is either set in the broker configuration file or automatically generated.
  </li>
  <li>
    Brokers receive messages from producers, assign offsets to them and commit them to disk.
  </li>
  <li>
    Brokers also service consumers by responding with the messages that have been committed to disk.
  </li>
</ul>


<h4>Clusters</h4>

<ul>
  <li>
    Kafka is designed to operate as a cluster of multiple brokers running on separate servers.
  </li>
  <li>
    Within a cluster of brokers, one live broker will be automatically elected as the cluster controller.
  </li>
  <li>
    The controller is responsible for administrative operations including assigning partitions to brokers, monitoring for broker failures and electing partition leaders.
  </li>
  <li>
    Kafka uses ZooKeeper for storing certain broker metadata including the list of brokers that are currently members of the cluster.
  </li>
  <li>
    The MirrorMaker tool can be used for replicating data across multiple Kafka clusters.
  </li>
</ul>


<h4>Messages</h4>

<ul>
  <li>
    The unit of data in Kafka is called a message. Each message has a value and timestamp as well as an optional key and optional metadata headers.
  </li>
  <li>
    As far as Kafka is concerned, both values and keys are arbitrary byte arrays so they do not need to have any particular format.
  </li>
  <li>
    Messages are immutable and are persisted to disk in append-only ordered sequences called logs.
  </li>
  <li>
    Using well-defined schemas stored in a common repository allows writing and reading messages to be decoupled as the messages can be understood without coordination.
  </li>
</ul>


<h4>Batching</h4>

<ul>
  <li>
    Messages produced to the same partition of a topic are written in collections called batches for efficiency.
  </li>
  <li>
    The larger the batches, the more messages that can be handled per unit of time, but the longer it takes an individual message to propagate. This presents a tradeoff between latency and throughout.
  </li>
  <li>
    Batches are also typically compressed to allow for more efficient data transfer and storage at the cost of some processing power.
  </li>
  <li>
    Kafka supports various compression protocols (e.g. GZIP, Snappy, LZ4 and ZStandard).
  </li>
</ul>


<h4>Topics</h4>

<ul>
  <li>
    Messages in Kafka are organized and durably stored in named collections called topics.
  </li>
  <li>
    Producers publish messages to topics and consumers subscribe to topics to consume messages from them.
  </li>
  <li>
    The term "stream" is used to refer to a single topic of data, regardless of the number of partitions.
  </li>
</ul>

<!-- 
  Topic	Topics are used to organize data. You always read and write to and from a particular topic
 -->


<h4>Partitions</h4>

<ul>
  <li>
    Topics are divided into a number of immutable logs called partitions.
  </li>
  <li>
    Messages are written to a partition in an append-only fashion and are read in order from beginning to end.
  </li>
  <li>
    Each message in a partition is assigned a unique sequential integer called an offset which identifies its position in the log.
  </li>
  <li>
    Message ordering is guaranteed within a single partition but not across the partitions of a topic.
  </li>
  <li>
    It is possible to increase the number of partitions for a topic though this can be difficult for topics that are produced with keyed messages because the mapping of keys to partitions will change.
  </li>
  <li>
    It is not possible to reduce the number of partitions for a topic as this would cause part of the data in that topic to be deleted. Instead, you will need to delete the topic and recreate it.
  </li>
</ul>


<h4>Replication</h4>

<ul>
  <li>
    Each partition can be hosted on a different broker which allows a
    single topic to be scaled horizontally for improved performance.
  </li>
  <li>
    Partitions can also be replicated such that different brokers store a copy of the same partition which allows for failover should a broker become unavailable.
  </li>
  <li>
    The number of replicas is called the replication factor of the topic.
  </li>
</ul>


<h4>Leaders</h4>

<ul>
  <li>
    Among the replicas of a partition, one is designated as the leader while the others are followers.
  </li>
  <li>
    In order to guarantee consistency, all reads and writes go through the leader while followers try to stay up-to-date with the leader.
  </li>
  <li>
    Kafka requires that new leaders are elected from the subset of replicas that are caught up with the log of the previous leader.
  </li>
  <li>
    The leader for every partition tracks this in-sync replica list by computing the lag of every replica from itself and removes replicas when they fall sufficiently behind.
  </li>
  <li>
    A message written to the leader is considered committed once it has been successfully replicated to all the in-sync replicas. Only committed message are available to be read by consumers.
  </li>
</ul>


<h4>Unclean Elections</h4>

<ul>
  <li>
    Messages that are committed will not be lost as long as at least one replica remains in-sync. If all the replicas fall out out of sync or fail then this guarantee no longer holds.
  </li>
  <li>
    There are two options should all the replicas fail:

    <ol>
      <li>
        1. Wait for a replica in the ISR to come back to life and choose this replica as the leader.
      </li>
      <li>
        2. Choose the first replica that comes back to life as the leader.
      </li>
    </ol>
  </li>
  <li>
    If we wait for replicas in the ISR then we will remain unavailable as long as those replicas are down. If such replicas were destroyed or their data was lost then we are permanently down. 
  </li>
  <li>
    Alternatively, if a non-in-sync replica comes back to life and we allow it to become leader then its log becomes the source of truth even though it is not guaranteed to have every committed message.
  </li>
  <li>
    By default, Kafka chooses the first strategy and favor waiting for a consistent replica. This behavior can be changed using configuration property <code>unclean.leader.election.enable</code> to support use cases where uptime is preferable to consistency.
  </li>
</ul>


<h4>Producers</h4>

<ul>
  <li>
    A producer is an application that creates and writes messages to topics.
  </li>
  <li>
    The <code>acks</code> parameter controls how many partition replicas must receive the message before the producer can consider a write successful. There are three allowed values:
  
    <ul>
      <li>
        <code>acks=0</code>: The producer will not wait for any verification from the broker. This allows for very high throughput at the cost of possible silent message losses.
      </li>
      <li>
        <code>acks=1</code>: The producer will wait for verification that the leader has received the message. The message can still get lost if the leader crashes and a replica without this message gets elected via unclean leader election.
      </li>
      <li>
        <code>acks=all</code>: The producer will wait for verification that all in-sync replicas have received the message. This will ensure a high degree of safety but will result in higher latency.
      </li>
    </ul>
  </li>
  <li>

  </li>
</ul>

<!-- 
  Fire-and-forget: Send a message to the server and don't wait to confirm that it arrives successfully. The producer will retry sending messages automatically but in the case of non-retriable errors or a timeout, message will get lost and the application will not get any information or exceptions about this. This method of sending messages can be used when dropping a message silently is acceptable.

  Synchronous send: Send a message and wait to see if the send was successful or not. Sending a message synchronously is simple but still allows the producer to catch exceptions when Kafka responds to the produce request with an error, or when send retries were exhausted. The main tradeoff involved is performance. If you send messages synchronously, the sending thread will spend this time waiting and doing nothing else.
  
  This method will throw an exception if the record is not sent successfully to Kafka. If there were no errors, we will get a RecordMetadata object that we can use to retrieve the offset the message was written to.

  Asynchronous send: Send a message and trigger a callback when a response is received from the Kafka broker.

  A producer object can be used by multiple threads to send messages.
-->

<!-- 
  A producer partitioner maps each message to a topic partition and the producer sends a produce request to the leader of that partition.

  The default partitioner guarantees that all messages with the same non-empty key will be sent to the same partition.

  If you explicitly set the partition field when creating a ProducerRecord, the default behavior described in this section will be overridden.

  If the key is provided, the partitioner will hash the key with the murmur2 algorithm and divide the result by the number of partitions.

  The result is that the same key is always assigned to the same partition.

  If a key is not provided, behavior is version-dependent:

  In Kafka 2.4 and later, the partition is assigned with awareness to batching. If a batch of records is not full and has not yet been sent to the broker, it will select the same partition as a prior record. Partitions for newly created batches are assigned randomly.

  In versions prior to 2.4, the partition is assigned in a round robin method, starting at a random partition.

  Each partition in the Kafka cluster has a leader and set of replicas among the brokers.
  
  All writes to the partition must go through the partition leader.

  The replicas are kept in sync by fetching from the leader.

  When the leader shuts down or fails, the next leader is chosen from among the in-sync replicas.

  Depending on how the producer is configured, each produce request to the partition leader can be held until the replicas have successfully acknowledged the write. This gives the producer some control over message durability at some cost to overall throughput.

  Messages written to the partition leader are not immediately readable by consumers regardless of the producer’s acknowledgement settings. When all in-sync replicas have acknowledged the write, then the message is considered committed, which makes it available for reading. This ensures that messages cannot be lost by a broker failure after they have already been read. Note that this implies that messages which were acknowledged by the leader only (that is, acks=1) can be lost if the partition leader fails before the replicas have copied the message. Nevertheless, this is often a reasonable compromise in practice to ensure durability in most cases while not impacting throughput too significantly.
-->

<!--
  By default, when acks=all, acknowledgement happens as soon as all the current in-sync replicas have received the message.

  Although this ensures maximum availability of the partition, this behavior may be undesirable to some users who prefer durability over availability.

  Two topic-level configurations can be used to prefer message durability over availability:

  1. Disable unclean leader election - if all replicas become unavailable, then the partition will remain unavailable until the most recent leader becomes available again.

  2. Specify a minimum ISR size - the partition will only accept writes if the size of the ISR is above a certain minimum, in order to prevent the loss of messages that were written to just a single replica, which subsequently becomes unavailable. This setting only takes effect if the producer uses acks=all and guarantees that the message will be acknowledged by at least this many in-sync replicas. This setting offers a trade-off between consistency and availability. A higher setting for minimum ISR size guarantees better consistency since the message is guaranteed to be written to more replicas which reduces the probability that it will be lost. However, it reduces availability since the partition will be unavailable for writes if the number of in-sync replicas drops below the minimum threshold.
-->


<h4>Partitioners</h4>

<ul>
  <li>
    The producer partitioner determines which partition a given message will be written to.
  </li>
  <li>
    By default, messages with the same key will be sent to the same partition provided the number of partitions does not change. This is achieved by calculating the partition number as the hash of the key modulus the total number of partitions in the topic.
  </li>
  <li>
    Messages without keys will be evenly balanced over all the partitions of a topic.
  </li>
  <li>
    Alternatively, the producer could use a custom partitioner or choose precisely which partition to write a given message to.
  </li>
</ul>


<h4>Consumers</h4>

<ul>
  <li>
    A consumer is an application that subscribes to one or more topics and reads the messages in the order in which they were produced.
  </li>
  <li>
    Kafka acts as a buffer allowing producers to write records faster than consumers can read them.
  </li>
</ul>


<h4>Consumer Groups</h4>

<ul>
  <li>
    A consumer typically operates as part of a consumer group that consists of one or more consumers that work together to consume a topic.
  </li>
  <li>
    Each group member reads from zero or more exclusive partitions. This ensures that each partition is consumed by only one consumer.
  </li>
  <li>
    The mapping of partitions to consumers in a group is called partition ownership.
  </li>
  <li>
    By adding more consumers to consumer groups we can horizontally scale topic consumption. However, if there are more consumers in a group than partitions then some consumers will be inactive.
  </li>
</ul>


<h4>Rebalancing</h4>

<ul>
  <li>
    If a consumer becomes unavailable, its partitions will be reassigned to the remaining consumers in its consumer group.
  </li>
  <li>
    Similarly, if a consumer joins a consumer group then it will be assigned partitions previously consumed by other consumers in the consumer group.
  </li>
  <li>
    This movement of partition ownership from one consumer to another is called a rebalance.
  </li>
  <li>
    During a rebalance, consumers can't consume messages, so a rebalance is constitutes a short window of unavailability.
  </li>
  <li>
    When closing a consumer cleanly, we can trigger a rebalance immediately to reduce this period of unavailability.
  </li>
</ul>


<h4>Consumer Offsets</h4>

<ul>
  <li>
    Each consumer keeps track of which messages it has already processed by committing offsets to Kafka.
  </li>
  <li>
    By storing the offset of the last consumed message for each partition, a consumer can stop and restart without losing its place.
  </li>
  <li>
    Additionally, offsets allow consumers to read from different places in the log simultaneously and replay messages as required.
  </li>
  <li>
    If a rebalance occurs and a consumer is assigned a new partition, then the consumer can read the latest committed offsets for that partition and continue from there.
  </li>
  <li>
    However, if the committed offset is smaller than the offset of the last message that was processed then the messages will be processed twice. Similarly, if the committed offset is larger than the offset of the last processed message then messages will be missed.
  </li>
</ul>


<h4>Committing Offsets</h4>

<ul>
  <li>
    Setting <code>enable.auto.commit=true</code> will enable automatic commit so that whenever the consumer polls for messages, it will commit the offsets returned in the last poll if <code>auto.commit.interval.ms</code> has elapsed since its last commit.
  </li>
  <li>
    Using automatic commit is vulnerable to message duplication during rebalancing. Alternatively, configuring <code>auto.commit.offset=false</code> will require the application to explicitly commit offsets.
  </li>
  <li>
    A synchronous commit can be used to commit the latest offset returned by polling and return once the offset is committed. A drawback of synchronous commits is that the application is blocked until the broker responds to the commit request.
  </li>
  <li>

  </li>
</ul>

<p>
   When rebalance is triggered, all the messages from the beginning of the most recent batch until the time of the rebalance will be processed twice.
</p>

<p>
  Another option is to asynchronously commit offsets. The drawback is that while a synchronous commit will retry the commit until it either succeeds or encounters a non-retriable error, an asynchronous commit will not retry. This is to avoid having retried commits overwrite later successful commits.
</p>

<p>
  Normally, occasional failures to commit without retrying are not a huge problem because if the problem is temporary, the following commit will be successful. But if we know that this is the last commit before we close the consumer, or before a rebalance, we want to make extra sure that the commit succeeds. Therefore, a common pattern is to used asynchronous commits and then use a synchronous commit just before shutdown because it will retry until it succeeds or suffers unrecoverable failure.
</p>


<h4>Retention</h4>

<ul>
  <li>
    Kafka can durably store messages for a configurable time period while means that if a consumer falls behind or stops there is no concern about messages backing up on the producer or getting lost.
  </li>
  <li>
    Brokers are configured with a per-topic retention setting, either retaining messages for some period of time or until the topic reaches a certain size in bytes. Once these limits are reached, messages are expired and deleted.
  </li>
  <li>
    The performance of Kafka is effectively constant with respect to data size, so storing data for a long time is perfectly fine.
  </li>
  <li>
    Topics can also be configured as log compacted which means that only the last messaged produced with a specific key will be retained.
  </li>
</ul>

<!-- A partition replica is the unit of storage in Kafka. Partitions cannot be split between multiple brokers and not even between multiple disks on the same broker which limits the size of a partition.  -->



<h4>Delivery Semantics</h4>



<!--
  Recall the following types of message delivery guarantees:

  - At most once: Messages may be lost but are never duplicated.
  - At least once: Messages are never lost but may be duplicated.
  - Exactly once: Each message is delivered once and only once.


  When publishing a message we have a notion of the message being "committed" to the log.

  
-->



The
consumer keeps track of which messages it has already consumed by keeping track of
the offset of messages. The offset—an integer value that continually increases—is
another piece of metadata that Kafka adds to each message as it is produced. Each
message in a given partition has a unique offset, and the following message has a
greater offset (though not necessarily monotonically greater). By storing the next pos‐
sible offset for each partition, typically in Kafka itself, a consumer can stop and
restart without losing its place.
Consumers work as part of a consumer group, which is one or more consumers that
work together to consume a topic. The group ensures that each partition is only con‐
sumed by one member. In Figure 1-6, there are three consumers in a single group
consuming a topic. Two of the consumers are working from one partition each, while
the third consumer is working from two partitions. The mapping of a consumer to a
partition is often called ownership of the partition by the consumer.
In this way, consumers can horizontally scale to consume topics with a large number
of messages. Additionally, if a single consumer fails, the remaining members of the
group will reassign the partitions being consumed to take over for the missing mem‐
ber.



Disk-Based Retention
Not only can Kafka handle multiple consumers, but durable message retention means
that consumers do not always need to work in real time. Messages are written to disk
and will be stored with configurable retention rules. These options can be selected on
a per-topic basis, allowing for different streams of messages to have different amounts
of retention depending on the consumer needs. Durable retention means that if a
consumer falls behind, either due to slow processing or a burst in traffic, there is no
danger of losing data. It also means that maintenance can be performed on consum‐
ers, taking applications offline for a short period of time, with no concern about mes‐
sages backing up on the producer or getting lost. Consumers can be stopped, and the
messages will be retained in Kafka. This allows them to restart and pick up processing
messages where they left off with no data loss.



<h3>Client APIs</h3>

- Client APIs are provided for developing applications that interact with Kafka.
- It is also possible for applications interact with Kafka using its binary wire protocol.



<h4>ZooKeeper</h4>

<ul>
  <li>
    ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services.
  </li>
  <li>
    ZooKeeper is designed to work as a cluster called an ensemble to ensure high availability.
  </li>
  <li>
    It is recommended that ensembles contain an odd number of servers (e.g., 3, 5, etc.) as a majority of ensemble members must be working in order for ZooKeeper to respond to requests.
  </li>
  <li>
    Kafka uses ZooKeeper to store metadata about the cluster.
  </li>
</ul>






<!-- #region installation -->
<h3>Installation</h3>

<h4>Java</h4>

{{% code bash %}}$ java -version
$ export JAVA_HOME=<path>{{% /code %}}


<h4>ZooKeeper</h4>

{{% code bash %}}$ tar -zxf apache-zookeeper-3.7.0-bin.tar.gz
$ mv apache-zookeeper-3.7.0-bin /usr/local/zookeeper
$ cd /usr/local/zookeeper

$ mkdir -p /var/lib/zookeeper
$ cp ./conf/zoo_sample.cfg ./conf/zoo.cfg
$ vim ./conf/zoo.cfg
tickTime=2000
dataDir=/tmp/zookeeper/data
clientPort=2181

$ ./bin/zkServer.sh start ./conf/zoo.cfg
$ telnet localhost 2181
srvr
$ ./bin/zkServer.sh stop{{% /code %}}


{{% code bash %}}
$ tar -zxf kafka_2.13-2.6.0.tgz
$ mv ./kafka_2.13-2.6.0 /usr/local/kafka
$ cd /usr/local/kafka

$ cp ./config/server.properties ./config/server0.properties
$ mkdir -p /tmp/kafka/logs-0
$ vim ./config/server0.properties
broker.id=0
port=9092
log.dir=/tmp/kafka/logs-0

$ cp ./config/server.properties ./config/server1.properties
$ mkdir -p /tmp/kafka/logs-1
$ vim ./config/server1.properties
broker.id=1
port=9093
log.dir=/tmp/kafka/logs-1

$ cp ./config/server.properties ./config/server2.properties
$ mkdir -p /tmp/kafka/logs-2
$ vim ./config/server2.properties
broker.id=2
port=9094
log.dir=/tmp/kafka/logs-2

$ cd /usr/local/kafka
$ ./bin/kafka-server-start.sh -daemon ./config/server0.properties
$ ./bin/kafka-server-start.sh -daemon ./config/server1.properties
$ ./bin/kafka-server-start.sh -daemon ./config/server2.properties

# test kafka
$ lsof -i :9092
$ lsof -i :9093
$ lsof -i :9094

$ ./bin/kafka-topics.sh --create --bootstrap-server :9092 --replication-factor 1 --partitions 1 --topic test
$ ./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
> Hello!
^C
$ ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
^C

# stop kafka
$ cd /usr/local/kafka
$ ./bin/kafka-server-stop.sh

# stop zookeeper
$ cd /usr/local/zookeeper
$ ./bin/zkServer.sh stop



<h4>Kafka</h4>



# tar -zxf kafka_2.13-2.7.0.tgz
# mv kafka_2.13-2.7.0 /usr/local/kafka
# mkdir /tmp/kafka-logs
# /usr/local/kafka/bin/kafka-server-start.sh -daemon
/usr/local/kafka/config/server.properties
#
Once the Kafka broker is started, we can verify that it is working by performing some
simple operations against the cluster: creating a test topic, producing some messages,
and consuming the same messages.
Installing a Kafka Broker | 23
Create and verify a topic:
# /usr/local/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --
create
--replication-factor 1 --partitions 1 --topic test
Created topic "test".
# /usr/local/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092
--describe --topic test
Topic:test PartitionCount:1 ReplicationFactor:1 Configs:
 Topic: test Partition: 0 Leader: 0 Replicas: 0 Isr: 0
#
Produce messages to a test topic (use Ctrl-C to stop the producer at any time):
# /usr/local/kafka/bin/kafka-console-producer.sh --bootstrap-server
localhost:9092 --topic test
Test Message 1
Test Message 2
^C
#
Consume messages from a test topic:
# /usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server
localhost:9092 --topic test --from-beginning
Test Message 1
Test Message 2
^C
Processed a total of 2 messages
#


Conguring the Broker
The example configuration provided with the Kafka distribution is sufficient to run a
standalone server as a proof of concept, but most likely will not be sufficient for large
installations. There are numerous configuration options for Kafka that control all
aspects of setup and tuning. Most of the options can be left at the default settings,
though, as they deal with tuning aspects of the Kafka broker that will not be applica‐
ble until you have a specific use case that requires adjusting these settings.
24 | Chapter 2: Installing Kafka
General Broker Parameters
There are several broker configuration parameters that should be reviewed when
deploying Kafka for any environment other than a standalone broker on a single
server. These parameters deal with the basic configuration of the broker, and most of
them must be changed to run properly in a cluster with other brokers.
broker.id
Every Kafka broker must have an integer identifier, which is set using the broker.id
configuration. By default, this integer is set to 0, but it can be any value. It is essential
that the integer must be unique for each broker within a single Kafka cluster. The
selection of this number is technically arbitrary, and it can be moved between brokers
if necessary for maintenance tasks. However, it is highly recommended to set this
value to something intrinsic to the host so that when performing maintenance it is
not onerous to map broker ID numbers to hosts. For example, if your hostnames
contain a unique number (such as host1.example.com, host2.example.com, etc.),
then 1 and 2 would be good choices for the broker.id values, respectively.
listeners
Older versions of Kafka used a simple port configuration. This can still be used
as a backup for simple configurations but is a deprecated config. The example config‐
uration file starts Kafka with a listener on TCP port 9092. The new listeners config
is a comma-separated list of URIs that we listen on with the listener names. If the lis‐
tener name is not a common security protocol, then another config
listener.security.protocol.map must also be configured. A listener is defined as
<protocol>://<hostname>:<port>. An example of a legal listener config is PLAIN
TEXT://localhost:9092,SSL://:9091. Specifying the hostname as 0.0.0.0 will
bind to all interfaces. Leaving the hostname empty will bind it to the default interface.
Keep in mind that if a port lower than 1024 is chosen, Kafka must be started as root.
Running Kafka as root is not a recommended configuration.
zookeeper.connect
The location of the ZooKeeper used for storing the broker metadata is set using the
zookeeper.connect configuration parameter. The example configuration uses a Zoo‐
Keeper running on port 2181 on the local host, which is specified as localhost:2181.
The format for this parameter is a semicolon-separated list of hostname:port/path
strings, which include:
hostname
The hostname or IP address of the ZooKeeper server.
Conguring the Broker | 25
port
The client port number for the server.
/path
An optional ZooKeeper path to use as a chroot environment for the Kafka clus‐
ter. If it is omitted, the root path is used.
If a chroot path (a path designated to act as the root directory for a given application)
is specified and does not exist, it will be created by the broker when it starts up.
Why Use a Chroot Path?
It is generally considered to be good practice to use a chroot path
for the Kafka cluster. This allows the ZooKeeper ensemble to be
shared with other applications, including other Kafka clusters,
without a conflict. It is also best to specify multiple ZooKeeper
servers (which are all part of the same ensemble) in this configura‐
tion. This allows the Kafka broker to connect to another member
of the ZooKeeper ensemble in the event of server failure.
log.dirs
Kafka persists all messages to disk, and these log segments are stored in the directory
specified in the log.dir configuration. For multiple directories, the config log.dirs
is preferable. If this value is not set, it will default back to log.dir. log.dirs is a
comma-separated list of paths on the local system. If more than one path is specified,
the broker will store partitions on them in a “least-used” fashion, with one partition’s
log segments stored within the same path. Note that the broker will place a new parti‐
tion in the path that has the least number of partitions currently stored in it, not the
least amount of disk space used, so an even distribution of data across multiple direc‐
tories is not guaranteed.
num.recovery.threads.per.data.dir
Kafka uses a configurable pool of threads for handling log segments. Currently, this
thread pool is used:
• When starting normally, to open each partition’s log segments
• When starting after a failure, to check and truncate each partition’s log segments
• When shutting down, to cleanly close log segments
By default, only one thread per log directory is used. As these threads are only used
during startup and shutdown, it is reasonable to set a larger number of threads in
order to parallelize operations. Specifically, when recovering from an unclean shut‐
down, this can mean the difference of several hours when restarting a broker with a
26 | Chapter 2: Installing Kafka
large number of partitions! When setting this parameter, remember that the number
configured is per log directory specified with log.dirs. This means that if num.
recovery.threads.per.data.dir is set to 8, and there are 3 paths specified in
log.dirs, this is a total of 24 threads.
auto.create.topics.enable
The default Kafka configuration specifies that the broker should automatically create
a topic under the following circumstances:
• When a producer starts writing messages to the topic
• When a consumer starts reading messages from the topic
• When any client requests metadata for the topic
In many situations, this can be undesirable behavior, especially as there is no way to
validate the existence of a topic through the Kafka protocol without causing it to be
created. If you are managing topic creation explicitly, whether manually or through a
provisioning system, you can set the auto.create.topics.enable configuration to
false.
auto.leader.rebalance.enable
In order to ensure a Kafka cluster doesn’t become unbalanced by having all topic
leadership on one broker, this config can be specified to ensure leadership is balanced
as much as possible. It enables a background thread that checks the distribution
of partitions at regular intervals (this interval is configurable via leader.
imbalance.check.interval.seconds). If leadership imbalance exceeds another con‐
fig, leader.imbalance.per.broker.percentage, then a rebalance of preferred lead‐
ers for partitions is started.
delete.topic.enable
Depending on your environment and data retention guidelines, you may wish to lock
down a cluster to prevent arbitrary deletions of topics. Disabling topic deletion can
be set by setting this flag to false.
Topic Defaults
The Kafka server configuration specifies many default configurations for topics that
are created. Several of these parameters, including partition counts and message
retention, can be set per topic using the administrative tools (covered in Chapter 12).
The defaults in the server configuration should be set to baseline values that are
appropriate for the majority of the topics in the cluster.
Conguring the Broker | 27
Using Per-Topic Overrides
In older versions of Kafka, it was possible to specify per-topic over‐
rides for these configurations in the broker configuration using the
parameters log.retention.hours.per.topic, log.retention.
bytes.per.topic, and log.segment.bytes.per.topic. These
parameters are no longer supported, and overrides must be speci‐
fied using the administrative tools.
num.partitions
The num.partitions parameter determines how many partitions a new topic is cre‐
ated with, primarily when automatic topic creation is enabled (which is the default
setting). This parameter defaults to one partition. Keep in mind that the number of
partitions for a topic can only be increased, never decreased. This means that if a
topic needs to have fewer partitions than num.partitions, care will need to be taken
to manually create the topic (discussed in Chapter 12).
As described in Chapter 1, partitions are the way a topic is scaled within a Kafka clus‐
ter, which makes it important to use partition counts that will balance the message
load across the entire cluster as brokers are added. Many users will have the partition
count for a topic be equal to, or a multiple of, the number of brokers in the cluster.
This allows the partitions to be evenly distributed to the brokers, which will evenly
distribute the message load. For example, a topic with 10 partitions operating in a
Kafka cluster with 10 hosts with leadership balanced among all 10 hosts will have
optimal throughput. This is not a requirement, however, as you can also balance mes‐
sage load in other ways, such as having multiple topics.
How to Choose the Number of Partitions
There are several factors to consider when choosing the number of partitions:
• What is the throughput you expect to achieve for the topic? For example, do you
expect to write 100 KBps or 1 GBps?
• What is the maximum throughput you expect to achieve when consuming from
a single partition? A partition will always be consumed completely by a single
consumer (even when not using consumer groups, the consumer must read all
messages in the partition). If you know that your slower consumer writes the
data to a database and this database never handles more than 50 MBps from each
thread writing to it, then you know you are limited to 50 MBps throughput when
consuming from a partition.
• You can go through the same exercise to estimate the maximum throughput per
producer for a single partition, but since producers are typically much faster than
consumers, it is usually safe to skip this.
28 | Chapter 2: Installing Kafka
• If you are sending messages to partitions based on keys, adding partitions later
can be very challenging, so calculate throughput based on your expected future
usage, not the current usage.
• Consider the number of partitions you will place on each broker and available
diskspace and network bandwidth per broker.
• Avoid overestimating, as each partition uses memory and other resources on the
broker and will increase the time for metadata updates and leadership transfers.
• Will you be mirroring data? You may need to consider the throughput of your
mirroring configuration as well. Large partitions can become a bottleneck in
many mirroring configurations.
• If you are using cloud services, do you have IOPS (input/output operations per
second) limitations on your VMs or disks? There may be hard caps on the num‐
ber of IOPS allowed depending on your cloud service and VM configuration that
will cause you to hit quotas. Having too many partitions can have the side effect
of increasing the amount of IOPS due to the parallelism involved.
With all this in mind, it’s clear that you want many partitions, but not too many. If
you have some estimate regarding the target throughput of the topic and the expected
throughput of the consumers, you can divide the target throughput by the expected
consumer throughput and derive the number of partitions this way. So if we want to
be able to write and read 1 GBps from a topic, and we know each consumer can only
process 50 MBps, then we know we need at least 20 partitions. This way, we can have
20 consumers reading from the topic and achieve 1 GBps.
If you don’t have this detailed information, our experience suggests that limiting the
size of the partition on the disk to less than 6 GB per day of retention often gives sat‐
isfactory results. Starting small and expanding as needed is easier than starting too
large.
default.replication.factor
If auto-topic creation is enabled, this configuration sets what the replication factor
should be for new topics. Replication strategy can vary depending on the desired
durability or availability of a cluster and will be discussed more in later chapters. The
following is a brief recommendation if you are running Kafka in a cluster that will
prevent outages due to factors outside of Kafka’s internal capabilities, such as hard‐
ware failures.
It is highly recommended to set the replication factor to at least 1 above the
min.insync.replicas setting. For more fault-resistant settings, if you have large
enough clusters and enough hardware, setting your replication factor to 2 above the
min.insync.replicas (abbreviated as RF++) can be preferable. RF++ will allow eas‐
ier maintenance and prevent outages. The reasoning behind this recommendation is
Conguring the Broker | 29
to allow for one planned outage within the replica set and one unplanned outage to
occur simultaneously. For a typical cluster, this would mean you’d have a minimum of
three replicas of every partition. An example of this is if there is a network switch
outage, disk failure, or some other unplanned problem during a rolling deployment
or upgrade of Kafka or the underlying OS, you can be assured there will still be an
additional replica available. This will be discussed more in Chapter 7.
log.retention.ms
The most common configuration for how long Kafka will retain messages is by time.
The default is specified in the configuration file using the log.retention.hours
parameter, and it is set to 168 hours, or one week. However, there are two other
parameters allowed, log.retention.minutes and log.retention.ms. All three of
these control the same goal (the amount of time after which messages may be
deleted), but the recommended parameter to use is log.retention.ms, as the smaller
unit size will take precedence if more than one is specified. This will ensure that the
value set for log.retention.ms is always the one used. If more than one is specified,
the smaller unit size will take precedence.
Retention by Time and Last Modied Times
Retention by time is performed by examining the last modified
time (mtime) on each log segment file on disk. Under normal clus‐
ter operations, this is the time that the log segment was closed, and
represents the timestamp of the last message in the file. However,
when using administrative tools to move partitions between brok‐
ers, this time is not accurate and will result in excess retention for
these partitions. For more information on this, see Chapter 12 dis‐
cussing partition moves.
log.retention.bytes
Another way to expire messages is based on the total number of bytes of messages
retained. This value is set using the log.retention.bytes parameter, and it is
applied per partition. This means that if you have a topic with 8 partitions, and
log.retention.bytes is set to 1 GB, the amount of data retained for the topic will be
8 GB at most. Note that all retention is performed for individual partitions, not the
topic. This means that should the number of partitions for a topic be expanded, the
retention will also increase if log.retention.bytes is used. Setting the value to –1
will allow for infinite retention.
30 | Chapter 2: Installing Kafka
Conguring Retention by Size and Time
If you have specified a value for both log.retention.bytes and
log.retention.ms (or another parameter for retention by time),
messages may be removed when either criteria is met. For example,
if log.retention.ms is set to 86400000 (1 day) and log.
retention.bytes is set to 1000000000 (1 GB), it is possible for
messages that are less than 1 day old to get deleted if the total vol‐
ume of messages over the course of the day is greater than 1 GB.
Conversely, if the volume is less than 1 GB, messages can be deleted
after 1 day even if the total size of the partition is less than 1 GB. It
is recommended, for simplicity, to choose either size- or timebased retention—and not both—to prevent surprises and unwan‐
ted data loss, but both can be used for more advanced
configurations.
log.segment.bytes
The log retention settings previously mentioned operate on log segments, not indi‐
vidual messages. As messages are produced to the Kafka broker, they are appended to
the current log segment for the partition. Once the log segment has reached the size
specified by the log.segment.bytes parameter, which defaults to 1 GB, the log seg‐
ment is closed and a new one is opened. Once a log segment has been closed, it can be
considered for expiration. A smaller log segment size means that files must be closed
and allocated more often, which reduces the overall efficiency of disk writes.
Adjusting the size of the log segments can be important if topics have a low produce
rate. For example, if a topic receives only 100 megabytes per day of messages, and
log.segment.bytes is set to the default, it will take 10 days to fill one segment. As
messages cannot be expired until the log segment is closed, if log.retention.ms is
set to 604800000 (1 week), there will actually be up to 17 days of messages retained
until the closed log segment expires. This is because once the log segment is closed
with the current 10 days of messages, that log segment must be retained for 7 days
before it expires based on the time policy (as the segment cannot be removed until
the last message in the segment can be expired).
Retrieving Offsets by Timestamp
The size of the log segment also affects the behavior of fetching off‐
sets by timestamp. When requesting offsets for a partition at a spe‐
cific timestamp, Kafka finds the log segment file that was being
written at that time. It does this by using the creation and last
modified time of the file, and looking for a file that was created
before the timestamp specified and last modified after the time‐
stamp. The offset at the beginning of that log segment (which is
also the filename) is returned in the response.
Conguring the Broker | 31
log.roll.ms
Another way to control when log segments are closed is by using the log.roll.ms
parameter, which specifies the amount of time after which a log segment should be
closed. As with the log.retention.bytes and log.retention.ms parameters,
log.segment.bytes and log.roll.ms are not mutually exclusive properties. Kafka
will close a log segment either when the size limit is reached or when the time limit is
reached, whichever comes first. By default, there is no setting for log.roll.ms, which
results in only closing log segments by size.
Disk Performance When Using Time-Based Segments
When using a time-based log segment limit, it is important to con‐
sider the impact on disk performance when multiple log segments
are closed simultaneously. This can happen when there are many
partitions that never reach the size limit for log segments, as the
clock for the time limit will start when the broker starts and will
always execute at the same time for these low-volume partitions.
min.insync.replicas
When configuring your cluster for data durability, setting min.insync.replicas to 2
ensures that at least two replicas are caught up and “in sync” with the producer. This
is used in tandem with setting the producer config to ack “all” requests. This will
ensure that at least two replicas (leader and one other) acknowledge a write for it to
be successful. This can prevent data loss in scenarios where the leader acks a write,
then suffers a failure and leadership is transferred to a replica that does not have a
successful write. Without these durable settings, the producer would think it success‐
fully produced, and the message(s) would be dropped on the floor and lost. However,
configuring for higher durability has the side effect of being less efficient due to the
extra overhead involved, so clusters with high-throughput that can tolerate occasional
message loss aren’t recommended to change this setting from the default of 1. See
Chapter 7 for more information.
message.max.bytes
The Kafka broker limits the maximum size of a message that can be produced, con‐
figured by the message.max.bytes parameter, which defaults to 1000000, or 1 MB. A
producer that tries to send a message larger than this will receive an error back from
the broker, and the message will not be accepted. As with all byte sizes specified on
the broker, this configuration deals with compressed message size, which means that
producers can send messages that are much larger than this value uncompressed,
provided they compress to under the configured message.max.bytes size.
32 | Chapter 2: Installing Kafka
There are noticeable performance impacts from increasing the allowable message
size. Larger messages will mean that the broker threads that deal with processing net‐
work connections and requests will be working longer on each request. Larger mes‐
sages also increase the size of disk writes, which will impact I/O throughput. Other
storage solutions, such as blob stores and/or tiered storage, may be another method
of addressing large disk write issues, but will not be covered in this chapter.
Coordinating Message Size Congurations
The message size configured on the Kafka broker must be coordi‐
nated with the fetch.message.max.bytes configuration on con‐
sumer clients. If this value is smaller than message.max.bytes,
then consumers that encounter larger messages will fail to fetch
those messages, resulting in a situation where the consumer gets
stuck and cannot proceed. The same rule applies to the
replica.fetch.max.bytes configuration on the brokers when
configured in a cluster.


<h4>Client</h4>

listeners=PLAINTEXT://localhost:9092
  
$ mvn archetype:generate -DgroupId=com.reissenzahn    
  -DartifactId=kafka-demo
  -DarchetypeArtifactId=maven-archetype-quickstart
  -DinteractiveMode=false


<!-- https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients -->
<dependency>
  <groupId>org.apache.kafka</groupId>
  <artifactId>kafka-clients</artifactId>
  <version>3.1.0</version>
</dependency>
<!-- #endregion -->


Conguring Kafka Clusters

There are two configuration requirements to allow multiple brokers to join a single cluster: 

- All brokers must have the same configuration for the <code>zookeeper.connect</code> parameter which specifies the ZooKeeper ensemble and path where the cluster stores groupMetadata

- All brokers in the cluster must have a unique value for the <code>broker.id</code> parameter.





in older versions of Kafka, con‐
sumers (in addition to the brokers) utilized ZooKeeper to directly
store information about the composition of the consumer group
and what topics it was consuming, and to periodically commit off‐
sets for each partition being consumed (to enable failover between
consumers in the group). With version 0.9.0.0, the consumer inter‐
face was changed, allowing this to be managed directly with the
Kafka brokers. In each 2.x release of Kafka, we see additional steps
to removing ZooKeeper from other required paths of Kafka.




Administration tools now connect directly to the cluster and have
deprecated the need to connect to ZooKeeper directly for opera‐
tions such as topic creations, dynamic configuration changes, etc.
As such, many of the command-line tools that previously used the
--zookeeper flags have been updated to use the --bootstrapserver option.




<h3>Producers</h3>

- To produce a message, we start by creating a <code>ProducerRecord</code> which must specify a value and topic and may optionally include a partition, key, timestamp and headers.
- Once we send the <code>ProducerRecord</code>, the producer will serialize the key and value objects to byte arrays.
- If we did not explicitly specify a partition, the data is sent to a partitioner which will choose a partition.
- The producer then adds the record to a batch of records that will all be sent to the specified topic and partition.
- A separate thread is responsible for sending those batches of records to the appropriate brokers.
- When the broker receives the messages, it sends back a response. If the messages were successfully written, it will return a <code>RecordMetadata</code> object with the topic, partition, and the offset of the record within the partition.
- If the broker failed to write the messages, it will return an error. When the producer receives an error, it may retry sending the message a few more times before giving up and returning an error.




bootstrap.servers: List of host:port pairs of brokers that the producer will use to establish initial connection to the Kafka cluster. This list does not need to include all brokers since
the producer will get more information after the initial connection

key.serializer: Name of a class that will be used to serialize the keys of the records we will produce to Kafka. Should be set to a name of a class that implements the <code>org.apache.kafka.common.serialization.Serializer</code> interface.

The Kafka client package includes ByteArraySerializer (which doesn’t do much), StringSerializer, IntegerSerializer, and much more, so if you use common types, there is no need to implement your own serializers.

value.serializer: Name of a class that will be used to serialize the values of the records we will pro‐
duce to Kafka. The same way you set key.serializer to a name of a class that
will serialize the message key object to a byte array, you set value.serializer to
a class that will serialize the message value object.
The following code snippet shows how to create a new producer by setting just the
mandatory parameters and using defaults for everything else:


Properties kafkaProps = new Properties();

kafkaProps.put("bootstrap.servers", "broker1:9092,broker2:9092");
kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

producer = new KafkaProducer<String, String>(kafkaProps);


Once we instantiate a producer, it is time to start sending messages. There are three primary methods of sending messages:

- Fire-and-forget: We send a message to the server and don’t really care if it arrives successfully or not. Most of the time, it will arrive successfully, since Kafka is highly available
and the producer will retry sending messages automatically. However, in case of
nonretriable errors or timeout, messages will get lost and the application will not
get any information or exceptions about this.

- Synchronous send
Technically, Kafka producer is always asynchronous—we send a message and the
send() method returns a Future object. However, we use get() to wait on the
Future and see if the send() was successful or not before sending the next
record.
Asynchronous send
We call the send() method with a callback function, which gets triggered when it
receives a response from the Kafka broker.
In the examples that follow, we will see how to send messages using these methods
and how to handle the different types of errors that might occur.
While all the examples in this chapter are single threaded, a producer object can be
used by multiple threads to send messages.
Constructing a Kafka Producer | 51
Sending a Message to Kafka
The simplest way to send a message is as follows:
ProducerRecord<String, String> record =
 new ProducerRecord<>("CustomerCountry", "Precision Products",
 "France");
try {
 producer.send(record);
} catch (Exception e) {
 e.printStackTrace();
}
The producer accepts ProducerRecord objects, so we start by creating one.
ProducerRecord has multiple constructors, which we will discuss later. Here we
use one that requires the name of the topic we are sending data to, which is
always a string, and the key and value we are sending to Kafka, which in this case
are also strings. The types of the key and value must match our key serializer
and value serializer objects.
We use the producer object send() method to send the ProducerRecord. As
we’ve seen in the producer architecture diagram in Figure 3-1, the message will
be placed in a buffer and will be sent to the broker in a separate thread. The
send() method returns a Java Future object with RecordMetadata, but since we
simply ignore the returned value, we have no way of knowing whether the mes‐
sage was sent successfully or not. This method of sending messages can be used
when dropping a message silently is acceptable. This is not typically the case in
production applications.
While we ignore errors that may occur while sending messages to Kafka brokers
or in the brokers themselves, we may still get an exception if the producer
encountered errors before sending the message to Kafka. Those can be, for exam‐
ple, a SerializationException when it fails to serialize the message, a Buffer
ExhaustedException or TimeoutException if the buffer is full, or an
InterruptException if the sending thread was interrupted.
Sending a Message Synchronously
Sending a message synchronously is simple but still allows the producer to catch
exceptions when Kafka responds to the produce request with an error, or when send
retries were exhausted. The main trade-off involved is performance. Depending on
how busy the Kafka cluster is, brokers can take anywhere from 2 ms to a few seconds
to respond to produce requests. If you send messages synchronously, the sending
thread will spend this time waiting and doing nothing else, not even sending
additional messages. This leads to very poor performance, and as a result,
52 | Chapter 3: Kafka Producers: Writing Messages to Kafka
synchronous sends are usually not used in production applications (but are very
common in code examples).
The simplest way to send a message synchronously is as follows:
ProducerRecord<String, String> record =
 new ProducerRecord<>("CustomerCountry", "Precision Products", "France");
try {
 producer.send(record).get();
} catch (Exception e) {
 e.printStackTrace();
}
Here, we are using Future.get() to wait for a reply from Kafka. This method
will throw an exception if the record is not sent successfully to Kafka. If there
were no errors, we will get a RecordMetadata object that we can use to retrieve
the offset the message was written to and other metadata.
If there were any errors before or while sending the record to Kafka, we will
encounter an exception. In this case, we just print any exception we ran into.
KafkaProducer has two types of errors. Retriable errors are those that can be resolved
by sending the message again. For example, a connection error can be resolved
because the connection may get reestablished. A “not leader for partition” error can
be resolved when a new leader is elected for the partition and the client metadata is
refreshed. KafkaProducer can be configured to retry those errors automatically, so
the application code will get retriable exceptions only when the number of retries was
exhausted and the error was not resolved. Some errors will not be resolved by retry‐
ing—for example, “Message size too large.” In those cases, KafkaProducer will not
attempt a retry and will return the exception immediately.
Sending a Message Asynchronously
Suppose the network round-trip time between our application and the Kafka cluster
is 10 ms. If we wait for a reply after sending each message, sending 100 messages will
take around 1 second. On the other hand, if we just send all our messages and not
wait for any replies, then sending 100 messages will barely take any time at all. In
most cases, we really don’t need a reply—Kafka sends back the topic, partition, and
offset of the record after it was written, which is usually not required by the sending
app. On the other hand, we do need to know when we failed to send a message com‐
pletely so we can throw an exception, log an error, or perhaps write the message to an
“errors” file for later analysis.
To send messages asynchronously and still handle error scenarios, the producer sup‐
ports adding a callback when sending a record. Here is an example of how we use a
callback:
Sending a Message to Kafka | 53
private class DemoProducerCallback implements Callback {
 @Override
 public void onCompletion(RecordMetadata recordMetadata, Exception e) {
 if (e != null) {
 e.printStackTrace();
 }
 }
}
ProducerRecord<String, String> record =
 new ProducerRecord<>("CustomerCountry", "Biomedical Materials", "USA");
producer.send(record, new DemoProducerCallback());
To use callbacks, you need a class that implements the org.apache.kafka.
clients.producer.Callback interface, which has a single function—on
Completion().
If Kafka returned an error, onCompletion() will have a nonnull exception. Here
we “handle” it by printing, but production code will probably have more robust
error handling functions.
The records are the same as before.
And we pass a Callback object along when sending the record.
The callbacks execute in the producer’s main thread. This guaran‐
tees that when we send two messages to the same partition one
after another, their callbacks will be executed in the same order that
we sent them. But it also means that the callback should be reason‐
ably fast to avoid delaying the producer and preventing other mes‐
sages from being sent. It is not recommended to perform a
blocking operation within the callback. Instead, you should use
another thread to perform any blocking operation concurrently.
Conguring Producers
So far we’ve seen very few configuration parameters for the producers—just the
mandatory bootstrap.servers URI and serializers.
The producer has a large number of configuration parameters that are documented
in Apache Kafka documentation, and many have reasonable defaults, so there is no
reason to tinker with every single parameter. However, some of the parameters have a
significant impact on memory use, performance, and reliability of the producers. We
will review those here.
54 | Chapter 3: Kafka Producers: Writing Messages to Kafka
client.id
client.id is a logical identifier for the client and the application it is used in. This
can be any string and will be used by the brokers to identify messages sent from the
client. It is used in logging and metrics and for quotas. Choosing a good client name
will make troubleshooting much easier—it is the difference between “We are seeing a
high rate of authentication failures from IP 104.27.155.134” and “Looks like the
Order Validation service is failing to authenticate—can you ask Laura to take a look?”
acks
The acks parameter controls how many partition replicas must receive the record
before the producer can consider the write successful. By default, Kafka will respond
that the record was written successfully after the leader received the record (release
3.0 of Apache Kafka is expected to change this default). This option has a significant
impact on the durability of written messages, and depending on your use case, the
default may not be the best choice. Chapter 7 discusses Kafka’s reliability guarantees
in depth, but for now let’s review the three allowed values for the acks parameter:
acks=0
The producer will not wait for a reply from the broker before assuming the mes‐
sage was sent successfully. This means that if something goes wrong and the
broker does not receive the message, the producer will not know about it, and the
message will be lost. However, because the producer is not waiting for any
response from the server, it can send messages as fast as the network will support,
so this setting can be used to achieve very high throughput.
acks=1
The producer will receive a success response from the broker the moment the
leader replica receives the message. If the message can’t be written to the leader
(e.g., if the leader crashed and a new leader was not elected yet), the producer will
receive an error response and can retry sending the message, avoiding potential
loss of data. The message can still get lost if the leader crashes and the latest mes‐
sages were not yet replicated to the new leader.
acks=all
The producer will receive a success response from the broker once all in sync
replicas receive the message. This is the safest mode since you can make sure
more than one broker has the message and that the message will survive even in
case of a crash (more information on this in Chapter 6). However, the latency we
discussed in the acks=1 case will be even higher, since we will be waiting for
more than just one broker to receive the message.
Conguring Producers | 55
1 Image contributed to the Apache Kafka project by Sumant Tambe under the ASLv2 license terms.
You will see that with lower and less reliable acks configuration,
the producer will be able to send records faster. This means that
you trade off reliability for producer latency. However, end-to-end
latency is measured from the time a record was produced until it is
available for consumers to read and is identical for all three
options. The reason is that, in order to maintain consistency, Kafka
will not allow consumers to read records until they are written to
all in sync replicas. Therefore, if you care about end-to-end latency,
rather than just the producer latency, there is no trade-off to make:
you will get the same end-to-end latency if you choose the most
reliable option.
Message Delivery Time
The producer has multiple configuration parameters that interact to control one of
the behaviors that are of most interest to developers: how long will it take until a call
to send() will succeed or fail. This is the time we are willing to spend until Kafka
responds successfully, or until we are willing to give up and admit defeat.
The configurations and their behaviors were modified several times over the years.
We will describe here the latest implementation, introduced in Apache Kafka 2.1.
Since Apache Kafka 2.1, we divide the time spent sending a ProduceRecord into two
time intervals that are handled separately:
• Time until an async call to send() returns. During this interval, the thread that
called send() will be blocked.
• From the time an async call to send() returned successfully until the callback is
triggered (with success or failure). This is the same as from the point a ProduceConstructing a Kafka Producer

Record was placed in a batch for sending until Kafka responds with success, non‐
retriable failure, or we run out of time allocated for sending.
If you use send() synchronously, the sending thread will block for
both time intervals continuously, and you won’t be able to tell how
much time was spent in each. We’ll discuss the common and rec‐
ommended case, where send() is used asynchronously, with a
callback.
The flow of data within the producer and how the different configuration parameters
affect each other can be summarized in Figure 3-2.
1
56 | Chapter 3: Kafka Producers: Writing Messages to Kafka
Figure 3-2. Sequence diagram of delivery time breakdown inside Kafka producer
We’ll go through the different configuration parameters used to control the time
spent waiting in these two intervals and how they interact.
max.block.ms
This parameter controls how long the producer may block when calling send() and
when explicitly requesting metadata via partitionsFor(). Those methods may block
when the producer’s send buffer is full or when metadata is not available. When
max.block.ms is reached, a timeout exception is thrown.
delivery.timeout.ms
This configuration will limit the amount of time spent from the point a record is
ready for sending (send() returned successfully and the record is placed in a batch)
until either the broker responds or the client gives up, including time spent on retries.
As you can see in Figure 3-2, this time should be greater than linger.ms and
request.timeout.ms. If you try to create a producer with an inconsistent timeout
configuration, you will get an exception. Messages can be successfully sent much
faster than delivery.timeout.ms, and typically will.
If the producer exceeds delivery.timeout.ms while retrying, the callback will be
called with the exception that corresponds to the error that the broker returned
before retrying. If delivery.timeout.ms is exceeded while the record batch was still
waiting to be sent, the callback will be called with a timeout exception.
Conguring Producers | 57
You can configure the delivery timeout to the maximum time you’ll
want to wait for a message to be sent, typically a few minutes, and
then leave the default number of retries (virtually infinite). With
this configuration, the producer will keep retrying for as long as it
has time to keep trying (or until it succeeds). This is a much more
reasonable way to think about retries. Our normal process for tun‐
ing retries is: “In case of a broker crash, it typically takes leader
election 30 seconds to complete, so let’s keep retrying for 120 sec‐
onds just to be on the safe side.” Instead of converting this mental
dialog to number of retries and time between retries, you just con‐
figure deliver.timeout.ms to 120.
request.timeout.ms
This parameter controls how long the producer will wait for a reply from the server
when sending data. Note that this is the time spent waiting on each producer request
before giving up; it does not include retries, time spent before sending, and so on. If
the timeout is reached without reply, the producer will either retry sending or com‐
plete the callback with a TimeoutException.
retries and retry.backoff.ms
When the producer receives an error message from the server, the error could be
transient (e.g., a lack of leader for a partition). In this case, the value of the retries
parameter will control how many times the producer will retry sending the message
before giving up and notifying the client of an issue. By default, the producer will wait
100 ms between retries, but you can control this using the retry.backoff.ms
parameter.
We recommend against using these parameters in the current version of Kafka.
Instead, test how long it takes to recover from a crashed broker (i.e., how long until
all partitions get new leaders), and set delivery.timeout.ms such that the total
amount of time spent retrying will be longer than the time it takes the Kafka cluster
to recover from the crash—otherwise, the producer will give up too soon.
Not all errors will be retried by the producer. Some errors are not transient and will
not cause retries (e.g., “message too large” error). In general, because the producer
handles retries for you, there is no point in handling retries within your own applica‐
tion logic. You will want to focus your efforts on handling nonretriable errors or cases
where retry attempts were exhausted.
If you want to completely disable retries, setting retries=0 is the
only way to do so.
58 | Chapter 3: Kafka Producers: Writing Messages to Kafka
linger.ms
linger.ms controls the amount of time to wait for additional messages before send‐
ing the current batch. KafkaProducer sends a batch of messages either when the cur‐
rent batch is full or when the linger.ms limit is reached. By default, the producer will
send messages as soon as there is a sender thread available to send them, even if
there’s just one message in the batch. By setting linger.ms higher than 0, we instruct
the producer to wait a few milliseconds to add additional messages to the batch
before sending it to the brokers. This increases latency a little and significantly
increases throughput—the overhead per message is much lower, and compression, if
enabled, is much better.
buffer.memory
This config sets the amount of memory the producer will use to buffer messages wait‐
ing to be sent to brokers. If messages are sent by the application faster than they can
be delivered to the server, the producer may run out of space, and additional send()
calls will block for max.block.ms and wait for space to free up before throwing an
exception. Note that unlike most producer exceptions, this timeout is thrown by
send() and not by the resulting Future.
compression.type
By default, messages are sent uncompressed. This parameter can be set to snappy,
gzip, lz4, or zstd, in which case the corresponding compression algorithms will be
used to compress the data before sending it to the brokers. Snappy compression was
invented by Google to provide decent compression ratios with low CPU overhead
and good performance, so it is recommended in cases where both performance and
bandwidth are a concern. Gzip compression will typically use more CPU and time
but results in better compression ratios, so it is recommended in cases where network
bandwidth is more restricted. By enabling compression, you reduce network utiliza‐
tion and storage, which is often a bottleneck when sending messages to Kafka.
batch.size
When multiple records are sent to the same partition, the producer will batch them
together. This parameter controls the amount of memory in bytes (not messages!)
that will be used for each batch. When the batch is full, all the messages in the batch
will be sent. However, this does not mean that the producer will wait for the batch to
become full. The producer will send half-full batches and even batches with just a sin‐
gle message in them. Therefore, setting the batch size too large will not cause delays
in sending messages; it will just use more memory for the batches. Setting the batch
Conguring Producers | 59
size too small will add some overhead because the producer will need to send mes‐
sages more frequently.
max.in.flight.requests.per.connection
This controls how many message batches the producer will send to the server without
receiving responses. Higher settings can increase memory usage while improving
throughput. Apache’s wiki experiments show that in a single-DC environment, the
throughput is maximized with only 2 in-flight requests; however, the default value is
5 and shows similar performance.
Ordering Guarantees
Apache Kafka preserves the order of messages within a partition.
This means that if messages are sent from the producer in a specific
order, the broker will write them to a partition in that order and all
consumers will read them in that order. For some use cases, order
is very important. There is a big difference between depositing
$100 in an account and later withdrawing it, and the other way
around! However, some use cases are less sensitive.
Setting the retries parameter to nonzero and the max.in.
flight.requests.per.connection to more than 1 means that it is
possible that the broker will fail to write the first batch of messages,
succeed in writing the second (which was already in-flight), and
then retry the first batch and succeed, thereby reversing the order.
Since we want at least two in-flight requests for performance rea‐
sons, and a high number of retries for reliability reasons, the best
solution is to set enable.idempotence=true. This guarantees mes‐
sage ordering with up to five in-flight requests and also guarantees
that retries will not introduce duplicates. Chapter 8 discusses the
idempotent producer in depth.
max.request.size
This setting controls the size of a produce request sent by the producer. It caps both
the size of the largest message that can be sent and the number of messages that the
producer can send in one request. For example, with a default maximum request size
of 1 MB, the largest message you can send is 1 MB, or the producer can batch 1,024
messages of size 1 KB each into one request. In addition, the broker has its own limit
on the size of the largest message it will accept (message.max.bytes). It is usually a
good idea to have these configurations match, so the producer will not attempt to
send messages of a size that will be rejected by the broker.
60 | Chapter 3: Kafka Producers: Writing Messages to Kafka
receive.buffer.bytes and send.buffer.bytes
These are the sizes of the TCP send and receive buffers used by the sockets when
writing and reading data. If these are set to –1, the OS defaults will be used. It is a
good idea to increase these when producers or consumers communicate with brokers
in a different datacenter, because those network links typically have higher latency
and lower bandwidth.
enable.idempotence
Starting in version 0.11, Kafka supports exactly once semantics. Exactly once is a fairly
large topic, and we’ll dedicate an entire chapter to it, but idempotent producer is a
simple and highly beneficial part of it.
Suppose you configure your producer to maximize reliability: acks=all and a
decently large delivery.timeout.ms to allow sufficient retries. These make sure each
message will be written to Kafka at least once. In some cases, this means that mes‐
sages will be written to Kafka more than once. For example, imagine that a broker
received a record from the producer, wrote it to local disk, and the record was suc‐
cessfully replicated to other brokers, but then the first broker crashed before sending
a response to the producer. The producer will wait until it reaches request.
timeout.ms and then retry. The retry will go to the new leader that already has a copy
of this record since the previous write was replicated successfully. You now have a
duplicate record.
To avoid this, you can set enable.idempotence=true. When the idempotent pro‐
ducer is enabled, the producer will attach a sequence number to each record it sends.
If the broker receives records with the same sequence number, it will reject the sec‐
ond copy and the producer will receive the harmless DuplicateSequenceException.
Enabling idempotence requires max.in.flight.requests.per.
connection to be less than or equal to 5, retries to be greater than
0, and acks=all. If incompatible values are set, a ConfigException
will be thrown.
Serializers
As seen in previous examples, producer configuration includes mandatory serializers.
We’ve seen how to use the default String serializer. Kafka also includes serializers for
integers, ByteArrays, and many more, but this does not cover most use cases. Even‐
tually, you will want to be able to serialize more generic records.
We will start by showing how to write your own serializer and then introduce the
Avro serializer as a recommended alternative.
Serializers | 61
Custom Serializers
When the object you need to send to Kafka is not a simple string or integer, you have
a choice of either using a generic serialization library like Avro, Thrift, or Protobuf to
create records, or creating a custom serialization for objects you are already using. We
highly recommend using a generic serialization library. In order to understand how
the serializers work and why it is a good idea to use a serialization library, let’s see
what it takes to write your own custom serializer.
Suppose that instead of recording just the customer name, you create a simple class to
represent customers:
public class Customer {
 private int customerID;
 private String customerName;
 public Customer(int ID, String name) {
 this.customerID = ID;
 this.customerName = name;
 }
 public int getID() {
 return customerID;
 }
 public String getName() {
 return customerName;
 }
}
Now suppose we want to create a custom serializer for this class. It will look some‐
thing like this:
import org.apache.kafka.common.errors.SerializationException;
import java.nio.ByteBuffer;
import java.util.Map;
public class CustomerSerializer implements Serializer<Customer> {
 @Override
 public void configure(Map configs, boolean isKey) {
 // nothing to configure
 }
 @Override
 /**
 We are serializing Customer as:
 4 byte int representing customerId
 4 byte int representing length of customerName in UTF-8 bytes (0 if
 name is Null)
 N bytes representing customerName in UTF-8
62 | Chapter 3: Kafka Producers: Writing Messages to Kafka
 **/
 public byte[] serialize(String topic, Customer data) {
 try {
 byte[] serializedName;
 int stringSize;
 if (data == null)
 return null;
 else {
 if (data.getName() != null) {
 serializedName = data.getName().getBytes("UTF-8");
 stringSize = serializedName.length;
 } else {
 serializedName = new byte[0];
 stringSize = 0;
 }
 }
 ByteBuffer buffer = ByteBuffer.allocate(4 + 4 + stringSize);
 buffer.putInt(data.getID());
 buffer.putInt(stringSize);
 buffer.put(serializedName);
 return buffer.array();
 } catch (Exception e) {
 throw new SerializationException(
 "Error when serializing Customer to byte[] " + e);
 }
 }
 @Override
 public void close() {
 // nothing to close
 }
}
Configuring a producer with this CustomerSerializer will allow you to define
ProducerRecord<String, Customer>, and send Customer data and pass Customer
objects directly to the producer. This example is pretty simple, but you can see how
fragile the code is. If we ever have too many customers, for example, and need to
change customerID to Long, or if we ever decide to add a startDate field to
Customer, we will have a serious issue in maintaining compatibility between old and
new messages. Debugging compatibility issues between different versions of serializ‐
ers and deserializers is fairly challenging: you need to compare arrays of raw bytes. To
make matters even worse, if multiple teams in the same company end up writing
Customer data to Kafka, they will all need to use the same serializers and modify the
code at the exact same time.
For these reasons, we recommend using existing serializers and deserializers such as
JSON, Apache Avro, Thrift, or Protobuf. In the following section, we will describe
Apache Avro and then show how to serialize Avro records and send them to Kafka.
Serializers | 63
Serializing Using Apache Avro
Apache Avro is a language-neutral data serialization format. The project was created
by Doug Cutting to provide a way to share data files with a large audience.
Avro data is described in a language-independent schema. The schema is usually
described in JSON, and the serialization is usually to binary files, although serializing
to JSON is also supported. Avro assumes that the schema is present when reading and
writing files, usually by embedding the schema in the files themselves.
One of the most interesting features of Avro, and what makes it a good fit for use in a
messaging system like Kafka, is that when the application that is writing messages
switches to a new but compatible schema, the applications reading the data can con‐
tinue processing messages without requiring any change or update.
Suppose the original schema was:
{"namespace": "customerManagement.avro",
 "type": "record",
 "name": "Customer",
 "fields": [
 {"name": "id", "type": "int"},
 {"name": "name", "type": "string"},
 {"name": "faxNumber", "type": ["null", "string"], "default": "null"}
 ]
}
id and name fields are mandatory, while faxNumber is optional and defaults to
null.
We used this schema for a few months and generated a few terabytes of data in this
format. Now suppose we decide that in the new version, we will upgrade to the 21st
century and will no longer include a fax number field and will instead use an email
field.
The new schema would be:
{"namespace": "customerManagement.avro",
 "type": "record",
 "name": "Customer",
 "fields": [
 {"name": "id", "type": "int"},
 {"name": "name", "type": "string"},
 {"name": "email", "type": ["null", "string"], "default": "null"}
 ]
}
Now, after upgrading to the new version, old records will contain faxNumber and new
records will contain email. In many organizations, upgrades are done slowly and
over many months. So we need to consider how pre-upgrade applications that still
64 | Chapter 3: Kafka Producers: Writing Messages to Kafka
use the fax numbers and post-upgrade applications that use email will be able to han‐
dle all the events in Kafka.
The reading application will contain calls to methods similar to getName(), getId(),
and getFaxNumber(). If it encounters a message written with the new schema, get
Name() and getId() will continue working with no modification, but getFax
Number() will return null because the message will not contain a fax number.
Now suppose we upgrade our reading application and it no longer has the getFax
Number() method but rather getEmail(). If it encounters a message written with the
old schema, getEmail() will return null because the older messages do not contain
an email address.
This example illustrates the benefit of using Avro: even though we changed the
schema in the messages without changing all the applications reading the data, there
will be no exceptions or breaking errors and no need for expensive updates of exist‐
ing data.
However, there are two caveats to this scenario:
• The schema used for writing the data and the schema expected by the reading
application must be compatible. The Avro documentation includes compatibility
rules.
• The deserializer will need access to the schema that was used when writing the
data, even when it is different from the schema expected by the application that
accesses the data. In Avro files, the writing schema is included in the file itself,
but there is a better way to handle this for Kafka messages. We will look at that
next.
Using Avro Records with Kafka
Unlike Avro files, where storing the entire schema in the data file is associated with a
fairly reasonable overhead, storing the entire schema in each record will usually more
than double the record size. However, Avro still requires the entire schema to be
present when reading the record, so we need to locate the schema elsewhere. To ach‐
ieve this, we follow a common architecture pattern and use a Schema Registry. The
Schema Registry is not part of Apache Kafka, but there are several open source
options to choose from. We’ll use the Confluent Schema Registry for this example.
You can find the Schema Registry code on GitHub, or you can install it as part of the
Confluent Platform. If you decide to use the Schema Registry, we recommend check‐
ing the documentation on Confluent.
The idea is to store all the schemas used to write data to Kafka in the registry. Then
we simply store the identifier for the schema in the record we produce to Kafka. The
consumers can then use the identifier to pull the record out of the Schema Registry
Serializers | 65
and deserialize the data. The key is that all this work—storing the schema in the reg‐
istry and pulling it up when required—is done in the serializers and deserializers. The
code that produces data to Kafka simply uses the Avro serializer just like it would any
other serializer. Figure 3-3 demonstrates this process.
Figure 3-3. Flow diagram of serialization and deserialization of Avro records
Here is an example of how to produce generated Avro objects to Kafka (see the Avro
documentation for how to generate objects from Avro schemas):
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("key.serializer",
 "io.confluent.kafka.serializers.KafkaAvroSerializer");
props.put("value.serializer",
 "io.confluent.kafka.serializers.KafkaAvroSerializer");
props.put("schema.registry.url", schemaUrl);
String topic = "customerContacts";
Producer<String, Customer> producer = new KafkaProducer<>(props);
// We keep producing new events until someone ctrl-c
while (true) {
 Customer customer = CustomerGenerator.getNext();
 System.out.println("Generated customer " +
 customer.toString());
 ProducerRecord<String, Customer> record =
 new ProducerRecord<>(topic, customer.getName(), customer);
 producer.send(record);
}
We use the KafkaAvroSerializer to serialize our objects with Avro. Note that
the KafkaAvroSerializer can also handle primitives, which is why we can later
use String as the record key and our Customer object as the value.
66 | Chapter 3: Kafka Producers: Writing Messages to Kafka
schema.registry.url is the configuration of the Avro serializer that will be
passed to the serializer by the producer. It simply points to where we store the
schemas.
Customer is our generated object. We tell the producer that our records will con‐
tain Customer as the value.
Customer class is not a regular Java class (plain old Java object, or POJO) but
rather a specialized Avro object, generated from a schema using Avro code gener‐
ation. The Avro serializer can only serialize Avro objects, not POJO. Generating
Avro classes can be done either using the avro-tools.jar or the Avro Maven plugin, both part of Apache Avro. See the Apache Avro Getting Started (Java) guide
for details on how to generate Avro classes.
We also instantiate ProducerRecord with Customer as the value type, and pass a
Customer object when creating the new record.
That’s it. We send the record with our Customer object, and KafkaAvro
Serializer will handle the rest.
Avro also allows you to use generic Avro objects, that are used as key-value maps,
rather than generated Avro objects with getters and setters that match the schema
that was used to generate them. To use generic Avro objects, you just need to provide
the schema:
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("key.serializer",
 "io.confluent.kafka.serializers.KafkaAvroSerializer");
props.put("value.serializer",
 "io.confluent.kafka.serializers.KafkaAvroSerializer");
props.put("schema.registry.url", url);
String schemaString =
 "{\"namespace\": \"customerManagement.avro\",
 "\"type\": \"record\", " +
 "\"name\": \"Customer\"," +
 "\"fields\": [" +
 "{\"name\": \"id\", \"type\": \"int\"}," +
 "{\"name\": \"name\", \"type\": \"string\"}," +
 "{\"name\": \"email\", \"type\": " + "[\"null\",\"string\"], " +
 "\"default\":\"null\" }" +
 "]}";
Producer<String, GenericRecord> producer =
 new KafkaProducer<String, GenericRecord>(props);
Schema.Parser parser = new Schema.Parser();
Serializers | 67
Schema schema = parser.parse(schemaString);
for (int nCustomers = 0; nCustomers < customers; nCustomers++) {
 String name = "exampleCustomer" + nCustomers;
 String email = "example " + nCustomers + "@example.com";
 GenericRecord customer = new GenericData.Record(schema);
 customer.put("id", nCustomers);
 customer.put("name", name);
 customer.put("email", email);
 ProducerRecord<String, GenericRecord> data =
 new ProducerRecord<>("customerContacts", name, customer);
 producer.send(data);
}
We still use the same KafkaAvroSerializer.
And we provide the URI of the same Schema Registry.
But now we also need to provide the Avro schema, since it is not provided by an
Avro-generated object.
Our object type is an Avro GenericRecord, which we initialize with our schema
and the data we want to write.
Then the value of the ProducerRecord is simply a GenericRecord that contains
our schema and data. The serializer will know how to get the schema from this
record, store it in the Schema Registry, and serialize the object data.
Partitions
In previous examples, the ProducerRecord objects we created included a topic name,
key, and value. Kafka messages are key-value pairs, and while it is possible to create a
ProducerRecord with just a topic and a value, with the key set to null by default,
most applications produce records with keys. Keys serve two goals: they are addi‐
tional information that gets stored with the message, and they are typically also used
to decide which one of the topic partitions the message will be written to (keys also
play an important role in compacted topics—we’ll discuss those in Chapter 6). All
messages with the same key will go to the same partition. This means that if a process
is reading only a subset of the partitions in a topic (more on that in Chapter 4), all the
records for a single key will be read by the same process. To create a key-value record,
you simply create a ProducerRecord as follows:
ProducerRecord<String, String> record =
 new ProducerRecord<>("CustomerCountry", "Laboratory Equipment", "USA");
68 | Chapter 3: Kafka Producers: Writing Messages to Kafka
When creating messages with a null key, you can simply leave the key out:
ProducerRecord<String, String> record =
 new ProducerRecord<>("CustomerCountry", "USA");
Here, the key will simply be set to null.
When the key is null and the default partitioner is used, the record will be sent to
one of the available partitions of the topic at random. A round-robin algorithm will
be used to balance the messages among the partitions. Starting in the Apache Kafka
2.4 producer, the round-robin algorithm used in the default partitioner when han‐
dling null keys is sticky. This means that it will fill a batch of messages sent to a single
partition before switching to the next partition. This allows sending the same number
of messages to Kafka in fewer requests, leading to lower latency and reduced CPU
utilization on the broker.
If a key exists and the default partitioner is used, Kafka will hash the key (using its
own hash algorithm, so hash values will not change when Java is upgraded) and use
the result to map the message to a specific partition. Since it is important that a key is
always mapped to the same partition, we use all the partitions in the topic to calculate
the mapping—not just the available partitions. This means that if a specific partition
is unavailable when you write data to it, you might get an error. This is fairly rare, as
you will see in Chapter 7 when we discuss Kafka’s replication and availability.
In addition to the default partitioner, Apache Kafka clients also provide RoundRobin
Partitioner and UniformStickyPartitioner. These provide random partition
assignment and sticky random partition assignment even when messages have keys.
These are useful when keys are important for the consuming application (for exam‐
ple, there are ETL applications that use the key from Kafka records as the primary key
when loading data from Kafka to a relational database), but the workload may be
skewed, so a single key may have a disproportionately large workload. Using the
UniformStickyPartitioner will result in an even distribution of workload across all
partitions.
When the default partitioner is used, the mapping of keys to partitions is consistent
only as long as the number of partitions in a topic does not change. So as long as the
number of partitions is constant, you can be sure that, for example, records regarding
user 045189 will always get written to partition 34. This allows all kinds of optimiza‐
tion when reading data from partitions. However, the moment you add new parti‐
tions to the topic, this is no longer guaranteed—the old records will stay in partition
34 while new records may get written to a different partition. When partitioning keys
is important, the easiest solution is to create topics with sufficient partitions (the
Confluent blog contains suggestions on how to choose the number of partitions) and
never add partitions.


Implementing a custom partitioning strategy

For example, suppose
that you are a B2B vendor and your biggest customer is a company that manufactures
handheld devices called Bananas. Suppose that you do so much business with cus‐
tomer “Banana” that over 10% of your daily transactions are with this customer. If
you use default hash partitioning, the Banana records will get allocated to the same
partition as other accounts, resulting in one partition being much larger than the rest.
This can cause servers to run out of space, processing to slow down, etc. What we
really want is to give Banana its own partition and then use hash partitioning to map
the rest of the accounts to all other partitions.
Here is an example of a custom partitioner:
import org.apache.kafka.clients.producer.Partitioner;
import org.apache.kafka.common.Cluster;
import org.apache.kafka.common.PartitionInfo;
import org.apache.kafka.common.record.InvalidRecordException;
import org.apache.kafka.common.utils.Utils;
public class BananaPartitioner implements Partitioner {
 public void configure(Map<String, ?> configs) {}
 public int partition(String topic, Object key, byte[] keyBytes,
 Object value, byte[] valueBytes,
 Cluster cluster) {
 List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
 int numPartitions = partitions.size();
 if ((keyBytes == null) || (!(key instanceOf String)))
 throw new InvalidRecordException("We expect all messages " +
 "to have customer name as key");
 if (((String) key).equals("Banana"))
 return numPartitions - 1; // Banana will always go to last partition
 // Other records will get hashed to the rest of the partitions
 return Math.abs(Utils.murmur2(keyBytes)) % (numPartitions - 1);
 }
 public void close() {}
}
Partitioner interface includes configure, partition, and close methods. Here
we only implement partition, although we really should have passed the special
customer name through configure instead of hardcoding it in partition.
70 | Chapter 3: Kafka Producers: Writing Messages to Kafka
We only expect String keys, so we throw an exception if that is not the case.
Headers
Records can, in addition to key and value, also include headers. Record headers give
you the ability to add some metadata about the Kafka record, without adding any
extra information to the key/value pair of the record itself. Headers are often used for
lineage to indicate the source of the data in the record, and for routing or tracing
messages based on header information without having to parse the message itself
(perhaps the message is encrypted and the router doesn’t have permissions to access
the data).
Headers are implemented as an ordered collection of key/value pairs. The keys are
always a String, and the values can be any serialized object—just like the message
value.
Here is a small example that shows how to add headers to a ProduceRecord:
ProducerRecord<String, String> record =
 new ProducerRecord<>("CustomerCountry", "Precision Products", "France");
record.headers().add("privacy-level","YOLO".getBytes(StandardCharsets.UTF_8));
Interceptors
There are times when you want to modify the behavior of your Kafka client applica‐
tion without modifying its code, perhaps because you want to add identical behavior
to all applications in the organization. Or perhaps you don’t have access to the origi‐
nal code.
Kafka’s ProducerInterceptor interceptor includes two key methods:
ProducerRecord<K, V> onSend(ProducerRecord<K, V> record)
This method will be called before the produced record is sent to Kafka, indeed
before it is even serialized. When overriding this method, you can capture infor‐
mation about the sent record and even modify it. Just be sure to return a valid
ProducerRecord from this method. The record that this method returns will be
serialized and sent to Kafka.
void onAcknowledgement(RecordMetadata metadata, Exception exception)
This method will be called if and when Kafka responds with an acknowledgment
for a send. The method does not allow modifying the response from Kafka, but
you can capture information about the response.
Headers | 71
Common use cases for producer interceptors include capturing monitoring and trac‐
ing information; enhancing the message with standard headers, especially for lineage
tracking purposes; and redacting sensitive information.
Here is an example of a very simple producer interceptor. This one simply counts the
messages sent and acks received within specific time windows:
public class CountingProducerInterceptor implements ProducerInterceptor {
 ScheduledExecutorService executorService =
 Executors.newSingleThreadScheduledExecutor();
 static AtomicLong numSent = new AtomicLong(0);
 static AtomicLong numAcked = new AtomicLong(0);
 public void configure(Map<String, ?> map) {
 Long windowSize = Long.valueOf(
 (String) map.get("counting.interceptor.window.size.ms"));
 executorService.scheduleAtFixedRate(CountingProducerInterceptor::run,
 windowSize, windowSize, TimeUnit.MILLISECONDS);
 }
 public ProducerRecord onSend(ProducerRecord producerRecord) {
 numSent.incrementAndGet();
 return producerRecord;
 }
 public void onAcknowledgement(RecordMetadata recordMetadata, Exception e) {
 numAcked.incrementAndGet();
 }
 public void close() {
 executorService.shutdownNow();
 }
 public static void run() {
 System.out.println(numSent.getAndSet(0));
 System.out.println(numAcked.getAndSet(0));
 }
}
ProducerInterceptor is a Configurable interface. You can override the
configure method and setup before any other method is called. This method
receives the entire producer configuration, and you can access any configuration
parameter. In this case, we added a configuration of our own that we reference
here.
When a record is sent, we increment the record count and return the record
without modifying it.
72 | Chapter 3: Kafka Producers: Writing Messages to Kafka
When Kafka responds with an ack, we increment the acknowledgment count and
don’t need to return anything.
This method is called when the producer closes, giving us a chance to clean up
the interceptor state. In this case, we close the thread we created. If you opened
file handles, connections to remote data stores, or similar, this is the place to
close everything and avoid leaks.
As we mentioned earlier, producer interceptors can be applied without any changes
to the client code. To use the preceding interceptor with kafka-console-producer,
an example application that ships with Apache Kafka, follow these three simple steps:
1. Add your jar to the classpath:
export CLASSPATH=$CLASSPATH:~./target/CountProducerInterceptor-1.0-
SNAPSHOT.jar
2. Create a config file that includes:
interceptor.classes=com.shapira.examples.interceptors.CountProducer
Interceptor counting.interceptor.window.size.ms=10000
3. Run the application as you normally would, but make sure to include the config‐
uration that you created in the previous step:
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic
interceptor-test --producer.config producer.config

















RELIABLE DATA DELIVERY


Kakfa is very flexibility about reliable data delivery to accomodate use cases that require utmost reliability as well as others that prioritize speed and simplicity.

The trade-offs usually involve how important
it is to reliably and consistently store messages versus other important considerations,
such as availability, high throughput, low latency, and hardware costs.


<h3>Reliability Guarantees</h3>

<ul>
  <li>
    If message B was written after message A using the same producer in the same partition then Kafka guarantees that the offset of message B will be higher than message A and that consumers will read message B after message A.
  </li>
  <li>
    Produced messages are considered "committed" when they were written to the partition on all its in-sync replica. Messages that are committed will not be lost as long as at least one replica remains alive.
  </li>
  <li>
    Consumers can only read messages that are committed.
  </li>
</ul>





Replication
Kafka’s replication mechanism, with its multiple replicas per partition, is at the core
of all of Kafka’s reliability guarantees. Having a message written in multiple replicas is
how Kafka provides durability of messages in the event of a crash.
We explained Kafka’s replication mechanism in depth in Chapter 6, but let’s recap the
highlights here.
Each Kafka topic is broken down into partitions, which are the basic data building
blocks. A partition is stored on a single disk. Kafka guarantees the order of events
within a partition, and a partition can be either online (available) or offline (unavail‐
able). Each partition can have multiple replicas, one of which is a designated leader.
All events are produced to the leader replica and are usually consumed from the
leader replica as well. Other replicas just need to stay in sync with the leader and rep‐
licate all the recent events on time. If the leader becomes unavailable, one of the insync replicas becomes the new leader (there is an exception to this rule, which we
discussed in Chapter 6).
A replica is considered in sync if it is the leader for a partition, or if it is a follower
that:
• Has an active session with ZooKeeper—meaning that it sent a heartbeat to Zoo‐
Keeper in the last 6 seconds (configurable).
• Fetched messages from the leader in the last 10 seconds (configurable).
• Fetched the most recent messages from the leader in the last 10 seconds. That is,
it isn’t enough that the follower is still getting messages from the leader; it must
have had no lag at least once in the last 10 seconds (configurable).
If a replica loses connection to ZooKeeper, stops fetching new messages, or falls
behind and can’t catch up within 10 seconds, the replica is considered out of sync. An
out-of-sync replica gets back into sync when it connects to ZooKeeper again and
catches up to the most recent message written to the leader. This usually happens
quickly after a temporary network glitch is healed but can take a while if the broker
the replica is stored on was down for a longer period of time.
Replication | 163

Out-of-Sync Replicas
In older versions of Kafka, it was not uncommon to see one or
more replicas rapidly flip between in-sync and out-of-sync status.
This was a sure sign that something was wrong with the cluster. A
relatively common cause was a large maximum request size and
large JVM heap that required tuning to prevent long garbage col‐
lection pauses that would cause the broker to temporarily discon‐
nect from ZooKeeper. These days the problem is very rare,
especially when using Apache Kafka release 2.5.0 and higher with
its default configurations for ZooKeeper connection timeout and
maximum replica lag. The use of JVM version 8 and above (now
the minimum version supported by Kafka) with G1 garbage collec‐
tor helped curb this problem, although tuning may still be required
for large messages. Generally speaking, Kafka’s replication protocol
became significantly more reliable in the years since the first edi‐
tion of the book was published. For details on the evolution of Kaf‐
ka’s replication protocol, refer to Jason Gustafson’s excellent talk,
“Hardening Apache Kafka Replication”, and Gwen Shapira’s over‐
view of Kafka improvements, “Please Upgrade Apache Kafka
Now”.
An in-sync replica that is slightly behind can slow down producers and consumers—
since they wait for all the in-sync replicas to get the message before it is committed.
Once a replica falls out of sync, we no longer wait for it to get messages. It is still
behind, but now there is no performance impact. The catch is that with fewer in-sync
replicas, the effective replication factor of the partition is lower, and therefore there is
a higher risk for downtime or data loss.
In the next section, we will look at what this means in practice.
Broker Conguration
There are three configuration parameters in the broker that change Kafka’s behavior
regarding reliable message storage. Like many broker configuration variables, these
can apply at the broker level, controlling configuration for all topics in the system,
and at the topic level, controlling behavior for a specific topic.
Being able to control reliability trade-offs at the topic level means that the same Kafka
cluster can be used to host reliable and nonreliable topics. For example, at a bank, the
administrator will probably want to set very reliable defaults for the entire cluster but
make an exception to the topic that stores customer complaints where some data loss
is acceptable.
Let’s look at these configuration parameters one by one and see how they affect the
reliability of message storage in Kafka and the trade-offs involved.
164 | Chapter 7: Reliable Data Delivery
Replication Factor
The topic-level configuration is replication.factor. At the broker level, we control
the default.replication.factor for automatically created topics.
Until this point in the book, we have assumed that topics had a replication factor of
three, meaning that each partition is replicated three times on three different brokers.
This was a reasonable assumption, as this is Kafka’s default, but this is a configuration
that users can modify. Even after a topic exists, we can choose to add or remove repli‐
cas and thereby modify the replication factor using Kafka’s replica assignment tool.
A replication factor of N allows us to lose N-1 brokers while still being able to read
and write data to the topic. So a higher replication factor leads to higher availability,
higher reliability, and fewer disasters. On the flip side, for a replication factor of N, we
will need at least N brokers and we will store N copies of the data, meaning we will
need N times as much disk space. We are basically trading availability for hardware.
So how do we determine the right number of replicas for a topic? There are a few key
considerations:
Availability
A partition with just one replica will become unavailable even during a routine
restart of a single broker. The more replicas we have, the higher availability we
can expect.
Durability
Each replica is a copy of all the data in a partition. If a partition has a single rep‐
lica and the disk becomes unusable for any reason, we’ve lost all the data in the
partition. With more copies, especially on different storage devices, the probabil‐
ity of losing all of them is reduced.


Throughput
With each additional replica, we multiply the inter-broker traffic. If we produce
to a partition at a rate of 10 MBps, then a single replica will not generate any rep‐
lication traffic. If we have 2 replicas, then we’ll have 10 MBps replication traffic,
with 3 replicas it will be 20 MBps, and with 5 replicas it will be 40 MBps. We need
to take this into account when planning the cluster size and capacity.
End-to-end latency
Each produced record has to be replicated to all in-sync replicas before it is avail‐
able for consumers. In theory, with more replicas, there is higher probability that
one of these replicas is a bit slow and therefore will slow the consumers down. In
practice, if one broker becomes slow for any reason, it will slow down every cli‐
ent that tries using it, regardless of replication factor.
Broker Conguration | 165
Cost
This is the most common reason for using a replication factor lower than 3 for
noncritical data. The more replicas we have of our data, the higher the storage
and network costs. Since many storage systems already replicate each block 3
times, it sometimes makes sense to reduce costs by configuring Kafka with a rep‐
lication factor of 2. Note that this will still reduce availability compared to a repli‐
cation factor of 3, but durability will be guaranteed by the storage device.
Placement of replicas is also very important. Kafka will always make sure each replica
for a partition is on a separate broker. In some cases, this is not safe enough. If all
replicas for a partition are placed on brokers that are on the same rack, and the topof-rack switch misbehaves, we will lose availability of the partition regardless of the
replication factor. To protect against rack-level misfortune, we recommend placing
brokers in multiple racks and using the broker.rack broker configuration parameter
to configure the rack name for each broker. If rack names are configured, Kafka will
make sure replicas for a partition are spread across multiple racks in order to guaran‐
tee even higher availability. When running Kafka in cloud environments, it is com‐
mon to consider availability zones as separate racks. In Chapter 6, we provided details
on how Kafka places replicas on brokers and racks.
Unclean Leader Election
This configuration is only available at the broker (and in practice, cluster-wide) level.
The parameter name is unclean.leader.election.enable, and by default it is set to
false.
As explained earlier, when the leader for a partition is no longer available, one of the
in-sync replicas will be chosen as the new leader. This leader election is “clean” in the
sense that it guarantees no loss of committed data—by definition, committed data
exists on all in-sync replicas.
But what do we do when no in-sync replica exists except for the leader that just
became unavailable?
This situation can happen in one of two scenarios:
• The partition had three replicas, and the two followers became unavailable (let’s
say two brokers crashed). In this situation, as producers continue writing to the
leader, all the messages are acknowledged and committed (since the leader is the
one and only in-sync replica). Now let’s say that the leader becomes unavailable
(oops, another broker crash). In this scenario, if one of the out-of-sync followers
starts first, we have an out-of-sync replica as the only available replica for the
partition.
• The partition had three replicas, and due to network issues, the two followers fell
behind so that even though they are up and replicating, they are no longer in
166 | Chapter 7: Reliable Data Delivery
sync. The leader keeps accepting messages as the only in-sync replica. Now if the
leader becomes unavailable, there are only out-of-sync replicas available to
become leaders.
In both these scenarios, we need to make a difficult decision:
• If we don’t allow the out-of-sync replica to become the new leader, the partition
will remain offline until we bring the old leader (and the last in-sync replica)
back online. In some cases (e.g., memory chip needs replacement), this can take
many hours.
• If we do allow the out-of-sync replica to become the new leader, we are going to
lose all messages that were written to the old leader while that replica was out of
sync and also cause some inconsistencies in consumers. Why? Imagine that while
replicas 0 and 1 were not available, we wrote messages with offsets 100–200 to
replica 2 (then the leader). Now replica 2 is unavailable and replica 0 is back
online. Replica 0 only has messages 0–100 but not 100–200. If we allow replica 0
to become the new leader, it will allow producers to write new messages and
allow consumers to read them. So, now the new leader has completely new mes‐
sages 100–200. First, let’s note that some consumers may have read the old
messages 100–200, some consumers got the new 100–200, and some got a mix of
both. This can lead to pretty bad consequences when looking at things like
downstream reports. In addition, replica 2 will come back online and become a
follower of the new leader. At that point, it will delete any messages it got that
don’t exist on the current leader. Those messages will not be available to any con‐
sumer in the future.
In summary, if we allow out-of-sync replicas to become leaders, we risk data loss and
inconsistencies. If we don’t allow them to become leaders, we face lower availability as
we must wait for the original leader to become available before the partition is back
online.
By default, unclean.leader.election.enable is set to false, which will not allow
out-of-sync replicas to become leaders. This is the safest option since it provides the
best guarantees against data loss. It does mean that in the extreme unavailability sce‐
narios that we described previously, some partitions will remain unavailable until
manually recovered. It is always possible for an administrator to look at the situation,
decide to accept the data loss in order to make the partitions available, and switch this
configuration to true before starting the cluster. Just don’t forget to turn it back to
false after the cluster recovered.
Minimum In-Sync Replicas
Both the topic and the broker-level configuration are called min.insync.replicas.
Broker Conguration | 167
As we’ve seen, there are cases where even though we configured a topic to have three
replicas, we may be left with a single in-sync replica. If this replica becomes unavail‐
able, we may have to choose between availability and consistency. This is never an
easy choice. Note that part of the problem is that, per Kafka reliability guarantees,
data is considered committed when it is written to all in-sync replicas, even when all
means just one replica and the data could be lost if that replica is unavailable.
When we want to be sure that committed data is written to more than one replica, we
need to set the minimum number of in-sync replicas to a higher value. If a topic has
three replicas and we set min.insync.replicas to 2, then producers can only write to
a partition in the topic if at least two out of the three replicas are in sync.
When all three replicas are in sync, everything proceeds normally. This is also true if
one of the replicas becomes unavailable. However, if two out of three replicas are not
available, the brokers will no longer accept produce requests. Instead, producers that
attempt to send data will receive NotEnoughReplicasException. Consumers can con‐
tinue reading existing data. In effect, with this configuration, a single in-sync replica
becomes read-only. This prevents the undesirable situation where data is produced
and consumed, only to disappear when unclean election occurs. In order to recover
from this read-only situation, we must make one of the two unavailable partitions
available again (maybe restart the broker) and wait for it to catch up and get in sync.
Keeping Replicas In Sync
As mentioned earlier, out-of-sync replicas decrease the overall reliability, so it is
important to avoid these as much as possible. We also explained that a replica can
become out of sync in one of two ways: either it loses connectivity to ZooKeeper or it
fails to keep up with the leader and builds up a replication lag. Kafka has two broker
configurations that control the sensitivity of the cluster to these two conditions.
zookeeper.session.timeout.ms is the time interval during which a Kafka broker
can stop sending heartbeats to ZooKeeper without ZooKeeper considering the broker
dead and removing it from the cluster. In version 2.5.0, this value was increased from
6 seconds to 18 seconds, in order to increase the stability of Kafka clusters in cloud
environments where network latencies show higher variance. In general, we want this
time to be high enough to avoid random flapping caused by garbage collection or
network conditions, but still low enough to make sure brokers that are actually frozen
will be detected in a timely manner.
If a replica did not fetch from the leader or did not catch up to the latest messages on
the leader for longer than replica.lag.time.max.ms, it will become out of sync. This
was increased from 10 seconds to 30 seconds in release 2.5.0 to improve resilience of
the cluster and avoid unnecessary flapping. Note that this higher value also impacts
maximum latency for the consumer—with the higher value it can take up to 30
168 | Chapter 7: Reliable Data Delivery
seconds until a message arrives to all replicas and the consumers are allowed to con‐
sume it.
Persisting to Disk
We’ve mentioned a few times that Kafka will acknowledge messages that were not
persisted to disk, depending just on the number of replicas that received the message.
Kafka will flush messages to disk when rotating segments (by default 1 GB in size)
and before restarts but will otherwise rely on Linux page cache to flush messages
when it becomes full. The idea behind this is that having three machines in separate
racks or availability zones, each with a copy of the data, is safer than writing the mes‐
sages to disk on the leader, because simultaneous failures on two different racks or
zones are so unlikely. However, it is possible to configure the brokers to persist mes‐
sages to disk more frequently. The configuration parameter flush.messages allows
us to control the maximum number of messages not synced to disk, and flush.ms
allows us to control the frequency of syncing to disk. Before using this feature, it is
worth reading how fsync impacts Kafka’s throughput and how to mitigate its
drawbacks.
Using Producers in a Reliable System
Even if we configure the brokers in the most reliable configuration possible, the sys‐
tem as a whole can still potentially lose data if we don’t configure the producers to be
reliable as well.
Here are two example scenarios to demonstrate this:
• We configured the brokers with three replicas, and unclean leader election is dis‐
abled. So we should never lose a single message that was committed to the Kafka
cluster. However, we configured the producer to send messages with acks=1. We
sent a message from the producer, and it was written to the leader but not yet to
the in-sync replicas. The leader sent back a response to the producer saying,
“Message was written successfully” and immediately crashes before the data was
replicated to the other replicas. The other replicas are still considered in sync
(remember that it takes a while before we declare a replica out of sync), and one
of them will become the leader. Since the message was not written to the replicas,
it was lost. But the producing application thinks it was written successfully. The
system is consistent because no consumer saw the message (it was never commit‐
ted because the replicas never got it), but from the producer perspective, a mes‐
sage was lost.
• We configured the brokers with three replicas, and unclean leader election is dis‐
abled. We learned from our mistakes and started producing messages with
acks=all. Suppose that we are attempting to write a message to Kafka, but the
Using Producers in a Reliable System | 169
leader for the partition we are writing to just crashed and a new one is still get‐
ting elected. Kafka will respond with “Leader not Available.” At this point, if the
producer doesn’t handle the error correctly and doesn’t retry until the write is
successful, the message may be lost. Once again, this is not a broker reliability
issue because the broker never got the message; and it is not a consistency issue
because the consumers never got the message either. But if producers don’t han‐
dle errors correctly, they may cause message loss.
As the examples show, there are two important things that everyone who writes appli‐
cations that produce to Kafka must pay attention to:
• Use the correct acks configuration to match reliability requirements
• Handle errors correctly both in configuration and in code
We discussed producer configuration in depth in Chapter 3, but let’s go over the
important points again.
Send Acknowledgments
Producers can choose between three different acknowledgment modes:
acks=0
This means that a message is considered to be written successfully to Kafka if the
producer managed to send it over the network. We will still get errors if the
object we are sending cannot be serialized or if the network card failed, but we
won’t get any error if the partition is offline, a leader election is in progress, or
even if the entire Kafka cluster is unavailable. Running with acks=0 has low pro‐
duce latency (which is why we see a lot of benchmarks with this configuration),
but it will not improve end-to-end latency (remember that consumers will not
see messages until they are replicated to all available replicas).
acks=1
This means that the leader will send either an acknowledgment or an error the
moment it gets the message and writes it to the partition data file (but not neces‐
sarily synced to disk). We can lose data if the leader shuts down or crashes and
some messages that were successfully written to the leader and acknowledged
were not replicated to the followers before the crash. With this configuration, it is
also possible to write to the leader faster than it can replicate messages and end
up with under-replicated partitions, since the leader will acknowledge messages
from the producer before replicating them.
acks=all
This means that the leader will wait until all in-sync replicas get the message
before sending back an acknowledgment or an error. In conjunction with the
170 | Chapter 7: Reliable Data Delivery
min.insync.replicas configuration on the broker, this lets us control how many
replicas get the message before it is acknowledged. This is the safest option—the
producer won’t stop trying to send the message before it is fully committed. This
is also the option with the longest producer latency—the producer waits for all
in-sync replicas to get all the messages before it can mark the message batch as
“done” and carry on.
Conguring Producer Retries
There are two parts to handling errors in the producer: the errors that the producers
handle automatically for us and the errors that we, as developers using the producer
library, must handle.
The producer can handle retriable errors. When the producer sends messages to a
broker, the broker can return either a success or an error code. Those error codes
belong to two categories—errors that can be resolved after retrying and errors that
won’t be resolved. For example, if the broker returns the error code
LEADER_NOT_AVAILABLE, the producer can try sending the message again—maybe a
new broker was elected and the second attempt will succeed. This means that
LEADER_NOT_AVAILABLE is a retriable error. On the other hand, if a broker returns an
INVALID_CONFIG exception, trying the same message again will not change the con‐
figuration. This is an example of a nonretriable error.
In general, when our goal is to never lose a message, our best approach is to configure
the producer to keep trying to send the messages when it encounters a retriable error.
And the best approach to retries, as recommended in Chapter 3, is to leave the num‐
ber of retries at its current default (MAX_INT, or effectively infinite) and use
delivery.timout.ms to configure the maximum amount of time we are willing to
wait until giving up on sending a message—the producer will retry sending the mes‐
sage as many times as possible within this time interval.
Retrying to send a failed message includes a risk that both messages were successfully
written to the broker, leading to duplicates. Retries and careful error handling can
guarantee that each message will be stored at least once, but not exactly once. Using
enable.idempotence=true will cause the producer to include additional information
in its records, which brokers will use to skip duplicate messages caused by retries. In
Chapter 8, we discuss in detail how and when this works.
Additional Error Handling
Using the built-in producer retries is an easy way to correctly handle a large variety of
errors without loss of messages, but as developers, we must still be able to handle
other types of errors. These include:
Using Producers in a Reliable System | 171
• Nonretriable broker errors, such as errors regarding message size, authorization
errors, etc.
• Errors that occur before the message was sent to the broker—for example, seriali‐
zation errors
• Errors that occur when the producer exhausted all retry attempts or when the
available memory used by the producer is filled to the limit due to using all of it
to store messages while retrying
• Timeouts
In Chapter 3 we discussed how to write error handlers for both sync and async
message-sending methods. The content of these error handlers is specific to the appli‐
cation and its goals—do we throw away “bad messages”? Log errors? Stop reading
messages from the source system? Apply back pressure to the source system to stop
sending messages for a while? Store these messages in a directory on the local disk?
These decisions depend on the architecture and the product requirements. Just note
that if all the error handler is doing is retrying to send the message, then we’ll be bet‐
ter off relying on the producer’s retry functionality.
Using Consumers in a Reliable System
Now that we have learned how to produce data while taking Kafka’s reliability guar‐
antees into account, it is time to see how to consume data.
As we saw in the first part of this chapter, data is only available to consumers after it
has been committed to Kafka—meaning it was written to all in-sync replicas. This
means that consumers get data that is guaranteed to be consistent. The only thing
consumers are left to do is make sure they keep track of which messages they’ve read
and which messages they haven’t. This is key to not losing messages while consuming
them.
When reading data from a partition, a consumer is fetching a batch of messages,
checking the last offset in the batch, and then requesting another batch of messages
starting from the last offset received. This guarantees that a Kafka consumer will
always get new data in correct order without missing any messages.
When a consumer stops, another consumer needs to know where to pick up the
work—what was the last offset that the previous consumer processed before it stop‐
ped? The “other” consumer can even be the original one after a restart. It doesn’t
really matter—some consumer is going to pick up consuming from that partition,
and it needs to know at which offset to start. This is why consumers need to “commit”
their offsets. For each partition it is consuming, the consumer stores its current loca‐
tion, so it or another consumer will know where to continue after a restart. The main
way consumers can lose messages is when committing offsets for events they’ve read
172 | Chapter 7: Reliable Data Delivery
but haven’t completely processed yet. This way, when another consumer picks up the
work, it will skip those messages and they will never get processed. This is why paying
careful attention to when and how offsets get committed is critical.
Committed Messages Versus Committed Offsets
This is different from a committed message, which, as discussed
previously, is a message that was written to all in-sync replicas and
is available to consumers. Committed offsets are offsets the con‐
sumer sent to Kafka to acknowledge that it received and processed
all the messages in a partition up to this specific offset.
In Chapter 4, we discussed the Consumer API in detail and covered the many meth‐
ods for committing offsets. Here we will cover some important considerations and
choices, but refer back to Chapter 4 for details on using the APIs.
Important Consumer Conguration Properties for Reliable Processing
There are four consumer configuration properties that are important to understand
in order to configure our consumer for a desired reliability behavior.
The first is group.id, as explained in great detail in Chapter 4. The basic idea is that if
two consumers have the same group ID and subscribe to the same topic, each will be
assigned a subset of the partitions in the topic and will therefore only read a subset of
the messages individually (but all the messages will be read by the group as a whole).
If we need a consumer to see, on its own, every single message in the topics it is sub‐
scribed to, it will need a unique group.id.
The second relevant configuration is auto.offset.reset. This parameter controls
what the consumer will do when no offsets were committed (e.g., when the consumer
first starts) or when the consumer asks for offsets that don’t exist in the broker (Chap‐
ter 4 explains how this can happen). There are only two options here. If we choose
earliest, the consumer will start from the beginning of the partition whenever it
doesn’t have a valid offset. This can lead to the consumer processing a lot of messages
twice, but it guarantees to minimize data loss. If we choose latest, the consumer will
start at the end of the partition. This minimizes duplicate processing by the consumer
but almost certainly leads to some messages getting missed by the consumer.
The third relevant configuration is enable.auto.commit. This is a big decision: are
we going to let the consumer commit offsets for us based on schedule, or are we plan‐
ning on committing offsets manually in our code? The main benefit of automatic off‐
set commits is that it’s one less thing to worry about when using consumers in our
application. When we do all the processing of consumed records within the con‐
sumer poll loop, then the automatic offset commit guarantees we will never acciden‐
tally commit an offset that we didn’t process. The main drawbacks of automatic offset
Using Consumers in a Reliable System | 173
commits is that we have no control over the number of duplicate records the applica‐
tion may process because it was stopped after processing some records but before the
automated commit kicked in. When the application has more complex processing,
such as passing records to another thread to process in the background, there is no
choice but to use manual offset commit since the automatic commit may commit off‐
sets for records the consumer has read but perhaps has not processed yet.
The fourth relevant configuration, auto.commit.interval.ms, is tied to the third. If
we choose to commit offsets automatically, this configuration lets us configure how
frequently they will be committed. The default is every five seconds. In general, com‐
mitting more frequently adds overhead but reduces the number of duplicates that can
occur when a consumer stops.
While not directly related to reliable data processing, it is difficult to consider a con‐
sumer reliable if it frequently stops consuming in order to rebalance. Chapter 4
includes advice on how to configure consumers to minimize unnecessary rebalancing
and to minimize pauses while rebalancing.
Explicitly Committing Offsets in Consumers
If we decide we need more control and choose to commit offsets manually, we need
to be concerned about correctness and performance implications.
We will not go over the mechanics and APIs involved in committing offsets here,
since they were covered in great depth in Chapter 4. Instead, we will review impor‐
tant considerations when developing a consumer to handle data reliably. We’ll start
with the simple and perhaps obvious points and move on to more complex patterns.
Always commit offsets after messages were processed
If we do all the processing within the poll loop and don’t maintain state between poll
loops (e.g., for aggregation), this should be easy. We can use the auto-commit config‐
uration, commit offset at the end of the poll loop, or commit offset inside the loop at
a frequency that balances requirements for both overhead and lack of duplicate pro‐
cessing. If there are additional threads or stateful processing involved, this becomes
more complex, especially since the consumer object is not thread safe. In Chapter 4,
we discussed how this can be done and provided references with additional examples.
Commit frequency is a trade-off between performance and number of duplicates
in the event of a crash
Even in the simplest case where we do all the processing within the poll loop and
don’t maintain state between poll loops, we can choose to commit multiple times
within a loop or choose to only commit every several loops. Committing has signifi‐
cant performance overhead. It is similar to produce with acks=all, but all offset
commits of a single consumer group are produced to the same broker, which can
174 | Chapter 7: Reliable Data Delivery
become overloaded. The commit frequency has to balance requirements for perfor‐
mance and lack of duplicates. Committing after every message should only ever be
done on very low-throughput topics.
Commit the right offsets at the right time
A common pitfall when committing in the middle of the poll loop is accidentally
committing the last offset read when polling and not the offset after the last offset
processed. Remember that it is critical to always commit offsets for messages after
they were processed—committing offsets for messages read but not processed can
lead to the consumer missing messages. Chapter 4 has examples that show how to do
just that.
Rebalances
When designing an application, we need to remember that consumer rebalances will
happen, and we need to handle them properly. Chapter 4 contains a few examples.
This usually involves committing offsets before partitions are revoked and cleaning
any state the application maintains when it is assigned new partitions.
Consumers may need to retry
In some cases, after calling poll and processing records, some records are not fully
processed and will need to be processed later. For example, we may try to write
records from Kafka to a database but find that the database is not available at that
moment and we need to retry later. Note that unlike traditional pub/sub messaging
systems, Kafka consumers commit offsets and do not “ack” individual messages. This
means that if we failed to process record #30 and succeeded in processing record #31,
we should not commit offset #31—this would result in marking as processed all the
records up to #31 including #30, which is usually not what we want. Instead, try fol‐
lowing one of the following two patterns.
One option when we encounter a retriable error is to commit the last record we pro‐
cessed successfully. We’ll then store the records that still need to be processed in a
buffer (so the next poll won’t override them), use the consumer pause() method to
ensure that additional polls won’t return data, and keep trying to process the records.
A second option when encountering a retriable error is to write it to a separate topic
and continue. A separate consumer group can be used to handle retries from the
retry topic, or one consumer can subscribe to both the main topic and to the retry
topic but pause the retry topic between retries. This pattern is similar to the deadletter-queue system used in many messaging systems.
Using Consumers in a Reliable System | 175
Consumers may need to maintain state
In some applications, we need to maintain state across multiple calls to poll. For
example, if we want to calculate moving average, we’ll want to update the average
after every time we poll Kafka for new messages. If our process is restarted, we will
need to not just start consuming from the last offset, but we’ll also need to recover the
matching moving average. One way to do this is to write the latest accumulated value
to a “results” topic at the same time the application is committing the offset. This
means that when a thread is starting up, it can pick up the latest accumulated value
when it starts and pick up right where it left off. In Chapter 8, we discuss how an
application can write results and commit offsets in a single transaction. In general,
this is a rather complex problem to solve, and we recommend looking at a library like
Kafka Streams or Flink, which provides high-level DSL-like APIs for aggregation,
joins, windows, and other complex analytics.
Validating System Reliability
Once we have gone through the process of figuring out our reliability requirements,
configuring the brokers, configuring the clients, and using the APIs in the best way
for our use case, we can just relax and run everything in production, confident that
no event will ever be missed, right?
We recommend doing some validation first and suggest three layers of validation:
validate the configuration, validate the application, and monitor the application in
production. Let’s look at each of these steps and see what we need to validate and
how.
Validating Conguration
It is easy to test the broker and client configuration in isolation from the application
logic, and it is recommended to do so for two reasons:
• It helps to test if the configuration we’ve chosen can meet our requirements.
• It is a good exercise to reason through the expected behavior of the system.
Kafka includes two important tools to help with this validation. The
org.apache.kafka.tools package includes VerifiableProducer and Verifiable
Consumer classes. These can run as command-line tools or be embedded in an auto‐
mated testing framework.
The idea is that the verifiable producer produces a sequence of messages containing
numbers from 1 to a value we choose. We can configure the verifiable producer the
same way we configure our own producer, setting the right number of acks, retries,
delivery.timeout.ms, and rate at which the messages will be produced. When we
176 | Chapter 7: Reliable Data Delivery
run it, it will print success or error for each message sent to the broker, based on the
acks received. The verifiable consumer performs the complementary check. It con‐
sumes events (usually those produced by the verifiable producer) and prints out the
events it consumed in order. It also prints information regarding commits and
rebalances.
It is important to consider which tests we want to run. For example:
• Leader election: what happens if we kill the leader? How long does it take the
producer and consumer to start working as usual again?
• Controller election: how long does it take the system to resume after a restart of
the controller?
• Rolling restart: can we restart the brokers one by one without losing any
messages?
• Unclean leader election test: what happens when we kill all the replicas for a par‐
tition one by one (to make sure each goes out of sync) and then start a broker
that was out of sync? What needs to happen in order to resume operations? Is
this acceptable?
Then we pick a scenario, start the verifiable producer, start the verifiable consumer,
and run through the scenario—for example, kill the leader of the partition we are
producing data into. If we expected a short pause and then everything to resume nor‐
mally with no message loss, we need to make sure the number of messages produced
by the producer and the number of messages consumed by the consumer match.
The Apache Kafka source repository includes an extensive test suite. Many of the
tests in the suite are based on the same principle and use the verifiable producer and
consumer to make sure rolling upgrades work.
Validating Applications
Once we are sure the broker and client configuration meet our requirements, it is
time to test whether the application provides the guarantees we need. This will check
things like custom error-handling code, offset commits, and rebalance listeners and
similar places where the application logic interacts with Kafka’s client libraries.
Naturally, because application logic can vary considerably, there is only so much
guidance we can provide on how to test it. We recommend integration tests for the
application as part of any development process, and we recommend running tests
under a variety of failure conditions:
• Clients lose connectivity to one of the brokers
• High latency between client and broker
Validating System Reliability | 177
• Disk full
• Hanging disk (also called “brown out”)
• Leader election
• Rolling restart of brokers
• Rolling restart of consumers
• Rolling restart of producers
There are many tools that can be used to introduce network and disk faults, and
many are excellent, so we will not attempt to make specific recommendations.
Apache Kafka itself includes the Trogdor test framework for fault injection. For each
scenario, we will have expected behavior, which is what we planned on seeing when
we developed the application. Then we run the test to see what actually happens. For
example, when planning for a rolling restart of consumers, we planned for a short
pause as consumers rebalance and then continue consumption with no more than
1,000 duplicate values. Our test will show whether the way the application commits
offsets and handles rebalances actually works this way.
Monitoring Reliability in Production
Testing the application is important, but it does not replace the need to continuously
monitor production systems to make sure data is flowing as expected. Chapter 12 will
cover detailed suggestions on how to monitor the Kafka cluster, but in addition to
monitoring the health of the cluster, it is important to also monitor the clients and the
flow of data through the system.
Kafka’s Java clients include JMX metrics that allow monitoring client-side status and
events. For the producers, the two metrics most important for reliability are
error-rate and retry-rate per record (aggregated). Keep an eye on those, since error or
retry rates going up can indicate an issue with the system. Also monitor the producer
logs for errors that occur while sending events that are logged at WARN level, and say
something along the lines of “Got error produce response with correlation id 5689 on
topic-partition [topic-1,3], retrying (two attempts left). Error: …” When we see
events with 0 attempts left, the producer is running out of retries. In Chapter 3 we
discussed how to configure delivery.timeout.ms and retries to improve the error
handling in the producer and avoid running out of retries prematurely. Of course, it
is always better to solve the problem that caused the errors in the first place. ERROR
level log messages on the producer are likely to indicate that sending the message
failed completely due to nonretriable error, a retriable error that ran out of retries, or
a timeout. When applicable, the exact error from the broker will be logged as well.
On the consumer side, the most important metric is consumer lag. This metric indi‐
cates how far the consumer is from the latest message committed to the partition on
178 | Chapter 7: Reliable Data Delivery
the broker. Ideally, the lag would always be zero and the consumer will always read
the latest message. In practice, because calling poll() returns multiple messages and
then the consumer spends time processing them before fetching more messages, the
lag will always fluctuate a bit. What is important is to make sure consumers do even‐
tually catch up rather than fall further and further behind. Because of the expected
fluctuation in consumer lag, setting traditional alerts on the metric can be challeng‐
ing. Burrow is a consumer lag checker by LinkedIn and can make this easier.
Monitoring flow of data also means making sure all produced data is consumed in a
timely manner (“timely manner” is usually based on business requirements). In order
to make sure data is consumed in a timely manner, we need to know when the data
was produced. Kafka assists in this: starting with version 0.10.0, all messages include
a timestamp that indicates when the event was produced (although note that this can
be overridden either by the application that is sending the events or by the brokers
themselves if they are configured to do so).
To make sure all produced messages are consumed within a reasonable amount of
time, we will need the application producing the messages to record the number of
events produced (usually as events per second). The consumers need to record the
number of events consumed per unit or time, and the lag from the time events were
produced to the time they were consumed, using the event timestamp. Then we will
need a system to reconcile the events per second numbers from both the producer
and the consumer (to make sure no messages were lost on the way) and to make sure
the interval between produce time and consume time is reasonable. This type of endto-end monitoring systems can be challenging and time-consuming to implement. To
the best of our knowledge, there is no open source implementation of this type of sys‐
tem, but Confluent provides a commercial implementation as part of the Confluent
Control Center.
In addition to monitoring clients and the end-to-end flow of data, Kafka brokers
include metrics that indicate the rate of error responses sent from the brokers
to clients. We recommend collecting kafka.server:type=BrokerTopicMetrics,
name=FailedProduceRequestsPerSec and kafka.server:type=BrokerTopic
Metrics,name=FailedFetchRequestsPerSec. At times, some level of error responses
is expected—for example, if we shut down a broker for maintenance and new leaders
are elected on another broker, it is expected that producers will receive a
NOT_LEADER_FOR_PARTITION error, which will cause them to request updated meta‐
data before continuing to produce events as usual. Unexplained increases in failed
requests should always be investigated. To assist in such investigations, the failed
requests metrics are tagged with the specific error response that the broker sent.













<h3>Exactly-Once Semantics</h3>



At-least-once delivery (i.e. the guarantee that Kafka will not lose messages that it acknowledged as committed) still leaves open the possibility of duplicate messages.


In these cases, it is important to provide a stronger
guarantee—exactly-once processing semantics.


Exactly-once semantics in Kafka is a combination of two key features: idempotent producers, which help avoid duplicates caused by producer retries, and transactional
semantics, which guarantee exactly-once processing in stream processing applica‐
tions. We will discuss both, starting with the simpler and more generally useful idem‐
potent producer.

Idempotent Producer
A service is called idempotent if performing the same operation multiple times has
the same result as performing it a single time. In databases it is usually demonstrated
as the difference between UPDATE t SET x=x+1 where y=5 and UPDATE t SET x=18
where y=5. The first example is not idempotent; if we call it three times, we’ll end up
with a very different result than if we were to call it once. The second example is
idempotent—no matter how many times we run this statement, x will be equal to 18.
How is this related to a Kafka producer? If we configure a producer to have at-leastonce semantics rather than idempotent semantics, it means that in cases of uncer‐
tainty, the producer will retry sending the message so it will arrive at least once. These
retries could lead to duplicates.
The classic case is when a partition leader received a record from the producer, repli‐
cated it successfully to the followers, and then the broker on which the leader resides
crashed before it could send a response to the producer. The producer, after a certain
time without a response, will resend the message. The message will arrive at the new
leader, who already has a copy of the message from the previous attempt—resulting
in a duplicate.
In some applications duplicates don’t matter much, but in others they can lead to
inventory miscounts, bad financial statements, or sending someone two umbrellas
instead of the one they ordered.
Kafka’s idempotent producer solves this problem by automatically detecting and
resolving such duplicates.
How Does the Idempotent Producer Work?
When we enable the idempotent producer, each message will include a unique identi‐
fied producer ID (PID) and a sequence number. These, together with the target topic
and partition, uniquely identify each message. Brokers use these unique identifiers to
track the last five messages produced to every partition on the broker. To limit the
number of previous sequence numbers that have to be tracked for each partition, we
also require that the producers will use max.inflight.requests=5 or lower (the
default is 5).
When a broker receives a message that it already accepted before, it will reject the
duplicate with an appropriate error. This error is logged by the producer and is reflec‐
ted in its metrics but does not cause any exception and should not cause any alarm.
On the producer client, it will be added to the record-error-rate metric. On the
broker, it will be part of the ErrorsPerSec metric of the RequestMetrics type, which
includes a separate count for each type of error.
182 | Chapter 8: Exactly-Once Semantics
What if a broker receives a sequence number that is unexpectedly high? The broker
expects message number 2 to be followed by message number 3; what happens if the
broker receives message number 27 instead? In such cases the broker will respond
with an “out of order sequence” error, but if we use an idempotent producer without
using transactions, this error can be ignored.
While the producer will continue normally after encountering an
“out of order sequence number” exception, this error typically indi‐
cates that messages were lost between the producer and the
broker—if the broker received message number 2 followed by mes‐
sage number 27, something must have happened to messages 3 to
26. When encountering such an error in the logs, it is worth revisit‐
ing the producer and topic configuration and making sure the pro‐
ducer is configured with recommended values for high reliability
and to check whether unclean leader election has occurred.
As is always the case with distributed systems, it is interesting to consider the behav‐
ior of an idempotent producer under failure conditions. Consider two cases: pro‐
ducer restart and broker failure.
Producer restart
When a producer fails, usually a new producer will be created to replace it—whether
manually by a human rebooting a machine, or using a more sophisticated framework
like Kubernetes that provides automated failure recovery. The key point is that when
the producer starts, if the idempotent producer is enabled, the producer will initialize
and reach out to a Kafka broker to generate a producer ID. Each initialization of a
producer will result in a completely new ID (assuming that we did not enable trans‐
actions). This means that if a producer fails and the producer that replaces it sends a
message that was previously sent by the old producer, the broker will not detect the
duplicates—the two messages will have different producer IDs and different sequence
numbers and will be considered as two different messages. Note that the same is true
if the old producer froze and then came back to life after its replacement started—the
original producer is not recognized as a zombie, because we have two totally different
producers with different IDs.
Broker failure
When a broker fails, the controller elects new leaders for the partitions that had lead‐
ers on the failed broker. Say that we have a producer that produced messages to topic
A, partition 0, which had its lead replica on broker 5 and a follower replica on broker
3. After broker 5 fails, broker 3 becomes the new leader. The producer will discover
that the new leader is broker 3 via the metadata protocol and start producing to it.
Idempotent Producer | 183
But how will broker 3 know which sequences were already produced in order to
reject duplicates?
The leader keeps updating its in-memory producer state with the five last sequence
IDs every time a new message is produced. Follower replicas update their own inmemory buffers every time they replicate new messages from the leader. This means
that when a follower becomes a leader, it already has the latest sequence numbers in
memory, and validation of newly produced messages can continue without any issues
or delays.
But what happens when the old leader comes back? After a restart, the old inmemory producer state will no longer be in memory. To assist in recovery, brokers
take a snapshot of the producer state to a file when they shut down or every time a
segment is created. When the broker starts, it reads the latest state from a file. The
newly restarted broker then keeps updating the producer state as it catches up by rep‐
licating from the current leader, and it has the most current sequence IDs in memory
when it is ready to become a leader again.
What if a broker crashed and the last snapshot is not updated? Producer ID and
sequence ID are also part of the message format that is written to Kafka’s logs. During
crash recovery, the producer state will be recovered by reading the older snapshot and
also messages from the latest segment of each partition. A new snapshot will be
stored as soon as the recovery process completes.
An interesting question is what happens if there are no messages? Imagine that a cer‐
tain topic has two hours of retention time, but no new messages arrived in the last
two hours—there will be no messages to use to recover the state if a broker crashed.
Luckily, no messages also means no duplicates. We will start accepting messages
immediately (while logging a warning about the lack of state), and create the pro‐
ducer state from the new messages that arrive.
Limitations of the Idempotent Producer
Kafka’s idempotent producer only prevents duplicates in case of retries that are
caused by the producer’s internal logic. Calling producer.send() twice with the same
message will create a duplicate, and the idempotent producer won’t prevent it. This is
because the producer has no way of knowing that the two records that were sent are
in fact the same record. It is always a good idea to use the built-in retry mechanism of
the producer rather than catching producer exceptions and retrying from the applica‐
tion itself; the idempotent producer makes this pattern even more appealing—it is the
easiest way to avoid duplicates when retrying.
184 | Chapter 8: Exactly-Once Semantics
It is also rather common to have applications that have multiple instances or even one
instance with multiple producers. If two of these producers attempt to send identical
messages, the idempotent producer will not detect the duplication. This scenario is
fairly common in applications that get data from a source—a directory with files, for
instance—and produce it to Kafka. If the application happened to have two instances
reading the same file and producing records to Kafka, we will get multiple copies of
the records in that file.
The idempotent producer will only prevent duplicates caused by
the retry mechanism of the producer itself, whether the retry is
caused by producer, network, or broker errors. But nothing else.
How Do I Use the Kafka Idempotent Producer?
This is the easy part. Add enable.idempotence=true to the producer configuration.
If the producer is already configured with acks=all, there will be no difference in
performance. By enabling idempotent producer, the following things will change:
• To retrieve a producer ID, the producer will make one extra API call when start‐
ing up.
• Each record batch sent will include the producer ID and the sequence ID for the
first message in the batch (sequence IDs for each message in the batch are
derived from the sequence ID of the first message plus a delta). These new fields
add 96 bits to each record batch (producer ID is a long, and sequence is an inte‐
ger), which is barely any overhead for most workloads.
• Brokers will validate the sequence numbers from any single producer instance
and guarantee the lack of duplicate messages.
• The order of messages produced to each partition will be guaranteed, through all
failure scenarios, even if max.in.flight.requests.per.connection is set to
more than 1 (5 is the default and also the highest value supported by the idempo‐
tent producer).
Idempotent Producer | 185
Idempotent producer logic and error handling improved signifi‐
cantly in version 2.5 (both on the producer side and the broker
side) as a result of KIP-360. Prior to release 2.5, the producer state
was not always maintained for long enough, which resulted in fatal
UNKNOWN_PRODUCER_ID errors in various scenarios (parti‐
tion reassignment had a known edge case where the new replica
became the leader before any writes happened from a specific pro‐
ducer, meaning that the new leader had no state for that partition).
In addition, previous versions attempted to rewrite the sequence
IDs in some error scenarios, which could lead to duplicates. In
newer versions, if we encounter a fatal error for a record batch, this
batch and all the batches that are in flight will be rejected. The user
who writes the application can handle the exception and decide
whether to skip those records or retry and risk duplicates and
reordering.
Transactions
As we mentioned in the introduction to this chapter, transactions were added to
Kafka to guarantee the correctness of applications developed using Kafka Streams. In
order for a stream processing application to generate correct results, each input
record must be processed exactly one time, and its processing result will be reflected
exactly one time, even in case of failure. Transactions in Apache Kafka allow stream
processing applications to generate accurate results. This, in turn, enables developers
to use stream processing applications in use cases where accuracy is a key
requirement.
It is important to keep in mind that transactions in Kafka were developed specifically
for stream processing applications. And therefore they were built to work with the
“consume-process-produce” pattern that forms the basis of stream processing appli‐
cations. Use of transactions can guarantee exactly-once semantics in this context—the
processing of each input record will be considered complete after the application’s
internal state has been updated and the results were successfully produced to output
topics. In “What Problems Aren’t Solved by Transactions?” on page 191, we’ll explore
a few scenarios where Kafka’s exactly-once guarantees will not apply.
Transactions is the name of the underlying mechanism. Exactlyonce semantics or exactly-once guarantees is the behavior of a
stream processing application. Kafka Streams uses transactions to
implement its exactly-once guarantees. Other stream processing
frameworks, such as Spark Streaming or Flink, use different mech‐
anisms to provide their users with exactly-once semantics.
186 | Chapter 8: Exactly-Once Semantics
Transactions Use Cases
Transactions are useful for any stream processing application where accuracy is
important, and especially where stream processing includes aggregation and/or joins.
If the stream processing application only performs single record transformation and
filtering, there is no internal state to update, and even if duplicates were introduced in
the process, it is fairly straightforward to filter them out of the output stream. When
the stream processing application aggregates several records into one, it is much more
difficult to check whether a result record is wrong because some input records were
counted more than once; it is impossible to correct the result without reprocessing
the input.
Financial applications are typical examples of complex stream processing applications
where exactly-once capabilities are used to guarantee accurate aggregation. However,
because it is rather trivial to configure any Kafka Streams application to provide
exactly-once guarantees, we’ve seen it enabled in more mundane use cases, including,
for instance, chatbots.
What Problems Do Transactions Solve?
Consider a simple stream processing application: it reads events from a source topic,
maybe processes them, and writes results to another topic. We want to be sure that
for each message we process, the results are written exactly once. What can possibly
go wrong?
It turns out that quite a few things could go wrong. Let’s look at two scenarios.
Reprocessing caused by application crashes
After consuming a message from the source cluster and processing it, the application
has to do two things: produce the result to the output topic, and commit the offset of
the message that we consumed. Suppose that these two separate actions happen in
this order. What happens if the application crashes after the output was produced but
before the offset of the input was committed?
In Chapter 4, we discussed what happens when a consumer crashes. After a few sec‐
onds, the lack of heartbeat will trigger a rebalance, and the partitions the consumer
was consuming from will be reassigned to a different consumer. That consumer will
begin consuming records from those partitions, starting at the last committed offset.
This means that all the records that were processed by the application between the
last committed offset and the crash will be processed again, and the results will be
written to the output topic again—resulting in duplicates.
Transactions | 187
Reprocessing caused by zombie applications
What happens if our application just consumed a batch of records from Kafka and
then froze or lost connectivity to Kafka before doing anything else with this batch of
records?
Just like in the previous scenario, after several heartbeats are missed, the application
will be assumed dead and its partitions reassigned to another consumer in the con‐
sumer group. That consumer will reread that batch of records, process it, produce the
results to an output topic, and continue on.
Meanwhile, the first instance of the application—the one that froze—may resume its
activity: process the batch of records it recently consumed, and produce the results to
the output topic. It can do all that before it polls Kafka for records or sends a heart‐
beat and discovers that it is supposed to be dead and another instance now owns
those partitions.
A consumer that is dead but doesn’t know it is called a zombie. In this scenario, we
can see that without additional guarantees, zombies can produce data to the output
topic and cause duplicate results.
How Do Transactions Guarantee Exactly-Once?
Take our simple stream processing application. It reads data from one topic, pro‐
cesses it, and writes the result to another topic. Exactly-once processing means that
consuming, processing, and producing are done atomically. Either the offset of the
original message is committed and the result is successfully produced or neither of
these things happen. We need to make sure that partial results—where the offset is
committed but the result isn’t produced, or vice versa—can’t happen.
To support this behavior, Kafka transactions introduce the idea of atomic multiparti‐
tion writes. The idea is that committing offsets and producing results both involve
writing messages to partitions. However, the results are written to an output topic,
and offsets are written to the _consumer_offsets topic. If we can open a transaction,
write both messages, and commit if both were written successfully—or abort to retry
if they were not—we will get the exactly-once semantics that we are after.
Figure 8-1 illustrates a simple stream processing application, performing an atomic
multipartition write to two partitions while also committing offsets for the event it
consumed.
188 | Chapter 8: Exactly-Once Semantics
Figure 8-1. Transactional producer with atomic multipartition write
To use transactions and perform atomic multipartition writes, we use a transactional
producer. A transactional producer is simply a Kafka producer that is configured with
a transactional.id and has been initialized using initTransactions(). Unlike
producer.id, which is generated automatically by Kafka brokers, transactional.id
is part of the producer configuration and is expected to persist between restarts. In
fact, the main role of the transactional.id is to identify the same producer across
restarts. Kafka brokers maintain transactional.id to producer.id mapping, so if
initTransactions() is called again with an existing transactional.id, the pro‐
ducer will also be assigned the same producer.id instead of a new random number.
Preventing zombie instances of the application from creating duplicates requires a
mechanism for zombie fencing, or preventing zombie instances of the application
from writing results to the output stream. The usual way of fencing zombies—using
an epoch—is used here. Kafka increments the epoch number associated with a
transactional.id when initTransaction() is invoked to initialize a transactional
producer. Send, commit, and abort requests from producers with the same
transactional.id but lower epochs will be rejected with the FencedProducer error.
The older producer will not be able to write to the output stream and will be forced to
close(), preventing the zombie from introducing duplicate records. In Apache Kafka
2.5 and later, there is also an option to add consumer group metadata to the transac‐
tion metadata. This metadata will also be used for fencing, which will allow producers
with different transactional IDs to write to the same partitions while still fencing
against zombie instances.
Transactions are a producer feature for the most part—we create a transactional pro‐
ducer, begin the transaction, write records to multiple partitions, produce offsets in
order to mark records as already processed, and commit or abort the transaction. We
do all this from the producer. However, this isn’t quite enough—records written
transactionally, even ones that are part of transactions that were eventually aborted,
are written to partitions just like any other records. Consumers need to be configured
Transactions | 189
with the right isolation guarantees, otherwise we won’t have the exactly-once guaran‐
tees we expected.
We control the consumption of messages that were written transactionally by setting
the isolation.level configuration. If set to read_committed, calling
consumer.poll() after subscribing to a set of topics will return messages that were
either part of a successfully committed transaction or that were written nontransac‐
tionally; it will not return messages that were part of an aborted transaction or a
transaction that is still open. The default isolation.level value, read_uncommitted,
will return all records, including those that belong to open or aborted transactions.
Configuring read_committed mode does not guarantee that the application will get
all messages that are part of a specific transaction. It is possible to subscribe to only a
subset of topics that were part of the transaction and therefore get a subset of the
messages. In addition, the application can’t know when transactions begin or end, or
which messages are part of which transaction.
Figure 8-2 shows which records are visible to a consumer in read_committed mode
compared to a consumer with the default read_uncommitted mode.
Figure 8-2. Consumers in read_committed mode will lag behind consumers with default
configuration
To guarantee that messages will be read in order, read_committed mode will not
return messages that were produced after the point when the first still-open transac‐
tion began (known as the Last Stable Offset, or LSO). Those messages will be with‐
held until that transaction is committed or aborted by the producer, or until they
reach transaction.timeout.ms (default of 15 minutes) and are aborted by the
broker. Holding a transaction open for a long duration will introduce higher end-toend latency by delaying consumers.
Our simple stream processing job will have exactly-once guarantees on its output
even if the input was written nontransactionally. The atomic multipartition produce
guarantees that if the output records were committed to the output topic, the offset of
190 | Chapter 8: Exactly-Once Semantics
the input records was also committed for that consumer, and as a result the input
records will not be processed again.
What Problems Aren’t Solved by Transactions?
As explained earlier, transactions were added to Kafka to provide multipartition
atomic writes (but not reads) and to fence zombie producers in stream processing
applications. As a result, they provide exactly-once guarantees when used within
chains of consume-process-produce stream processing tasks. In other contexts, trans‐
actions will either straight-out not work or will require additional effort in order to
achieve the guarantees we want.
The two main mistakes are assuming that exactly-once guarantees apply on actions
other than producing to Kafka, and that consumers always read entire transactions
and have information about transaction boundaries.
The following are a few scenarios in which Kafka transactions won’t help achieve
exactly-once guarantees.
Side effects while stream processing
Let’s say that the record processing step in our stream processing app includes send‐
ing email to users. Enabling exactly-once semantics in our app will not guarantee that
the email will only be sent once. The guarantee only applies to records written to
Kafka. Using sequence numbers to deduplicate records or using markers to abort or
to cancel a transaction works within Kafka, but it will not un-send an email. The
same is true for any action with external effects that is performed within the stream
processing app: calling a REST API, writing to a file, etc.
Reading from a Kafka topic and writing to a database
In this case, the application is writing to an external database rather than to Kafka. In
this scenario, there is no producer involved—records are written to the database
using a database driver (likely JDBC) and offsets are committed to Kafka within the
consumer. There is no mechanism that allows writing results to an external database
and committing offsets to Kafka within a single transaction. Instead, we could man‐
age offsets in the database (as explained in Chapter 4) and commit both data and off‐
sets to the database in a single transaction—this would rely on the database’s
transactional guarantees rather than Kafka’s.
Transactions | 191
Microservices often need to update the database and publish a
message to Kafka within a single atomic transaction, so either both
will happen or neither will. As we’ve just explained in the last two
examples, Kafka transactions will not do this.
A common solution to this common problem is known as the out‐
box pattern. The microservice only publishes the message to a
Kafka topic (the “outbox”), and a separate message relay service
reads the event from Kafka and updates the database. Because, as
we’ve just seen, Kafka won’t guarantee an exactly-once update to
the database, it is important to make sure the update is idempotent.
Using this pattern guarantees that the message will eventually make
it to Kafka, the topic consumers, and the database—or to none of
those.
The inverse pattern—where a database table serves as the outbox
and a relay service makes sure updates to the table will also arrive
to Kafka as messages—is also used. This pattern is preferred when
built-in RDBMS constraints, such as uniqueness and foreign keys,
are useful. The Debezium project published an in-depth blog post
on the outbox pattern with detailed examples.
Reading data from a database, writing to Kafka, and from there writing to another database
It is very tempting to believe that we can build an app that will read data from a data‐
base, identify database transactions, write the records to Kafka, and from there write
records to another database, still maintaining the original transactions from the
source database.
Unfortunately, Kafka transactions don’t have the necessary functionality to support
these kinds of end-to-end guarantees. In addition to the problem with committing
both records and offsets within the same transaction, there is another difficulty:
read_committed guarantees in Kafka consumers are too weak to preserve database
transactions. Yes, a consumer will not see records that were not committed. But it is
not guaranteed to have seen all the records that were committed within the transac‐
tion because it could be lagging on some topics; it has no information to identify
transaction boundaries, so it can’t know when a transaction began and ended, and
whether it has seen some, none, or all of its records.
Copying data from one Kafka cluster to another
This one is more subtle—it is possible to support exactly-once guarantees when copy‐
ing data from one Kafka cluster to another. There is a description of how this is done
in the Kafka improvement proposal for adding exactly-once capabilities in Mirror‐
Maker 2.0. At the time of this writing, the proposal is still in draft, but the algorithm
is clearly described. This proposal includes the guarantee that each record in the
source cluster will be copied to the destination cluster exactly once.
192 | Chapter 8: Exactly-Once Semantics
However, this does not guarantee that transactions will be atomic. If an app produces
several records and offsets transactionally, and then MirrorMaker 2.0 copies them to
another Kafka cluster, the transactional properties and guarantees will be lost during
the copy process. They are lost for the same reason when copying data from Kafka to
a relational database: the consumer reading data from Kafka can’t know or guarantee
that it is getting all the events in a transaction. For example, it can replicate part of a
transaction if it is only subscribed to a subset of the topics.
Publish/subscribe pattern
Here’s a slightly more subtle case. We’ve discussed exactly-once in the context of the
consume-process-produce pattern, but the publish/subscribe pattern is a very com‐
mon use case. Using transactions in a publish/subscribe use case provides some guar‐
antees: consumers configured with read_committed mode will not see records that
were published as part of a transaction that was aborted. But those guarantees fall
short of exactly-once. Consumers may process a message more than once, depending
on their own offset commit logic.
The guarantees Kafka provides in this case are similar to those provided by JMS
transactions but depend on consumers in read_committed mode to guarantee that
uncommitted transactions will remain invisible. JMS brokers withhold uncommitted
transactions from all consumers.
An important pattern to avoid is publishing a message and then
waiting for another application to respond before committing the
transaction. The other application will not receive the message
until after the transaction was committed, resulting in a deadlock.
How Do I Use Transactions?
Transactions are a broker feature and part of the Kafka protocol, so there are multiple
clients that support transactions.
The most common and most recommended way to use transactions is to enable
exactly-once guarantees in Kafka Streams. This way, we will not use transactions
directly at all, but rather Kafka Streams will use them for us behind the scenes to pro‐
vide the guarantees we need. Transactions were designed with this use case in mind,
so using them via Kafka Streams is the easiest and most likely to work as expected.
To enable exactly-once guarantees for a Kafka Streams application, we simply set the
processing.guarantee configuration to either exactly_once or exactly_once_
beta. That’s it.
Transactions | 193
exactly_once_beta is a slightly different method of handling
application instances that crash or hang with in-flight transactions.
This was introduced in release 2.5 to Kafka brokers, and in release
2.6 to Kafka Streams. The main benefit of this method is the ability
to handle many partitions with a single transactional producer and
therefore create more scalable Kafka Streams applications. There is
more information about the changes in the Kafka improvement
proposal where they were first discussed.
But what if we want exactly-once guarantees without using Kafka Streams? In this
case we will use transactional APIs directly. Here’s a snippet showing how this will
work. There is a full example in the Apache Kafka GitHub, which includes a demo
driver and a simple exactly-once processor that runs in separate threads:
Properties producerProps = new Properties();
producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
producerProps.put(ProducerConfig.CLIENT_ID_CONFIG, "DemoProducer");
producerProps.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, transactionalId);
producer = new KafkaProducer<>(producerProps);
Properties consumerProps = new Properties();
consumerProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
consumerProps.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);
props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false");
consumerProps.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, "read_committed");
consumer = new KafkaConsumer<>(consumerProps);
producer.initTransactions();
consumer.subscribe(Collections.singleton(inputTopic));
while (true) {
 try {
 ConsumerRecords<Integer, String> records =
 consumer.poll(Duration.ofMillis(200));
 if (records.count() > 0) {
 producer.beginTransaction();
 for (ConsumerRecord<Integer, String> record : records) {
 ProducerRecord<Integer, String> customizedRecord = transform(record);
 producer.send(customizedRecord);
 }
 Map<TopicPartition, OffsetAndMetadata> offsets = consumerOffsets();
 producer.sendOffsetsToTransaction(offsets, consumer.groupMetadata());
 producer.commitTransaction();
 }
 } catch (ProducerFencedException|InvalidProducerEpochException e) {
 throw new KafkaException(String.format(
 "The transactional.id %s is used by another process", transactionalId));
194 | Chapter 8: Exactly-Once Semantics
 } catch (KafkaException e) {
 producer.abortTransaction();
 resetToLastCommittedPositions(consumer);
 }}
Configuring a producer with transactional.id makes it a transactional pro‐
ducer capable of producing atomic multipartition writes. The transactional ID
must be unique and long-lived. Essentially it defines an instance of the
application.
Consumers that are part of the transactions don’t commit their own offsets—the
producer writes offsets as part of the transaction. So offset commit should be
disabled.
In this example, the consumer reads from an input topic. We will assume that the
records in the input topic were also written by a transactional producer (just for
fun—there is no such requirement for the input). To read transactions cleanly
(i.e., ignore in-flight and aborted transactions), we will set the consumer isolation
level to read_committed. Note that the consumer will still read nontransactional
writes, in addition to reading committed transactions.
The first thing a transactional producer must do is initialize. This registers the
transactional ID, bumps up the epoch to guarantee that other producers with the
same ID will be considered zombies, and aborts older in-flight transactions from
the same transactional ID.
Here we are using the subscribe consumer API, which means that partitions
assigned to this instance of the application can change at any point as a result of
rebalance. Prior to release 2.5, which introduced API changes from KIP-447, this
was much more challenging. Transactional producers had to be statically
assigned a set of partitions, because the transaction fencing mechanism relied on
the same transactional ID being used for the same partitions (there was no zom‐
bie fencing protection if the transactional ID changed). KIP-447 added new APIs,
used in this example, that attach consumer-group information to the transaction,
and this information is used for fencing. When using this method, it also makes
sense to commit transactions whenever the related partitions are revoked.
We consumed records, and now we want to process them and produce results.
This method guarantees that everything that is produced from the time it was
called, until the transaction is either committed or aborted, is part of a single
atomic transaction.
This is where we process the records—all our business logic goes here.
Transactions | 195
As we explained earlier in the chapter, it is important to commit the offsets as
part of the transaction. This guarantees that if we fail to produce results, we won’t
commit the offsets for records that were not, in fact, processed. This method
commits offsets as part of the transaction. Note that it is important not to com‐
mit offsets in any other way—disable offset auto-commit, and don’t call any of
the consumer commit APIs. Committing offsets by any other method does not
provide transactional guarantees.
We produced everything we needed, we committed offsets as part of the transac‐
tion, and it is time to commit the transaction and seal the deal. Once this method
returns successfully, the entire transaction has made it through, and we can con‐
tinue to read and process the next batch of events.
If we got this exception, it means we are the zombie. Somehow our application
froze or disconnected, and there is a newer instance of the app with our transac‐
tional ID running. Most likely the transaction we started has already been abor‐
ted and someone else is processing those records. Nothing to do but die
gracefully.
If we got an error while writing a transaction, we can abort the transaction, set
the consumer position back, and try again.
Transactional IDs and Fencing
Choosing the transactional ID for producers is important and a bit more challenging
than it seems. Assigning the transactional ID incorrectly can lead to either applica‐
tion errors or loss of exactly-once guarantees. The key requirements are that the
transactional ID will be consistent for the same instance of the application between
restarts and is different for different instances of the application, otherwise the brok‐
ers will not be able to fence off zombie instances.
Until release 2.5, the only way to guarantee fencing was to statically map the transac‐
tional ID to partitions. This guaranteed that each partition will always be consumed
with the same transactional ID. If a producer with transactional ID A processed mes‐
sages from topic T and lost connectivity, and the new producer that replaces it has
transactional ID B, and later producer A comes back as a zombie, zombie A will not
be fenced because the ID doesn’t match that of the new producer B. We want pro‐
ducer A to always be replaced by producer A, and the new producer A will have a
higher epoch number and zombie A will be properly fenced away. In those releases,
the previous example would be incorrect—transactional IDs are assigned randomly
to threads without making sure the same transactional ID is always used to write to
the same partition.
196 | Chapter 8: Exactly-Once Semantics
In Apache Kafka 2.5, KIP-447 introduced a second method of fencing based on con‐
sumer group metadata for fencing in addition to transactional IDs. We use the pro‐
ducer offset commit method and pass as an argument the consumer group metadata
rather than just the consumer group ID.
Let’s say that we have topic T1 with two partitions, t-0 and t-1. Each is consumed by a
separate consumer in the same group; each consumer passes records to a matching
transactional producer—one with transactional ID A and the other with transactional
ID B; and they are writing output to topic T2 partitions 0 and 1, respectively.
Figure 8-3 illustrates this scenario.
Figure 8-3. Transactional record processor
As illustrated in Figure 8-4, if the application instance with consumer A and producer
A becomes a zombie, consumer B will start processing records from both partitions.
If we want to guarantee that no zombies write to partition 0, consumer B can’t just
start reading from partition 0 and writing to partition 0 with transactional ID B.
Instead the application will need to instantiate a new producer, with transactional ID
A, to safely write to partition 0 and fence the old transactional ID A. This is wasteful.
Instead, we include the consumer group information in the transactions. Transac‐
tions from producer B will show that they are from a newer generation of the
consumer group, and therefore they will go through, while transactions from the
now-zombie producer A will show an old generation of the consumer group and will
be fenced.
Figure 8-4. Transactional record processor after a rebalance
Transactions | 197
How Transactions Work
We can use transactions by calling the APIs without understanding how they work.
But having some mental model of what is going on under the hood will help us trou‐
bleshoot applications that do not behave as expected.
The basic algorithm for transactions in Kafka was inspired by Chandy-Lamport snap‐
shots, in which “marker” control messages are sent into communication channels,
and consistent state is determined based on the arrival of the marker. Kafka transac‐
tions use marker messages to indicate that transactions are committed or aborted
across multiple partitions—when the producer decides to commit a transaction, it
sends a “commit” message to the transaction coordinator, which then writes commit
markers to all partitions involved in a transaction. But what happens if the producer
crashes after only writing commit messages to a subset of the partitions? Kafka trans‐
actions solve this by using two-phase commit and a transaction log. At a high level,
the algorithm will:
1. Log the existence of an ongoing transaction, including the partitions involved
2. Log the intent to commit or abort—once this is logged, we are doomed to com‐
mit or abort eventually
3. Write all the transaction markers to all the partitions
4. Log the completion of the transaction
To implement this basic algorithm, Kafka needs a transaction log. We use an internal
topic called __transaction_state.
Let’s see how this algorithm works in practice by going through the inner workings of
the transactional API calls we’ve used in the preceding code snippet.
Before we begin the first transaction, producers need to register as transactional by
calling initTransaction(). This request is sent to a broker that will be the transac‐
tion coordinator for this transactional producer. Each broker is the transactional coor‐
dinator for a subset of the producers, just like each broker is the consumer group
coordinator for a subset of the consumer groups. The transaction coordinator for
each transactional ID is the leader of the partition of the transaction log the transac‐
tional ID is mapped to.
The initTransaction() API registers a new transactional ID with the coordinator,
or increments the epoch of an existing transactional ID in order to fence off previous
producers that may have become zombies. When the epoch is incremented, pending
transactions will be aborted.
198 | Chapter 8: Exactly-Once Semantics
The next step for the producer is to call beginTransaction(). This API call isn’t part
of the protocol—it simply tells the producer that there is now a transaction in pro‐
gress. The transaction coordinator on the broker side is still unaware that the transac‐
tion began. However, once the producer starts sending records, each time the
producer detects that it is sending records to a new partition, it will also send Add
PartitionsToTxnRequest to the broker informing it that there is a transaction in
progress for this producer, and that additional partitions are part of the transaction.
This information will be recorded in the transaction log.
When we are done producing results and are ready to commit, we start by commit‐
ting offsets for the records we’ve processed in this transaction. Committing offsets
can be done at any time but must be done before the transaction is committed. Call‐
ing sendOffsetsToTransaction() will send a request to the transaction coordinator
that includes the offsets and also the consumer group ID. The transaction coordina‐
tor will use the consumer group ID to find the group coordinator and commit the
offsets as a consumer group normally would.
Now it is time to commit—or abort. Calling commitTransaction() or abort
Transaction() will send an EndTransactionRequest to the transaction coordinator.
The transaction coordinator will log the commit or abort intention to the transaction
log. Once this step is successful, it is the transaction coordinator’s responsibility to
complete the commit (or abort) process. It writes a commit marker to all the parti‐
tions involved in the transaction, then writes to the transaction log that the commit
completed successfully. Note that if the transaction coordinator shuts down or
crashes after logging the intention to commit and before completing the process, a
new transaction coordinator will be elected, pick up the intent to commit from the
transaction log, and complete the process.
If a transaction is not committed or aborted within transaction.timeout.ms, the
transaction coordinator will abort it automatically.
Transactions | 199
Each broker that receives records from transactional or idempotent
producers will store the producer/transactional IDs in memory,
together with related state for each of the last five batches sent by
the producer: sequence numbers, offsets, and such. This state is
stored for transactional.id.expiration.ms milliseconds after
the producer stopped being active (seven days by default). This
allows the producer to resume activity without running into
UNKNOWN_PRODUCER_ID errors. It is possible to cause something sim‐
ilar to a memory leak in the broker by creating new idempotent
producers or new transactional IDs at a very high rate but never
reusing them. Three new idempotent producers per second, accu‐
mulated over the course of a week, will result in 1.8 million pro‐
ducer state entries with a total of 9 million batch metadata stored,
using around 5 GB RAM. This can cause out-of-memory or severe
garbage collection issues on the broker. We recommend architect‐
ing the application to initialize a few long-lived producers when the
application starts up, and then reuse them for the lifetime of
the application. If this isn’t possible (Function as a Service makes
this difficult), we recommend lowering transactional.id.
expiration.ms so the IDs will expire faster, and therefore old state
that will never be reused won’t take up a significant part of the
broker memory.
Performance of Transactions
Transactions add moderate overhead to the producer. The request to register transac‐
tional ID occurs once in the producer lifecycle. Additional calls to register partitions
as part of a transaction happen at most one per partition for each transaction, then
each transaction sends a commit request, which causes an extra commit marker to be
written on each partition. The transactional initialization and transaction commit
requests are synchronous, so no data will be sent until they complete successfully, fail,
or time out, which further increases the overhead.
Note that the overhead of transactions on the producer is independent of the number
of messages in a transaction. So a larger number of messages per transaction will both
reduce the relative overhead and reduce the number of synchronous stops, resulting
in higher throughput overall.
On the consumer side, there is some overhead involved in reading commit markers.
The key impact that transactions have on consumer performance is introduced by the
fact that consumers in read_committed mode will not return records that are part of
an open transaction. Long intervals between transaction commits mean that the con‐
sumer will need to wait longer before returning messages, and as a result, end-to-end
latency will increase.
200 | Chapter 8: Exactly-Once Semantics
Note, however, that the consumer does not need to buffer messages that belong to
open transactions. The broker will not return those in response to fetch requests
from the consumer. Since there is no extra work for the consumer when reading
transactions, there is no decrease in throughput either.
Summary
Exactly-once semantics in Kafka is the opposite of chess: it is challenging to under‐
stand but easy to use.
This chapter covered the two key mechanisms that provide exactly-once guarantees
in Kafka: idempotent producer, which avoids duplicates that are caused by the retry
mechanism, and transactions, which form the basis of exactly-once semantics in
Kafka Streams.
Both can be enabled in a single configuration and allow us to use Kafka for applica‐
tions that require fewer duplicates and stronger correctness guarantees.
We discussed in depth specific scenarios and use cases to show the expected behavior,
and even looked at some of the implementation details. Those details are important
when troubleshooting applications or when using transactional APIs directly.
By understanding what Kafka’s exactly-once semantics guarantee in which use case,
we can design applications that will use exactly-once when necessary. Application
behavior should not be surprising, and the information in this chapter will help us
avoid surprises.


<h3>Administration</h3>

<h4>Configuration</h4>

<pre><code class="bash"># default broker configuration
$ kafka-configs.sh --bootstrap-server localhost:9092 --describe --entity-type brokers --entity-default
$ kafka-configs.sh --bootstrap-server localhost:9092 --alter --entity-type brokers --entity-default --add-config KEY=VALUE
$ kafka-configs.sh --bootstrap-server localhost:9092 --alter --entity-type brokers --entity-default --delete-config KEY

# broker configuration
$ kafka-configs.sh --bootstrap-server localhost:9092 --describe --entity-type brokers --entity-name 0
$ kafka-configs.sh --bootstrap-server localhost:9092 --alter --entity-type brokers --entity-name 0 --add-config KEY=VALUE
$ kafka-configs.sh --bootstrap-server localhost:9092 --alter --entity-type brokers --entity-name 0 --delete-config KEY

# topic configuration
$ kafka-configs.sh --bootstrap-server :9092 --describe --entity-type topics --entity-name t1
$ kafka-configs.sh --bootstrap-server :9092 --alter --entity-type topics --entity-name t1 --add-config KEY=VALUE
$ kafka-configs.sh --bootstrap-server :9092 --alter --entity-type topics --entity-name t1 --delete-config KEY</code></pre>


<h4>Topics</h4>

<pre><code class="bash"># list topics
$ kafka-topics.sh --bootstrap-server :9092 --list

# describe topics
$ kafka-topics.sh --bootstrap-server :9092 --describe

# describe specific topic
$ kafka-topics.sh --bootstrap-server :9092 --describe --topic t0

# show all partitions where one or more of the replicas for the partition are not in-sync with the leader
$ kafka-topics.sh --bootstrap-server :9092 --describe --under-replicated-partitions

# show all partition without a leader
$ kafka-topics.sh --bootstrap-server :9092 --describe --unavailable-partitions

# create new topic
$ kafka-topics.sh --bootstrap-server :9092 --create --topic t0 --partitions 3 --replication-factor 1

# alter number of partitions
$ kafka-topics.sh --bootstrap-server :9092 --alter --topic t0 --partitions 4

# delete topic
$ kafka-topics.sh --bootstrap-server :9092 --delete --topic t0</code></pre>


<h4>Consumer Groups</h4>

<pre><code class="bash"># list consumer groups
$ kafka-consumer-groups.sh --bootstrap-server :9092 --list

# describe consumer group
$ kafka-consumer-groups.sh --bootstrap-server :9092 --describe --group g0</code></pre>


<h4>Console Producers</h4>

<pre><code class="bash"># produce records with values to topic
$ kafka-console-producer.sh --broker-list :9092 --topic t0
> value
> ... ^C

# produce messages with keys to topic
$ kafka-console-producer.sh --broker-list :9092 --topic t0 --property parse.key=true --property key.separator=":"
> key:value
> ... ^C

# wait for messages to be acknowledged before sending the next one
$ kafka-console-producer.sh --broker-list :9092 --topic t0 --sync

# produce messages from file
$ kafka-console-producer.sh --broker-list :9092 --topic t0 &lt; text.txt</code></pre>


<h4>Console Producers</h4>

<pre><code class="bash"># consume messages from topic
$ kafka-console-consumer.sh --bootstrap-server :9092 --topic t0

# consume messages with keys from topic
$ kafka-console-consumer.sh --bootstrap-server :9092 --topic t0 --property print.key=true --property key.separator=":"

# join group and consume messages from topic
$ kafka-console-consumer.sh --bootstrap-server :9092 --topic t0 --group g0

# consume messages from topic from the first message
$ kafka-console-consumer.sh --bootstrap-server :9092 --topic t0 --from-beginning

# consume messages from particular partition
$ kafka-console-consumer.sh --bootstrap-server :9092 --topic t0 --partition 0</code></pre>

<!-- 
Replica Verification


$ kafka-replica-verification.sh --broker-list :9092
$ kafka-replica-verification.sh --broker-list :9092 --topic-white-list t1
$ kafka-replica-verification.sh --broker-list :9092 --topic-white-list t.*
-->


<h3 id="resources">Resources</h3>

<ul>
  <li>
    <a href="https://kafka.apache.org/documentation/">Official Documentation</a>
  </li>
  <li>
    <a href="https://www.youtube.com/watch?v=qu96DFXtbG4&list=PLa7VYi0yPIH0KbnJQcMv5N9iW8HkZHztH">Kafka 101</a>
  </li>
  <li>
    <a href="https://www.youtube.com/watch?v=-DyWhcX3Dpc&list=PLa7VYi0yPIH2PelhRHoFR5iQgflg-y6JA&index=1">Kafka Fundamentals</a>
  </li>
  <li>
    <a href="https://www.youtube.com/watch?v=v2RJQELoM6Y">Is Kafka a Database?</a>
  </li>
  <li>
    <a href="https://eng.uber.com/reliable-reprocessing/">Building Dead Letter Queues with Kafka</a>
  </li>
  <li>
    <a href="https://www.confluent.io/blog/hands-free-kafka-replication-a-lesson-in-operational-simplicity/">Hands-free Kafka Replication</a>
  </li>
</ul>

<!-- 
https://www.datadoghq.com/blog/monitoring-kafka-performance-metrics/
-->










<!-- KAFKA IN ACTION -->

3 5 6 7 8 9

A.3.2 Prerequisite: ZooKeeper
At the time of writing, Kafka also requires ZooKeeper, which is bundled with the Kafka
download. Even with the reduced dependency on ZooKeeper from the client side in
recent versions, Kafka needs a running installation of ZooKeeper to work. The
Apache Kafka distribution includes a compatible version of ZooKeeper; you don’t
need to download and install it separately. The required scripts to start and stop ZooKeeper are also included in the Kafka distribution.
A.3.3 Prerequisite: Kafka download
At the time of this book’s publication, Kafka version 2.7.1 (the version used in our
examples) was a recent release. The Apache® project has mirrors, and you can search
for the version to download in that way. To be automatically redirected to the nearest
mirror, use this URL: http://mng.bz/aZo7.
 After downloading the file, take a look at the actual binary filename. It might seem
a little confusing at first. For example, kafka_2.13-2.7.1 means the Kafka version is
2.7.1 (the information after the hyphen).
 To get the most out of the examples in this book while still making things easy to get
started, we recommend that you set up a three-node cluster on a single machine. This
is not a recommended strategy for production, however, but it will allow you to understand critical concepts without the overhead of spending a lot of time on the setup.
NOTE Why bother to use a three-node cluster? Kafka’s various parts as a distributed system lend themselves to more than one node. Our examples simulate a cluster without the need for different machines in the hope of clarifying
what you are learning.
Installing Kafka on your local machine 229
After you install Kafka, you need to configure a three-node cluster. First, you need to
unpack the binary and locate the bin directory.
 Listing A.1 shows the tar command used to unpack the JAR file, but you might
need to use unzip or another tool, depending on your downloaded compression format [3]. It’s a good idea to include the Kafka scripts bin directory in your $PATH environment variable. In this case, the commands are available without specifying a full
path to them.
$ tar -xzf kafka_2.13-2.7.1.tgz
$ mv kafka_2.13-2.7.1 ~/
$ cd ~/kafka_2.13-2.7.1
$ export PATH=$PATH:~/kafka_2.13-2.7.1/bin
NOTE For Windows users, you’ll find the .bat scripts under the bin/windows
folder with the same names as the shell scripts used in the following examples. You can use Windows Subsystem for Linux 2 (WSL2) and run the same
commands as you would use on Linux [1].
A.3.4 Starting a ZooKeeper server
The examples in this book use a single, local ZooKeeper server. The command in listing A.2 starts a single ZooKeeper server [2]. Note that you’ll want to start ZooKeeper
before you begin any Kafka brokers.
$ cd ~/kafka_2.13-2.7.1
$ bin/zookeeper-server-start.sh config/zookeeper.properties
A.3.5 Creating and configuring a cluster by hand
The next step is to create and configure a three-node cluster. To create your Kafka
cluster, you’ll set up three servers (brokers): server0, server1, and server2. We will
modify the property files for each server [2].
 Kafka comes with a set of predefined defaults. Run the commands in listing A.3 to
create configuration files for each server in your cluster [2]. We will use the default
server.properties file as a starting point. Then run the command in listing A.4 to open
each configuration file and change the properties file [2].
$ cd ~/kafka_2.13-2.7.1
$ cp config/server.properties config/server0.properties
$ cp config/server.properties config/server1.properties
$ cp config/server.properties config/server2.properties
Listing A.1 Unpacking the Kafka binary
Listing A.2 Starting ZooKeeper
Listing A.3 Creating multiple Kafka brokers
Adds the bin directory
to your shell $PATH
After moving to your
Kafka directory, makes
three copies of the default
server.properties file
230 APPENDIX A Installation
NOTE In our examples, we use vi as our text editor, but you can edit these
files with a text editor of your choice.
$ vi config/server0.properties
broker.id=0
listeners=PLAINTEXT://localhost:9092
log.dirs= /tmp/kafkainaction/kafka-logs-0
$ vi config/server1.properties
broker.id=1
listeners=PLAINTEXT://localhost:9093
log.dirs= /tmp/kafkainaction/kafka-logs-1
$ vi config/server2.properties
broker.id=2
listeners=PLAINTEXT://localhost:9094
log.dirs= /tmp/kafkainaction/kafka-logs-2
NOTE Each Kafka broker runs on its port and uses a separate log directory. It
is also critical that each configuration file has a unique ID for each broker
because each broker uses its own ID to register itself as a member of the cluster. You will usually see your broker IDs start at 0, following a zero-based arrayindexing scheme.
After this, you can start each broker using the built-in scripts that are part of the initial
installation (along with the configuration files that you updated in listing A.4). If you
want to observe the Kafka broker output in the terminal, we recommend starting each
process in a separate terminal tab or window and leaving them running. The following listing starts Kafka in a console window [2].
$ cd ~/kafka_2.13-2.7.1
$ bin/kafka-server-start.sh config/server0.properties
$ bin/kafka-server-start.sh config/server1.properties
$ bin/kafka-server-start.sh config/server2.properties
TIP If you close a terminal or your process hangs, do not forget about running the jps command [4]. That command will help you find the Java processes you might need to kill.
Listing A.6 shows an example from one author’s machine where you can get the brokers’ PIDs and ZooKeeper’s JVM process label (QuorumPeerMain) in the output from
the three brokers and the ZooKeeper instance. The process ID numbers for each
instance are on the left and will likely be different each time you run the start scripts.
Listing A.4 Configure server 0
Listing A.5 Starting Kafka in a console window
Updates id, port, and log
directory for broker ID 0
Updates id, port, and log
directory for broker ID 1
Updates id, port, and log
directory for broker ID 2
After moving to your Kafka
directory, starts each
broker process (3 total)
Confluent Platform 231
2532 Kafka
2745 Kafka
2318 Kafka
2085 QuorumPeerMain
Now that you know how to configure a local installation manually, let’s look at using
the Confluent Platform. Confluent Inc. (https://www.confluent.io/) offers the Confluent Platform, a platform based on Apache Kafka.
A.4 Confluent Platform
The Confluent Platform (find more at https://www.confluent.io/) is an enterpriseready packaging option that complements Apache Kafka with essential development
capabilities. It includes packages for Docker, Kubernetes, Ansible, and various others.
Confluent actively develops and supports Kafka clients for C++, C#/.NET, Python, and
Go. It also includes the Schema Registry, which we talk about in chapters 3 and 11.
Further, the Confluent Platform Community Edition includes ksqlDB. You learn
about stream processing with ksqlDB in chapter 12.
 Confluent also provides a fully managed, cloud-native Kafka service, which might
come in handy for later projects. A managed service provides Apache Kafka experience without requiring knowledge on how to run it. This is a characteristic that keeps
developers focused on what matters, which is coding. The Confluent version 6.1.1
download includes Apache Kafka version 2.7.1, which is used throughout this book.
You can follow easy installation steps from official Confluent documentation at http://
mng.bz/g1oV.
A.4.1 Confluent command line interface (CLI)
Confluent, Inc. also has command line tools to quickly start and manage its Confluent
Platform from the command line. A README.md on https://github.com/conflu
entinc/confluent-cli contains more details on the script usage and can be installed
with instructions from http://mng.bz/RqNR. The CLI is helpful in that it starts multiple parts of your product as needed.
A.4.2 Docker
Apache Kafka doesn’t provide official Docker images at this time, but Confluent does.
Those images are tested, supported, and used by many developers in production. In
the repository of examples for this book, you’ll find a docker-compose.yaml file with
preconfigured Kafka, ZooKeeper, and other components. To get all the components
up and running, issue the command docker-compose up -d in the directory with the
YAML file as the following listing shows.
NOTE If you are unfamiliar with Docker or don’t have it installed, check out
the official documentation at https://www.docker.com/get-started. You’ll find
instructions on installation at that site as well.
Listing A.6 jps output for ZooKeeper and three brokers
Kafka JVM process label
and ID for each broker ZooKeeper JVM
process label and ID
232 APPENDIX A Installation
$ git clone \
https://github.com/Kafka-In-Action-Book/Kafka-In-Action-Source-Code.git
$ cd ./Kafka-In-Action-Source-Code
$ docker-compose up -d
Creating network "kafka-in-action-code_default" with the default driver
Creating Zookeeper... done
Creating broker2 ... done
Creating broker1 ... done
Creating broker3 ... done
Creating schema-registry ... done
Creating ksqldb-server ... done
Creating ksqldb-cli ... done
$ docker ps --format "{{.Names}}: {{.State}}"
ksqldb-cli: running
ksqldb-server: running
schema-registry: running
broker1: running
broker2: running
broker3: running
zookeeper: running
A.5 How to work with the book examples
You can use any IDE to open and run companion code for this book. Here are a few
suggestions for you:
 IntelliJ IDEA Community Edition (https://www.jetbrains.com/idea/download/)
 Apache Netbeans (https://netbeans.org)
 VS Code for Java (https://code.visualstudio.com/docs/languages/java)
 Eclipse STS (https://spring.io/tools)
A.5.1 Building from the command line
If you want to build from the command line, a few more steps are needed. The Java 11
examples in this book are built with Maven 3.6.3. You should be able to create the JAR
for each chapter when running from the root of the chapter directory in the folder
that contains the pom.xml file and issuing either ./mvnw verify or ./mvnw --projects KafkaInAction_Chapter2 verify from the root project level.
 We use the Maven Wrapper tool (http://mng.bz/20yo), so if you don’t have Maven
installed, either of the previous commands will download and run Maven for you. To
run a specific class, you will need to supply a Java class that contains a main method as
an argument after the path to your JAR. The following listing demonstrates how to
run a generic Java class from chapter 2.
NOTE You must use a JAR that has been built with all the dependencies to
run the command successfully.
Listing A.7 filename.sh for a Docker image
Clones a repository with
book examples from GitHub
Starts Docker Compose in
the examples directory
Observe the
following output.
Validates that all components
are up and running 
Troubleshooting 233
java -cp target/chapter2-jar-with-dependencies.jar \
replace.with.full.package.name.HelloWorldProducer
A.6 Troubleshooting
All of the source code for this book is at https://github.com/Kafka-In-Action-Book/
Kafka-In-Action-Source-Code. If you have problems running this book’s examples,
here are some general tips for troubleshooting:
 Make sure you have a cluster started before running the code and command line
examples in this book.
 If you do not shut down your cluster correctly, you might have an old process
holding on to a port that you want to use the next time you attempt to start up.
You can use tools like jps or lsof to help identify which processes are running
and which might need to be killed.
 You should start inside your installation directory when you run commands,
unless otherwise noted. If you are more comfortable with the command line, you
can complete your setups, such as adding environment variables and aliases.
 If you are having trouble with commands not being found, check the setup for
your installation directory. Do you have the files marked as executable? Does a
command like chmod -R 755 help? Is the installation bin folder part of your PATH
variable? If nothing else works, using the absolute path to the command should.
 Check the source code for each chapter for a Commands.md file. This is a file
that includes most commands used throughout a specific chapter. Look for the
README.md files for more notes as well.
References
1 J. Galasyn. “How to Run Confluent on Windows in Minutes.” Confluent blog
(March 26, 2021). https://www.confluent.io/blog/set-up-and-run-kafka-on
-windows-and-wsl-2/ (accessed June 11, 2021).
2 M. G. Noll. “Running a Multi-Broker Apache Kafka 0.8 Cluster on a Single
Node.” (March 13, 2013). https://www.michael-noll.com/blog/2013/03/13/
running-a-multi-broker-apache-kafka-cluster-on-a-single-node/ (accessed July
20, 2021).
3 “Apache Kafka Quickstart.” Apache Software Foundation (n.d.). https://
kafka.apache.org/quickstart (accessed August 22, 2021).
4 README.md. Confluent Inc. GitHub (n.d.). https://github.com/conflu
entinc/customer-utilities (accessed August 21, 2021).

===

Kafka’s message delivery can take at least the following three delivery methods:

At-least-once semantics—A message is sent as needed until it is acknowledged.

If a message from a producer has a
failure or is not acknowledged, the
producer resends the message

The broker sees two messages
at least once (or only one if
there is a failure).

Consumers get as many messages
as the broker receives. Consumers
might see duplicate messages.

At-most-once semantics—A message is only sent once and not resent on failure.

If a message from a producer
has a failure or is not acknowledged,
the producer does not resend
the message.

The broker sees one
message at most (or
zero if there is a failure).

Consumers see the messages
that the broker receives. If there
is a failure, the consumer never
sees that message.

Exactly-once semantics—A message is only seen once by the consumer of the message.

If a message from a producer
fails or is not acknowledged,
the producer resends the
message.

The broker only
allows one message.

Consumers only
see the message
once.


Although this goes into deeper computer science theory, it is helpful to be aware of how Kafka defines their EOS feature [4]. If a producer sends a message more than once, it will still be delivered only once to the end consumer.


===

- A message, also called a record, is the basic piece of data flowing through Kafka.
- Each message has a timestamp, a value, and
an optional key. Custom headers can be used if desired as well.


- Brokers can be thought of as the server side of Kafka.

bin/kafka-topics.sh --create --bootstrap-server localhost:9094
--topic kinaction_helloworld --partitions 3 --replication-factor 3

The --partitions option determines how many parts we want the topic to be split into. For example, because we have three brokers, using three partitions gives us one partition per broker.

The --replication-factor also is set to three in this example. In essence, this says that for each partition, we want
to have three replicas. These copies are a crucial part of our design to improve reliability and fault tolerance.

The --bootstrap-server option points to our local Kafka
broker.

$ bin/kafka-topics.sh --list --bootstrap-server localhost:9094

The numbers we see next to the labels for the Leader, Replicas, and Isr fields are the broker.ids that correspond to the value for our three brokers that we set in our configuration files.

$ bin/kafka-topics.sh --bootstrap-server localhost:9094 \
--describe --topic kinaction_helloworld

The last column, Isr, stands for in-sync replicas. In-sync replicas show which brokers are current and not lagging
behind the leader.

When we reference a partition leader in the image, we are referring to a replica leader. It is important to know that a partition can consist of one or
more replicas, but only one replica will be a leader. A leader’s role involves
being updated by external clients, whereas nonleaders take updates only
from their leader.


$ bin/kafka-console-producer.sh --bootstrap-server localhost:9094 \
--topic kinaction_helloworld

Notice in listing 2.4 that we reference the topic that we want to interact with using a
bootstrap-server parameter. This parameter can be just one (or a list) of the current brokers in our cluster. By supplying this information, the cluster can obtain the
metadata it needs to work with the topic.

$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9094 \
--topic kinaction_helloworld --from-beginning



2.3 Tour of Kafka

Alert alert = new Alert(1, "Stage 1", "CRITICAL", "Stage 1 stopped");

ProducerRecord<Alert, String> producerRecord =
new ProducerRecord<Alert, String>
("kinaction_alert", alert, alert.getAlertMessage());
producer.send(producerRecord,
new AlertCallback());
producer.close();

consumer.subscribe(List.of("kinaction_audit"));

while (keepConsuming) {
var records = consumer.
poll(Duration.ofMillis(250));
for (ConsumerRecord<String, String> record : records) {
log.info("kinaction_info offset = {}, kinaction_value = {}",
record.offset(), record.value());
OffsetAndMetadata offsetMeta =
new OffsetAndMetadata(++record.offset(), "");
Map<TopicPartition, OffsetAndMetadata> kaOffsetMap = new HashMap<>();
kaOffsetMap.put(new TopicPartition("kinaction_audit",
record.partition()), offsetMeta);
consumer.commitSync(kaOffsetMap);
}
}


2.3.2 Topics overview
Topics are where most users start to think about the logic of what messages should go
where. Topics consist of units called partitions [1]. In other words, one or more partitions can make up a single topic. As far as what is actually implemented on the computer’s disk, partitions are what Kafka works with for the most part.
NOTE A single partition replica only exists on one broker and cannot be split
between brokers.
Figure 2.6 shows how each partition replica leader exists on a single Kafka broker
and cannot be divided smaller than that unit. Think back to our first example, the
kinaction_helloworld topic. If you’re looking
for reliability and want three copies of the data,
the topic itself is not one entity (or a single file)
that is copied; instead, it is the various partitions
that are replicated three times each.
NOTE The partition is even further broken up into segment files written on the
disk drive. We will cover these files’
details and their location when we talk
about brokers in later chapters. Although
segment files make up partitions, you will
likely not interact directly with them, and
this should be considered an internal
implementation detail.
One of the most important concepts to understand at this point is the idea that one of the partition copies (replicas) will be what is referred to
as a leader. For example, if you have a topic made
up of three partitions and a total of three copies
of each partition, every partition will have an
The topic kinaction_helloworld is made
up of three partitions that will likely be
spread out among different brokers.
Partition 0 Partition 1 Partition 2
Brokers
Topic: kinaction_helloworld
Figure 2.6 Partitions make up topics.
Tour of Kafka 27
elected leader replica. That leader will be one of the copies of the partition, and the
other two (in this case, not shown in figure 2.6) will be followers, which update their
information from their partition replica leader [1]. Producers and consumers only
read or write from the leader replica of each partition it is assigned to during scenarios
where there are no exceptions or failures (also known as a “happy path” scenario). But
how does your producer or consumer know which partition replica is the leader? In
the event of distributed computing and random failures, that answer is often influenced with help from ZooKeeper, the next stop on our tour.



2.3.3 ZooKeeper usage
Apache ZooKeeper (http://zookeeper.apache.org/) is a distributed store that provides discovery, configuration, and synchronization services in a highly available way.

In versions of Kafka since 0.9, changes were made in ZooKeeper
that allowed for a consumer to have the option not to store information about how far it had consumed messages (called offsets). 

This reduced usage did not get rid of the need for consensus and coordination in distributed systems, however.

To act as one correct application, these brokers need to not only communicate with each
other, they also need to reach an agreement. Agreeing on which one is the replica
leader of a partition is one example of the practical application of ZooKeeper within
the Kafka ecosystem.


What makes the commit log special is its append-only nature in which events are
always added to the end. The persistence as a log itself for storage is a major part of
what separates Kafka from other message brokers. Reading a message does not
remove it from the system or exclude it from other consumers.
 One common question then becomes, how long can I retain data in Kafka? In various companies today, it is not rare to see that after the data in Kafka commit logs hits
a configurable size or time retention period, the data is often moved into a permanent store. However, this is a matter of how much disk space you need and your processing workflow. The New York Times has a single partition that holds less than 100 GB
[9]. Kafka is made to keep its performance fast even while keeping its messages.
Retention details will be covered when we talk about brokers in chapter 6. For now,
just understand that log data retention can be controlled by age or size using configuration properties.

• Each log is made up of entries
 labeled with offset numbers



2.4 Various source code packages and what they do

2.4.3 AdminClient package
Kafka introduced the AdminClient API recently. Before this API, scripts and other
programs that wanted to perform specific administrative actions would either have to
run shell scripts (which Kafka provides) or invoke internal classes often used by those
shell scripts. This API is part of the kafka-clients.jar file, which is a different JAR than
the other APIs discussed previously. This interface is a great tool that will come in
handy the more involved we become with Kafka’s administration [10]. This tool also
uses a similar configuration that producers and consumers use. The source code can
be found in the org/apache/kafka/clients/admin package.


2.5 Confluent clients

public class HelloWorldProducer {
public static void main(String[] args) {
Properties kaProperties =
new Properties();
kaProperties.put("bootstrap.servers",
"localhost:9092,localhost:9093,localhost:9094");
kaProperties.put("key.serializer",
"org.apache.kafka.common.serialization.StringSerializer");
kaProperties.put("value.serializer",
"org.apache.kafka.common.serialization.StringSerializer");
try (Producer<String, String> producer =
new KafkaProducer<>(kaProperties))
ProducerRecord<String, String> producerRecord =
new ProducerRecord<>("kinaction_helloworld",
Listing 2.9 Java client producer
The producer takes a map
of name-value items to
configure its various options.
This property can take
a list of Kafka brokers.
Tells the message’s
key and value what
format to serialize
Creates a producer instance.
Producers implement the
closable interface that’s
closed automatically by the
Java runtime.
34 CHAPTER 2 Getting to know Kafka
null, "hello world again!");
producer.send(producerRecord);
}
}
}

The bootstrap.servers parameter is a list of your Kafka brokers. The list does
not have to be every server you have, though, because after the client connects, it will
find the information about the rest of the cluster’s brokers and not depend on that list.

The key.serializer and value.serializer parameters provide a class that will serialize the data as it
moves into Kafka.

Represents
our message
Sends the record
to the Kafka broker
Producer record sent to topic
kinaction_helloworld
The call to send has already figured out
which partition the producer record will be written to,
although it is not defined in your client code explicitly.
In this example, it is assigned to partition 1.
Kafka
Partition 0 Partition 1 Partition 2
JVM
Thread-safe
Kafka producer
Send Key Value
Null hello world again!
Figure 2.12
Producer flow
Confluent clients 35
The message we send as the last argument is something different from the first message we sent with our console producer. Do you know why we want to make sure the
message is different? We are working with the same topic with both producers, and
because we have a new consumer, we should be retrieving the old message we produced before in our Java client-initiated message. Once our message is ready, we asynchronously send it using the producer. In this case, because we are only sending one
message, we close the producer, which waits until previously sent requests complete
and then shuts down gracefully.


<dependency>
<groupId>org.apache.kafka</groupId>
<artifactId>kafka-clients</artifactId>
<version>2.7.1</version>
</dependency>

https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients



public class HelloWorldConsumer {
final static Logger log =
LoggerFactory.getLogger(HelloWorldConsumer.class);
private volatile boolean keepConsuming = true;
public static void main(String[] args) {
Properties kaProperties = new Properties();
kaProperties.put("bootstrap.servers",
"localhost:9092,localhost:9093,localhost:9094");
kaProperties.put("group.id", "kinaction_helloconsumer");
kaProperties.put("enable.auto.commit", "true");
kaProperties.put("auto.commit.interval.ms", "1000");
kaProperties.put("key.deserializer",
"org.apache.kafka.common.serialization.StringDeserializer");
kaProperties.put("value.deserializer",
"org.apache.kafka.common.serialization.StringDeserializer");
HelloWorldConsumer helloWorldConsumer = new HelloWorldConsumer();
helloWorldConsumer.consume(kaProperties);
Runtime.getRuntime().
addShutdownHook(new Thread(helloWorldConsumer::shutdown));
}
Listing 2.10 Java client POM entry
Listing 2.11 Java client consumer
Properties are set the
same way as producers.
36 CHAPTER 2 Getting to know Kafka
private void consume(Properties kaProperties) {
try (KafkaConsumer<String, String> consumer =
new KafkaConsumer<>(kaProperties)) {
consumer.subscribe(
List.of(
"kinaction_helloworld"
)
);
while (keepConsuming) {
ConsumerRecords<String, String> records =
consumer.poll(Duration.ofMillis(250));
for (ConsumerRecord<String, String> record :
records) {
log.info("kinaction_info offset = {}, kinaction_value = {}",
record.offset(), record.value());
}
}
}
}
private void shutdown() {
keepConsuming = false;
}
}

Unlike the producer, the Java consumer client is not thread safe.
Our code is responsible for ensuring that any access is synchronized: one simple option is
having only one consumer per Java thread. Also, whereas we told the producer where
to send the message, we now have the consumer subscribe to the topics it wants. A
subscribe command can subscribe to more than one topic at a time.
 One of the most important sections to note in listing 2.11 is the poll call on the consumer. This is what is actively trying to bring messages to our application. No messages,
one message, or many messages can all come back with a single poll, so it is important
to note that our logic should account for more than one result with each poll call.
 Finally, we can Ctrl-C the consumer program when we retrieve the test messages and
be done for now. As a note, these examples rely on many configuration properties that
are enabled by default. We will have a chance to dig into them more in later chapters.
2.6 Stream processing and terminology
We are not going to challenge distributed systems theories or certain definitions that
could have various meanings, but rather look at how Kafka works. As you start to think
of applying Kafka to your work, you will be presented with the following terms and
can, hopefully, use the following descriptions as a lens through which to view your
processing mindset.
The consumer tells Kafka what
topics it’s interested in.
Polls for new messages
as they come in
To see the result, prints
each record that we
consume to the console
Stream processing and terminology 37
Figure 2.13 Kafka overview
Figure 2.13 provides a high-level view of what Kafka does. Kafka has many moving
parts that depend on data coming into and out of its core to provide value to its users.
Producers send data into Kafka, which works as a distributed system for reliability and
scale, with logs, which are the basis for storage. Once data is inside the Kafka ecosystem, consumers can help users utilize that data in their other applications and use
cases. Our brokers make up the cluster and coordinate with a ZooKeeper cluster to
maintain metadata. Because Kafka stores data on disk, the ability to replay data in case
of an application failure is also part of Kafka’s feature set. These attributes allow Kafka
to become the foundation of powerful stream-processing applications.


===

The producer’s job includes fetching metadata about the cluster [2]. Because producers can only write to the replica leader of the partition they are assigned to, the metadata helps the producer determine which broker to write to as the user might have
only included a topic name without any other details. This is nice because the producer’s end user does not have to make a separate call to get that information. The
end user, however, needs to have at least one running broker to connect to, and the
Java client library figures out the rest.

 Because this distributed system is designed to account for momentary errors such as
a network blip, the logic for retries is already built in. However, if the ordering of the
messages is essential, like for our audit messages, then besides setting the retries to a
number like 3, we also need to set the max.in.flight.requests.per.connection
value to 1 and set acks (the number of brokers that send acknowledgments back) to
all [3] [4]. In our opinion, this is one of the safest methods to ensure that your producer’s messages arrive in the order you intend [4]. We can set the values for both acks
and retries as configuration parameters.
 Another option to be aware of is using an idempotent producer. The term idempotent refers to how sending the same message multiple times only results in producing
the message once. To use an idempotent producer, we can set the configuration property enable.idempotence=true [5]. We will not be using the idempotent producer in
our following examples.
 One thing we do not have to worry about is one producer getting in the way of
another producer’s data. Thread safety is not an issue because data will not be overwritten but handled by the broker itself and appended to the broker’s log [6]. Now
it is time to look at how to enable the values like max.in.flight.requests.per
.connection in code.

4.2 Producer options
One of the things that was interesting when we started working with sending data into
Kafka was the ease of setting options using the Java clients that we will specifically
focus on in this book. If you have worked with other queue or messaging systems, the
other systems’ setups can include things like providing remote and local queues lists,
manager hostnames, starting connections, connection factories, sessions, and more.
Producer options 71
Although far from being set up totally hassle free, the producer works from the configuration on its own to retrieve much of the information it needs, such as a list of all
of our Kafka brokers. Using the value from the property bootstrap.servers as a starting point, the producer fetches metadata about brokers and partitions that it uses for
all subsequent writes.
 As mentioned earlier, Kafka allows you to change key behaviors just by changing
some configuration values. One way to deal with all of the producer configuration key
names is to use the constants provided in the Java class ProducerConfig when developing producer code (see http://mng.bz/ZYdA) and by looking for the Importance
label of “high” in the Confluent website [7]. However, in our examples, we will use the
property names themselves for clarity.
 Table 4.1 lists some of the most crucial producer configurations that support our
specific examples. In the following sections, we'll look at what we need to complete
our factory work.
4.2.1 Configuring the broker list
From our examples of writing messages to Kafka, it is clear that we have to tell the producer which topic to send messages to. Recall that topics are made up of partitions,
but how does Kafka know where a topic partition resides? We, however, do not have to
know the details of those partitions when we send messages. Perhaps an illustration
will help clarify this conundrum. One of the required configuration options for producers is bootstrap.servers. Figure 4.4 shows an example of a producer that has
only broker 0 in its list of bootstrap servers, but it will be able to learn about all three
brokers in the cluster by starting with one only.
 The bootstrap.servers property can take many or just one initial broker as in figure 4.4. By connecting to this broker, the client can discover the metadata it needs,
which includes data about other brokers in the cluster as well [8].
Table 4.1 Important producer configurations
Key Purpose
acks Number of replica acknowledgments that a producer requires before
success is established
bootstrap.servers One or more Kafka brokers to connect for startup
value.serializer The class that’s used for serialization of the value
key.serializer The class that’s used for serialization of the key
72 CHAPTER 4 Producers: Sourcing data
Figure 4.4 Bootstrap servers
This configuration is key to helping the producer find a broker to talk to. Once the
producer is connected to the cluster, it can obtain the metadata it needs to get the
details (such as where the leader replica for the partition resides on disk) we did not
previously provide. Producer clients can also overcome a failure of the partition
leader they are writing to by using the information about the cluster to find a new
leader. You might have noticed that ZooKeeper’s information is not part of the configuration. Any metadata the producer needs will be handled without the producer client having to provide ZooKeeper cluster details.
4.2.2 How to go fast (or go safer)
Asynchronous message patterns are one reason that many use queue-type systems, and
this powerful feature is also available in Kafka. We can wait in our code for the result
of a producer send request, or we can handle success or failure asynchronously with
callbacks or Future objects. If we want to go faster and not wait for a reply, we can still
handle the results at a later time with our own custom logic.
 Another configuration property that applies to our scenario is the acks key, which
stands for acknowledgments. This controls how many acknowledgments the producer
needs to receive from the partition leader’s followers before it returns a completed
request. The valid values for this property are all, -1, 1, and 0 [9].
 Figure 4.5 shows how a message with ack set to 0 behaves. Setting this value to 0 will
probably get us the lowest latency but at the cost of safety. Additionally, guarantees are
not made if any broker receives the message and, also, retries are not attempted [9]. As
a sample use case, say that we have a web-tracking platform that collects the clicks on a
page and sends these events to Kafka. In this situation, it might not be a big deal to lose
a single link press or hover event. If one is lost, there is no real business impact.
 In essence, the event in figure 4.5 was sent from the producer and forgotten. The
message might have never made it to the partition. If the message did, by chance,
make it to the leader replica, the producer will not know if any follower replica copies
were successful.
1. Producer connects
 to bootstrap servers
2. Metadata sent back to producer letting
 it know its leader resides on Broker 2,
 which it did not know about at first.
 Kafka knows about its other brokers.
Producer
Controller
Broker 0 Broker 1
Our alert producers
connect to our servers
since they are local on
different ports on localhost.
Broker 2
Producer options 73
What we would consider the opposite setting to that used previously would be acks
with values all or -1. The values all or -1 are the strongest available option for this
configuration setting. Figure 4.6 shows how the value all means that a partition
leader’s replica waits on the entire list of its in-sync replicas (ISRs) to acknowledge
completion [9]. In other words, the producer will not get an acknowledgment of success until after all replicas for a partition are successful. It is easy to see that it won’t be
the quickest due to the dependencies it has on other brokers. In many cases, it is
1. The producer writes
 to the leader of the
 partition.
2. The leader doesn’t wait
 to find out if the write
 was successful.
3. Because we do not know if the leader
 write was successful, we are not aware
 of the state of any replica copies and if
 they were successful or not.
This is not what
we want for our
kinaction_audit
producer.
Figure 4.5 The property acks equals 0.
3. The producer receives
 notification when all of
 the replicas are updated.
2. The leader waits for all
 brokers to reply with
 success or failure.
1. The producer writes
 to the leader of the
 partition.
We use acks=all for our Leader broker
kinaction_audit producer.
Figure 4.6 The property
acks equals all.
74 CHAPTER 4 Producers: Sourcing data
worth paying the performance price in order to prevent data loss. With many brokers
in a cluster, we need to be aware of the number of brokers the leader has to wait on.
The broker that takes the longest to reply is the determining factor for how long until
a producer receives a success message.
 Figure 4.7 shows the impact of setting the acks value to 1 and asking for an
acknowledgment. An acknowledgment involves the receiver of the message (the
leader replica of the specific partition) sending confirmation back to the producer.
The producer client waits for that acknowledgment. However, the followers might not
have copied the message before a failure brings down the leader. If that situation
occurs before a copy is made, the message never appears on the replica followers for
that partition [9]. Figure 4.7 shows that while the message was acknowledged by the
leader replica and sent to the producer, a failure of any replica to make a copy of the
message would appear as if the message never made it to the cluster.
Figure 4.7 The property acks equals 1.
NOTE This is closely related to the ideas of at-most and at-least semantics that
we covered in chapter 1 [10]. The acks setting is a part of that larger picture.
4.2.3 Timestamps
Recent versions of the producer record contain a timestamp on the events you send. A
user can either pass the time into the constructor as a Java type long when sending a
ProducerRecord Java object or the current system time. The actual time that is used in
3. Before the leader that has success
 has time to copy the message to any
 follower replicas, the leader fails. This
 means that the message could be
 lost to the remaining brokers.
4. These brokers never see
 the message even though
 it was seen by the leader.
2. The partition leader replies
 that the message has made
 a successful call.
1. The producer writes
 to the leader of the
 partition.
Our other producers
might use this setting.
Producer options 75
the message can stay as this value, or it can be a broker timestamp that occurs when
the message is logged. Setting the topic configuration message.timestamp.type to
CreateTime uses the time set by the client, whereas setting it to LogAppendTime uses
the broker time [11].
 Why would you want to choose one over the other? You might want to use the created time in order to have the time that a transaction (like a sales order) takes place
rather than when it made its way to the broker. Using the broker time can be useful
when the created time is handled inside the message itself or an actual event time is
not business or order relevant.
 As always, timestamps can be tricky. For example, we might get a record with an
earlier timestamp than that of a record before it. This can happen in cases where a
failure occurred and a different message with a later timestamp was committed before
the retry of the first record completed. The data is ordered in the log by offsets and
not by timestamp. Although reading timestamped data is often thought of as a consumer client concern, it is also a producer concern because the producer takes the
first steps in ensuring message order.
 As discussed earlier, this is also why max.in.flight.requests.per.connection is
important when considering whether you want to allow retries or many inflight
requests at a time. If a retry happens and other requests succeed on their first attempt,
earlier messages might be added after the later ones. Figure 4.8 provides an example
of when a message can get out of order. Even though message 1 was sent first, it does
not make it into the log in an ordered manner because retries were enabled.
 As a reminder, with Kafka versions before 0.10, timestamp information is not available as that feature was not included in earlier releases. We can still include a timestamp, though, but we would need to store it in the value of the message itself.
Figure 4.8 Retry impact on order
Leader partition broker
Producer
Message 1
Message 2
Message 1 retry
We used this retry logic to determine if we
need ordering with our alert events from
chapter 3 and for topic kinaction_audit.
1. Message 1 is sent
 and fails.
2. Message 2 is sent
 and succeeds.
3. Message 1 is resent and
 appended to the leader
 log after message 2.
76 CHAPTER 4 Producers: Sourcing data
Another option when using a producer is to create producer interceptors. These were
introduced in KIP-42 (Kafka Improvement Proposal). Its main goal was to help support measuring and monitoring [12]. In comparison to using a Kafka Streams workflow to filter or aggregate data, or even creating different topics specifically for
modified data, the usage of these interceptors might not be our first choice. At present, there are no default interceptors that run in the life cycle. In chapter 9, we will
show a use case for tracing messages from producer clients to consumer clients with
interceptors adding a trace ID.
4.3 Generating code for our requirements
Let’s try to use the information we gathered about how producers work on our own
solutions. We’ll start with the audit checklist that we designed in chapter 3 for use with
Kafka in our e-bike factory. As noted in chapter 3, we want to make sure that we do not
lose any audit messages when operators complete commands against the sensors. One
requirement was that there was no need to correlate (or group together) any events.
Another requirement was to make sure we don’t lose any messages. The following listing shows how we would start our producer configuration and how to make sure that
we are safe for message acknowledgment by setting acks to all.
public class AuditProducer {
...
private static final Logger log = LoggerFactory.getLogger
(AuditProducer.class);Properties kaProperties = new Properties();
kaProperties.put( "bootstrap.servers",
"localhost:9092,localhost:9093,localhost:9094");
kaProperties.put("acks", "all");
kaProperties.put("retries", "3");
kaProperties.put("max.in.flight.requests.per.connection", "1");
...
Notice that we did not have to touch anything except the configuration we send to the
producer to address the concern of message loss. The acks configuration change is a
small but powerful feature that has a significant impact on if a message arrives or not.
Because we do not have to correlate (group) any events together, we are not using a
key for these messages. However, there is a foundational part that we want to change
in order to wait for the result before moving on. The following listing shows the get
method, which is how we can bring about waiting for the response to complete synchronously before moving on in the code. Note that the following listing was
Listing 4.1 Configuring the audit producer
Creates properties as before
for our configuration
Sets acks to all to get
the strongest guarantee
Lets the client retry in case of
failure so we don’t have to
implement our own failure logic
Generating code for our requirements 77
informed by examples located at: https://docs.confluent.io/2.0.0/clients/producer
.html#examples.
RecordMetadata result =
producer.send(producerRecord).get();
log.info("kinaction_info offset = {}, topic = {}, timestamp = {}",
result.offset(), result.topic(), result.timestamp());
 producer.close();
Waiting on the response directly in a synchronous way ensures that the code is handling each record’s results as they come back before another message is sent. The
focus is on delivering the messages without loss, more than on speed!
 So far, we have used a couple of prebuilt serializers in earlier chapters. For plain
text messages, our producer uses a serializer called StringSerializer. And when we
talked about Avro in chapter 3, we reached for the class io.confluent.kafka
.serializers.KafkaAvroSerializer. But what if we have a specific format we want to
produce? This often happens when trying to work with custom objects. We’ll use serialization to translate data into a format that can be transmitted, stored, and then
retrieved to achieve a clone of our original data. The following listing shows the code
for our Alert class.
public class Alert implements Serializable {
private final int alertId;
private String stageId;
private final String alertLevel;
private final String alertMessage;
public Alert(int alertId,
String stageId,
String alertLevel,
String alertMessage) {
this.alertId = alertId;
this.stageId = stageId;
this.alertLevel = alertLevel;
this.alertMessage = alertMessage;
}
public int getAlertId() {
return alertId;
}
public String getStageId() {
return stageId;
}
Listing 4.2 Waiting for a result
Listing 4.3 Alert class
Waits on the response
from the send call
Holds the alert’s ID,
level, and messages
78 CHAPTER 4 Producers: Sourcing data
public void setStageId(String stageId) {
this.stageId = stageId;
}
public String getAlertLevel() {
return alertLevel;
}
public String getAlertMessage() {
return alertMessage;
}
}
Listing 4.3 shows code that we use to create a bean named Alert to hold the information we want to send. Those familiar with Java will notice that the listing is nothing
more than getters and setters and a constructor for the Alert class. Now that there is a
format for the Alert data object, it is time to use it in making a simple alert Serializer called AlertKeySerde as the following listing shows.
public class AlertKeySerde implements Serializer<Alert>,
Deserializer<Alert> {
public byte[] serialize(String topic, Alert key) {
if (key == null) {
return null;
}
return key.getStageId()
.getBytes(StandardCharsets.UTF_8);
}
public Alert deserialize
(String topic, byte[] value) {
//could return Alert in future if needed
return null;
}
//...
}
In listing 4.5, we use this custom class only as the key serializer for the moment, leaving the value serializer as a StringSerializer. It is interesting to note that we can serialize keys and values with different serializers on the same message. But we should be
mindful of our intended serializers and the configuration values for both. The code
implements the Serializer interface and only pulls out the field stageId to use as a
key for our message. This example should be straightforward because the focus is on
the technique of using a serde. Other options for serdes that are often used are JSON
and Avro implementations.
NOTE If you see or hear the term serde, it means that the serializer and deserializer are both handled by the same implementation of that interface [13].
Listing 4.4 Our Alert serializer
Sends the topic and the
Alert object to our method
Converts objects to
bytes (our end goal)
The rest of the interface methods do
not need any logic at this point.
Generating code for our requirements 79
However, it is still common to see each interface defined separately. Just
watch when you use StringSerializer versus StringDeserializer; the difference can be hard to spot!
Another thing to keep in mind is that knowing how to deserialize the values involves
the consumers in relation to how the values were serialized by the producer. Some
sort of agreement or coordinator is needed for the data formats for clients even
though Kafka does not care what data it stores on the brokers.
 Another goal of our design for the factory was to capture the alert trend status of
our stages to track their alerts over time. Because we care about the information for
each stage (and not all sensors at a time), it might be helpful to think of how we are
going to group these events. In this case, as each stage ID is unique, it makes sense
that we can use that ID as a key. The following listing shows the key.serializer property that we’ll set, as well as sending a CRITICAL alert.
public class AlertTrendingProducer {
private static final Logger log =
LoggerFactory.getLogger(AlertTrendingProducer.class);
public static void main(String[] args)
throws InterruptedException, ExecutionException {
Properties kaProperties = new Properties();
kaProperties.put("bootstrap.servers",
"localhost:9092,localhost:9093,localhost:9094");
kaProperties.put("key.serializer",
 AlertKeySerde.class.getName());
kaProperties.put("value.serializer",
"org.apache.kafka.common.serialization.StringSerializer");
try (Producer<Alert, String> producer =
new KafkaProducer<>(kaProperties)) {
Alert alert = new Alert(0, "Stage 0", "CRITICAL", "Stage 0 stopped");
ProducerRecord<Alert, String> producerRecord =
new ProducerRecord<>("kinaction_alerttrend",
alert, alert.getAlertMessage());
RecordMetadata result = producer.send(producerRecord).get();
log.info("kinaction_info offset = {}, topic = {}, timestamp = {}",
result.offset(), result.topic(), result.timestamp());
}
}
}
In general, the same key should produce the same partition assignment, and nothing
will need to be changed. In other words, the same stage IDs (the keys) are grouped
Listing 4.5 Alert trending producer
Tells our producer client
how to serialize our custom
Alert object into a key
Instead of null for the second
parameter, uses the actual object
we want to populate the key
80 CHAPTER 4 Producers: Sourcing data
together just by using the correct key. We will keep an eye on the distribution of the size
of the partitions to note if they become uneven in the future, but for now, we will go
along with this. Also, note that for our specific classes that we created in the manuscript,
we are setting the class properties in a different way to show a different option. Instead
of hardcoding the entire path of the class, you can use something like AlertKeySerde.class.getName() or even AlertKeySerde.class for the value of the property.
 Our last requirement was to have alerts quickly processed to let operators know
about any critical outages so we can group by the stage ID in this case as well. One reason for doing this is that we can tell if a sensor failed or recovered (any state change)
by looking at only the last event for that stage ID. We do not care about the history of
the status checks, only the current scenario. In this case, we also want to partition our
alerts.
 So far in our examples of writing to Kafka, the data was directed to a topic with no
additional metadata provided from the client. Because the topics are made up of partitions that sit on the brokers, Kafka provides a default way to send messages to a specific partition. The default for a message with no key (which we used in the examples
thus far) was a round-robin assignment strategy prior to Kafka version 2.4. In versions
after 2.4, messages without keys use a sticky partition strategy [14]. However, sometimes we have specific ways that we want our data to be partitioned. One way to take
control of this is to write our own unique partitioner class.
 The client also has the ability to control what partition it writes to by configuring a
unique partitioner. One example to think about is the alert levels from our sensormonitoring service that was discussed in chapter 3. Some sensors’ information might
be more important than others; these might be on the critical path of our e-bike,
which would cause downtime if not addressed. Let’s say we have four levels of alerts:
Critical, Major, Minor, and Warning. We could create a partitioner that places the different levels in different partitions. Our consumer clients would always make sure to
read the critical alerts before processing the others.
 If our consumers keep up with the messages being logged, critical alerts probably
would not be a huge concern. However, listing 4.6 shows that we could change the
partition assignment with a class to make sure that our critical alerts are directed to a
specific partition (like partition 0). (Note that other alerts could end up on partition
0 as well due to our logic, but that critical alerts will always end up there.) The logic
mirrors an example of the DefaultPartitioner used in Kafka itself [15].
public int partition(final String topic
# ...
 int criticalLevelPartition = findCriticalPartitionNumber(cluster, topic);
Listing 4.6 Partitioner for alert levels
AlertLevelPartitioner needs
to implement the partition
method for its core logic.
Generating code for our requirements 81
return isCriticalLevel(((Alert) objectKey).getAlertLevel()) ?
 criticalLevelPartition :
 findRandomPartition(cluster, topic, objectKey);
}
//...
By implementing the Partitioner interface, we can use the partition method to send
back the specific partition we want our producer to write to. In this case, the value of the
key ensures that any CRITICAL event makes it to a specific place, partition 0 can be imagined to be sent back from the method findCriticalPartitionNumber, for example. In
addition to creating the class itself, listing 4.7 shows how we need to set the configuration key, partitioner.class, for our producer to use the specific class we created. The
configuration that powers Kafka is used to leverage our new class.
Properties kaProperties = new Properties();
//...
kaProperties.put("partitioner.class",
AlertLevelPartitioner.class.getName());
This example, in which a specific partition number is always sent back, can be
expanded on or made even more dynamic. We can use custom code to accomplish the
specific logic of our business needs.
 Listing 4.8 shows the configuration of the producer to add the partitioner.class
value to use as our specific partitioner. The intention is for us to have the data available in a specific partition, so consumers that process the data can have access to the
critical alerts specifically and can go after other alerts (in other partitions) when they
are handled.
public class AlertProducer {
public static void main(String[] args) {
Properties kaProperties = new Properties();
kaProperties.put("bootstrap.servers",
"localhost:9092,localhost:9093");
kaProperties.put("key.serializer",
AlertKeySerde.class.getName());
kaProperties.put("value.serializer",
"org.apache.kafka.common.serialization.StringSerializer");
kaProperties.put("partitioner.class",
AlertLevelPartitioner.class.getName());
try (Producer<Alert, String> producer =
new KafkaProducer<>(kaProperties)) {
Listing 4.7 Configuring the partitioner class
Listing 4.8 Alert producer
Critical alerts should end up
the partition returned from
findCriticalPartitionNumber
Updates the producer configuration
to reference and use the custom
partitioner AlertLevelPartitioner
Reuses the Alert
key serializer
Uses the property partitioner.class
to set our specific partitioner class
82 CHAPTER 4 Producers: Sourcing data
Alert alert = new Alert(1, "Stage 1", "CRITICAL", "Stage 1 stopped");
ProducerRecord<Alert, String>
producerRecord = new ProducerRecord<>
("kinaction_alert", alert, alert.getAlertMessage());
producer.send(producerRecord,
new AlertCallback());
}
}
}
One addition we see in listing 4.8 is how we added a callback to run on completion.
Although we said that we are not 100% concerned with message failures from time to
time, due to the frequency of events, we want to make sure that we do not see a high
failure rate that could be a hint at application-related errors. The following listing
shows an example of implementing a Callback interface. The callback would log a
message only if an error occurs. Note that the following listing was informed by examples located at https://docs.confluent.io/2.0.0/clients/producer.html#examples.
public class AlertCallback implements Callback {
private static final Logger log =
LoggerFactory.getLogger(AlertCallback.class);
public void onCompletion
(RecordMetadata metadata,
Exception exception) {
if (exception != null) {
log.error("kinaction_error", exception);
} else {
log.info("kinaction_info offset = {}, topic = {}, timestamp = {}",
metadata.offset(), metadata.topic(), metadata.timestamp());
}
}
}
Although we will focus on small samples in most of our material, we think that it is
helpful to look at how to use a producer in a real project as well. As mentioned earlier,
Apache Flume can be used alongside Kafka to provide various data features. When we
use Kafka as a sink, Flume places data into Kafka. You might (or might not) be familiar with Flume, but we are not interested in its feature set for this. We want to see how
it leverages Kafka producer code in a real situation.
 In the following examples, we reference Flume version 1.8 (located at https://
github.com/apache/flume/tree/flume-1.8, if you want to view more of the complete
source code). The following listing shows a configuration snippet that would be used
by a Flume agent.
Listing 4.9 Alert callback
This is the first time we’ve used
a callback to handle the
completion or failure of a send.
Implements the Kafka
Callback interface
The completion can
have success or failure.
Generating code for our requirements 83
a1.sinks.k1.kafka.topic = kinaction_helloworld
a1.sinks.k1.kafka.bootstrap.servers = localhost:9092
a1.sinks.k1.kafka.producer.acks = 1
a1.sinks.k1.kafka.producer.compression.type = snappy
Some configuration properties from listing 4.10 seem familiar: topic, acks, bootstrap.servers. In our previous examples, we declared the configurations as properties inside our code. However, listing 4.10 shows an example of an application that
externalizes the configuration values, which is something we could do on our projects
as well. The KafkaSink source code from Apache Flume, found at http://mng.bz/JvpZ,
provides an example of taking data and placing it inside Kafka with producer code. The
following listing is a different example of a producer using a similar idea, taking a configuration file like that in listing 4.10 and loading those values into a producer instance.
...
Properties kaProperties = readConfig();
String topic = kaProperties.getProperty("topic");
kaProperties.remove("topic");
try (Producer<String, String> producer =
new KafkaProducer<>(kaProperties)) {
ProducerRecord<String, String> producerRecord =
new ProducerRecord<>(topic, null, "event");
producer.send(producerRecord,
new AlertCallback());
}
private static Properties readConfig() {
Path path = Paths.get("src/main/resources/kafkasink.conf");
Properties kaProperties = new Properties();
try (Stream<String> lines = Files.lines(path))
lines.forEachOrdered(line ->
determineProperty(line, kaProperties));
} catch (IOException e) {
System.out.println("kinaction_error" + e);
}
return kaProperties;
}
private static void determineProperty
(String line, Properties kaProperties) {
if (line.contains("bootstrap")) {
kaProperties.put("bootstrap.servers", line.split("=")[1]);
} else if (line.contains("acks")) {
kaProperties.put("acks", line.split("=")[1]);
} else if (line.contains("compression.type")) {
kaProperties.put("compression.type", line.split("=")[1]);
} else if (line.contains("topic")) {
Listing 4.10 Flume sink configuration
Listing 4.11 Reading the Kafka producer configuration from a file
Our familiar producer.send
with a callback
Reads an external file
for configuration
Parses configuration properties
and sets those values
84 CHAPTER 4 Producers: Sourcing data
kaProperties.put("topic", line.split("=")[1]);
}
...
}
Although some code is omitted in listing 4.11, the core Kafka producer pieces might
be starting to look familiar. Setting the configuration and the producer send method
should all look like the code we wrote in this chapter. And now, hopefully, you have
the confidence to dig into which configuration properties were set and what impacts
they will have.
 One exercise left for the reader would be to compare how AlertCallback.java
stacks up to the Kafka Sink callback class SinkCallback, located in the source code at
http://mng.bz/JvpZ. Both examples uses the RecordMetadata object to find more
information about successful calls. This information can help us learn more about
where the producer message was written, including the partition and offset within that
specific partition.
 It is true that you can use applications like Flume without ever having to dig into its
source code and still be successful. However, we think that if you want to know what is
going on internally or need to do some advanced troubleshooting, it is important to
know what the tools are doing. With your new foundational knowledge of producers,
it should be apparent that you can make powerful applications using these techniques
yourself.
4.3.1 Client and broker versions
One important thing to note is that Kafka broker and client versions do not always
have to match. If you are running a broker that is at Kafka version 0.10.0 and the Java
producer client you are using is at 0.10.2, the broker will handle this upgrade in the
message version [16]. However, because you can does not mean you should do it in all
cases. To dig into more of the bidirectional version compatibility, take a peek at
KIP-97 (http://mng.bz/7jAQ).
 We crossed a significant hurdle by starting to get data into Kafka. Now that we are
deeper into the Kafka ecosystem, we have other concepts to conquer before we are
done with our end-to-end solution. The next question is, how can we start to pull this
data back out so our other applications can consume it? We now have some ideas
about how we get data into Kafka, so we can start to work on learning more about making that data useful to other applications by getting it out in the correct ways. Consumer clients are a vital part of this discovery and, as with producers, there are various
configuration-driven behaviors that we can use to help us satisfy different requirements for consumption.
Summary
 Producer clients provide developers a way to get data into Kafka.
 A large number of configuration options are available to control client behavior
without custom code.
References 85
 Data is stored on the brokers in what is known as partitions.
 The client can control which partition the data gets written to by providing
their own logic with the Partitioner interface.
 Kafka generally sees data as a series of bytes. However, custom serializers can be
used to deal with specific data formats.
References
1 J. Kreps. “Why Avro for Kafka Data?” Confluent blog (February 25, 2015).
https://www.confluent.io/blog/avro-kafka-data/ (accessed November 23, 2017).
2 “Sender.java.” Apache Kafka. GitHub (n.d.). https://github.com/apache/kafka/
blob/299eea88a5068f973dc055776c7137538ed01c62/clients/src/main/java/
org/apache/kafka/clients/producer/internals/Sender.java (accessed August
20, 2021).
3 “Producer Configurations: Retries.” Confluent documentation (n.d.). https://
docs.confluent.io/platform/current/installation/configuration/producer
-configs.html#producerconfigs_retries (accessed May 29, 2020).
4 “Producer Configurations: max.in.flight.requests.per.connection.” Confluent
documentation (n.d.). https://docs.confluent.io/platform/current/installa
tion/configuration/producer-configs.html#max.in.flight.requests.per.connec
tion (accessed May 29, 2020).
5 “Producer Configurations: enable.idempotence.” Confluent documentation
(n.d.). https://docs.confluent.io/platform/current/installation/configuration
/producer-configs.html#producerconfigs_enable.idempotence (accessed May
29, 2020).
6 “KafkaProducer.” Apache Software Foundation (n.d.). https://kafka.apache
.org/10/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html
(accessed July 7, 2019).
7 “Producer Configurations.” Confluent documentation (n.d.). https://docs.con
fluent.io/platform/current/installation/configuration/producer-configs.html
(accessed May 29, 2020).
8 “Producer Configurations: bootstrap.servers.” Confluent documentation (n.d.).
https://docs.confluent.io/platform/current/installation/configuration/
producer-configs.html #bootstrap.servers (accessed May 29, 2020).
9 “Producer Configurations: acks.” Confluent documentation (n.d.). https://
docs.confluent.io/platform/current/installation/configuration/producer
-configs.html#acks (accessed May 29, 2020).
10 “Documentation: Message Delivery Semantics.” Apache Software Foundation
(n.d.). https://kafka.apache.org/documentation/#semantics (accessed May 30,
2020).
11 “Topic Configurations: message.timestamp.type.” Confluent documentation (n.d.).
https://docs.confluent.io/platform/current/installation/configuration/topicconfigs.html#topicconfigs_message.timestamp.type (accessed July 22, 2020).
86 CHAPTER 4 Producers: Sourcing data
12 KIP-42: “Add Producer and Consumer Interceptors,” Wiki for Apache Kafka,
Apache Software Foundation. https://cwiki.apache.org/confluence/display/
KAFKA/KIP-42%3A+Add+Producer+and+Consumer+Interceptors (accessed
April 15, 2019).
13 “Kafka Streams Data Types and Serialization.” Confluent documentation (n.d.).
https://docs.confluent.io/platform/current/streams/developer-guide/data
types.html (accessed August 21, 2021).
14 J. Olshan. “Apache Kafka Producer Improvements with the Sticky Partitioner.”
Confluent blog (December 18, 2019). https://www.confluent.io/blog/apache
-kafka-producer-improvements-sticky-partitioner/ (accessed August 21, 2021).
15 “DefaultPartitioner.java,” Apache Software Foundation. GitHub (n.d.). https://
github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/
kafka/clients/producer/internals/DefaultPartitioner.java (accessed March 22,
2020).
16 C. McCabe. “Upgrading Apache Kafka Clients Just Got Easier.” Confluent blog
(July 18, 2017). https://www.confluent.io/blog/upgrading-apache-kafka-clients
-just-got-easier/ (accessed August 21, 2021).




