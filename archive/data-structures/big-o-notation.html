---
title: "Big-O Notation"
date: 2020-09-29
draft: false
---

<ul class="contents">
	<li>
		<ul>
      <li>
        <a href="#introduction">Introduction</a>
      </li>
      <li>
        <a href="#resources">Resources</a>
      </li>
		</ul>
	</li>
</ul>



<h3 id="introduction">Introduction</h3>

<p>
  Big-O notation is a symbolism that describes the asymptotic behavior of functions. Big-O notation is used to classify algorithms according to how their run time or space requirements grow as the input size grows.
</p>


<!--
Big-O notation is a symbolism used to describe  In other words, it tells you how fast a function grows or declines.

Big-O notation is a notation that describes the limiting behavior of a function when the argument tends towards a particular value or infinity.

Big-O notation characterizes functions according to their growth rates: different functions with the same growth rate may be represented using the same O notation.

For example, one might find the time (or number of steps) it takes to complete a problem of size \(n\) is given by \(T(n) = 4n^2 - 2n + 2\). If we ignore constants (which makes sense because those depend on the particular hardware the program is run on) and slower growing terms, we could say "\(T(n)\) grows at the order of \(n^2\)" and write: \(T(n) = O(n^2)\).
-->



<h3 class="definition">Definition</h3>

<p>
  Let \(f\) and \(g\) be functions defined on som e unbounded subset of the positive real numbers. We write \(f(n) = O(g(n))\) as \(n \rightarrow \infty\) if there exist constants \(N\) and \(M\) such that \(|f(n)| \le M|g(n)|\) for all \(n > N\). Intuitively, this means that \(f\) does not grow faster than \(g\).
</p>

<figure>
  <img src="/img/big-o-notation/definition.svg" style="max-width: 340px;">
  <figcaption>
    <i>figure 1</i>
  </figcaption>
</figure>



<h3 class="usage">Usage</h3>

<p>
  Big-O notation is typically used to describe the limiting behavior of a function \(f(n)\) for large values of \(n\). As such, dominant terms that grow most quickly will eventually make the other terms irrelevant. As a result the following simplification rules can be applied:
</p>

<ul>
  <li>
    If \(f(n)\) is a sum of several terms, if there is one with largest growth rate, then other terms can be omitted.
  </li>
  <li>
    If \(f(n)\) is a product of several factors, any constants can be omitted.
  </li>
</ul>


<!-- Big O notation is useful when analyzing algorithms for efficiency. For example, the time (or the number of steps) it takes to complete a problem of size n might be found to be T(n) = 4n2 − 2n + 2. As n grows large, the n2 term will come to dominate, so that all other terms can be neglected—for instance when n = 500, the term 4n2 is 1000 times as large as the 2n term. Ignoring the latter would have negligible effect on the expression's value for most purposes. Further, the coefficients become irrelevant if we compare to any other order of expression, such as an expression containing a term n3 or n4. Additionally, the number of steps depends on the details of the machine model on which the algorithm runs, but different types of machines typically vary by only a constant factor in the number of steps needed to execute an algorithm. So the big O notation captures what remains: we write

T(n)=O(n^2)

and say that the algorithm has order of n^2 time complexity. -->



<h3 class="example">Example</h3>

<p>
  For example, consider the function \(f(n) = 6n^4 - 2n^3 + 5\). Taking the highest order term \(6n^4\) and omitting constants we get that \(f(n) = O(n^4)\). We can confirm this using the formal definition. Let \(g(n) = n^4\)
</p>

<!-- 
One may confirm this calculation using the formal definition: let f(x) = 6x^4 − 2x^3 + 5 and g(x) = x^4. Applying the formal definition from above, the statement that f(x) = O(x^4) is equivalent to its expansion,

|f(x)| \le Mx^4

for some suitable choice of x_0 and M and for all x > x_0. To prove this, let x_0 = 1 and M = 13. Then, for all x > x_0:

|6x^4 - 2x^3 + 5| \le 6x^4 + |2x^3| + 5 \le 6x^4 + 2x^4 + 5x^4 = 13x^4

so

|6x^4 - 2x^3 + 5| \le 13x^4
-->

<!-- Product
{\displaystyle f_{1}=O(g_{1}){\text{ and }}f_{2}=O(g_{2})\Rightarrow f_{1}f_{2}=O(g_{1}g_{2})}{\displaystyle f_{1}=O(g_{1}){\text{ and }}f_{2}=O(g_{2})\Rightarrow f_{1}f_{2}=O(g_{1}g_{2})}
{\displaystyle f\cdot O(g)=O(fg)}f\cdot O(g)=O(fg)
Sum
{\displaystyle f_{1}=O(g_{1}){\text{ and }}f_{2}=O(g_{2})\Rightarrow f_{1}+f_{2}=O(\max(g_{1},g_{2}))}{\displaystyle f_{1}=O(g_{1}){\text{ and }}f_{2}=O(g_{2})\Rightarrow f_{1}+f_{2}=O(\max(g_{1},g_{2}))}
This implies {\displaystyle f_{1}=O(g){\text{ and }}f_{2}=O(g)\Rightarrow f_{1}+f_{2}\in O(g)}f_{1}=O(g){\text{ and }}f_{2}=O(g)\Rightarrow f_{1}+f_{2}\in O(g), which means that {\displaystyle O(g)}O(g) is a convex cone.

Multiplication by a constant
Let k be constant. Then:
{\displaystyle O(|k|g)=O(g)}{\displaystyle O(|k|g)=O(g)} if k is nonzero.
{\displaystyle f=O(g)\Rightarrow kf=O(g).}{\displaystyle f=O(g)\Rightarrow kf=O(g).} -->




<h3 class="orders-of-common-functions">Orders of Common Functions</h3>

<p>
  The following table lists the classes of functions that are most commonly encountered when analyzing the running time of an algorithm.
</p>


<table>
  <tr>
    <th>
      Notation
    </th>
    <th>
      Name
    </th>
  </tr>
  <tr>
    <td>
      \(O(1)\)
    </td>
    <td>
      constant
    </td>
  </tr>
  <tr>
    <td>
      \(O(\log n)\)
    </td>
    <td>
      logarithmic
    </td>
  </tr>
  <tr>
    <td>
      \(O(n^c)\)
    </td>
    <td>
      fractional power
    </td>
  </tr>
  <tr>
    <td>
      \(O(n)\)
    </td>
    <td>
      linear
    </td>
  </tr>
  <tr>
    <td>
      \(O(n \log n)\)
    </td>
    <td>
      linearithmic
    </td>
  </tr>
  <tr>
    <td>
      \(O(n^2)\)
    </td>
    <td>
      quadratic
    </td>
  </tr>
  <tr>
    <td>
      \(O(n^c)\)
    </td>
    <td>
      polynomial
    </td>
  </tr>
  <tr>
    <td>
      \(O(c^n)\)
    </td>
    <td>
      exponential
    </td>
  </tr>
  <tr>
    <td>
      \(O(n!)\)
    </td>
    <td>
      factorial
    </td>
  </tr>
</table>

<!-- TODO: diagram -->

<ul>
  <li>
    \(O(1)\) describes an algorithm that will always execute in the same time regardless of the size of the input data set.
  </li>
</ul>


<!--
// O(1)
bool IsFirstElementNull(IList<string> elements)
{
    return elements[0] == null;
}

O(N)
O(N) describes an algorithm whose performance will grow linearly and in direct proportion to the size of the input data set. The example below also demonstrates how Big O favours the worst-case performance scenario; a matching string could be found during any iteration of the for loop and the function would return early, but Big O notation will always assume the upper limit where the algorithm will perform the maximum number of iterations.

bool ContainsValue(IList<string> elements, string value)
{
    foreach (var element in elements)
    {
        if (element == value) return true;
    }

    return false;
}
O(N2)
O(N2) represents an algorithm whose performance is directly proportional to the square of the size of the input data set. This is common with algorithms that involve nested iterations over the data set. Deeper nested iterations will result in O(N3), O(N4) etc.

bool ContainsDuplicates(IList<string> elements)
{
    for (var outer = 0; outer < elements.Count; outer++)
    {
        for (var inner = 0; inner < elements.Count; inner++)
        {
            // Don't compare with self
            if (outer == inner) continue;

            if (elements[outer] == elements[inner]) return true;
        }
    }

    return false;
}
O(2N)
O(2N) denotes an algorithm whose growth doubles with each additon to the input data set. The growth curve of an O(2N) function is exponential - starting off very shallow, then rising meteorically. An example of an O(2N) function is the recursive calculation of Fibonacci numbers:

int Fibonacci(int number)
{
    if (number <= 1) return number;

    return Fibonacci(number - 2) + Fibonacci(number - 1);
}
Log -->



<h3 class="examples">Examples</h3>

<h4>Example 1</h4>

<pre><code class="java">public void example(int[] array) {
  int sum = 0;
  int product = 1;

  for (inti= 0; i &lt; array.length; i++) {
    sum += array[i);
  }

  for (int i= 0; i &lt; array.length; i++) {
    product *= array[i];
  }
  
  System.out.println(sum + ", " + product);
}</code></pre>

<p>
  This will take \(O(n)\) time. The fact that we iterate through the array twice doesn't matter.
</p>


<h4>Example 2</h4>

<pre><code class="java">public void example(int[] array) {
  for (int i= 0; i &lt; array.length; i++) {
    for (int j = 0; j &lt; array.length; j++) {
      System.out.println(array[i] + "," + array[j]);
    }
  }
}</code></pre>

<p>
  The inner loop has \(O(n)\) iterations and it is called \(n\) times. Therefore, the runtime is \(O(n^2)\).
</p>


<h4>Example 3</h4>

<pre><code class="java">public void example(int[] array) {
  for (int i = 0; i &lt; array.length; i++) {
    for (int j = i + 1; j &lt; array.length; j++) {
      System.out.println(array[i] + "," + array[j]);
    }
  }
}</code></pre>

<p>
  The first time through \(j\) runs for \(n-1\) steps. The second time, it runs for \(n-2\) steps. Then \(n-3\) step. And so on. Therefore, the total number of steps is \((n-1) + (n-2) + \dots + 2 + 1\) which is \((n(n-1))/2\). So the runtime will be \(O(n^2)\).
</p>


<h4>Example 4</h4>

<pre><code class="java"></code></pre>

<p>

</p>


<h4>Example 5</h4>

<pre><code class="java"></code></pre>

<p>

</p>


<h4>Example 6</h4>

<pre><code class="java"></code></pre>

<p>

</p>


<!-- TODO: Get examples from Cracking -->









<h3 id="resources">Resources</h3>

<ul>
  <li>
    <a href="https://en.wikipedia.org/wiki/Big_O_notation">Big-O Notation (Wikipedia)</a>
  </li>
  <li>
    <a href="https://rob-bell.net/2009/06/a-beginners-guide-to-big-o-notation/"></a>
  </li>
</ul>


<!-- 
  2 1 The Gist 
  https://www.youtube.com/watch?v=l-cNaKGc-yY&list=PLXFMmlk03Dt7Q0xr1PIAriY5623cKiH7V&index=9

  2 2 Big Oh Notation
  https://www.youtube.com/watch?v=QfRSeibcugw&list=PLXFMmlk03Dt7Q0xr1PIAriY5623cKiH7V&index=10

  2 3 Basic Examples
  https://www.youtube.com/watch?v=5rZCkblZFZM&list=PLXFMmlk03Dt7Q0xr1PIAriY5623cKiH7V&index=11
 -->
